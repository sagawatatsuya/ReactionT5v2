{
  "best_metric": 2.5859375,
  "best_model_checkpoint": "./output/checkpoint-262144",
  "epoch": 0.0009513726020542947,
  "eval_steps": 262144,
  "global_step": 262144,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.161343508367059e-07,
      "grad_norm": 25606.21861970252,
      "learning_rate": 0.002,
      "loss": 121.1763,
      "step": 32
    },
    {
      "epoch": 2.322687016734118e-07,
      "grad_norm": 26252.957776220188,
      "learning_rate": 0.002,
      "loss": 30.9237,
      "step": 64
    },
    {
      "epoch": 3.484030525101177e-07,
      "grad_norm": 31495.85102834975,
      "learning_rate": 0.002,
      "loss": 25.4659,
      "step": 96
    },
    {
      "epoch": 4.645374033468236e-07,
      "grad_norm": 12962.518119563036,
      "learning_rate": 0.002,
      "loss": 23.5299,
      "step": 128
    },
    {
      "epoch": 5.806717541835295e-07,
      "grad_norm": 12426.120633568627,
      "learning_rate": 0.002,
      "loss": 19.9345,
      "step": 160
    },
    {
      "epoch": 6.968061050202354e-07,
      "grad_norm": 12445.267212880566,
      "learning_rate": 0.002,
      "loss": 17.2281,
      "step": 192
    },
    {
      "epoch": 8.129404558569413e-07,
      "grad_norm": 10421.491064142407,
      "learning_rate": 0.002,
      "loss": 15.8623,
      "step": 224
    },
    {
      "epoch": 9.290748066936471e-07,
      "grad_norm": 13429.952792173173,
      "learning_rate": 0.002,
      "loss": 15.2696,
      "step": 256
    },
    {
      "epoch": 1.045209157530353e-06,
      "grad_norm": 8847.379894635475,
      "learning_rate": 0.002,
      "loss": 13.6005,
      "step": 288
    },
    {
      "epoch": 1.161343508367059e-06,
      "grad_norm": 12037.405866713974,
      "learning_rate": 0.002,
      "loss": 12.4542,
      "step": 320
    },
    {
      "epoch": 1.2774778592037649e-06,
      "grad_norm": 9362.097361168597,
      "learning_rate": 0.002,
      "loss": 11.9981,
      "step": 352
    },
    {
      "epoch": 1.3936122100404707e-06,
      "grad_norm": 8652.927654846075,
      "learning_rate": 0.002,
      "loss": 10.2553,
      "step": 384
    },
    {
      "epoch": 1.5097465608771768e-06,
      "grad_norm": 8445.383058215892,
      "learning_rate": 0.002,
      "loss": 9.502,
      "step": 416
    },
    {
      "epoch": 1.6258809117138826e-06,
      "grad_norm": 7352.88582802698,
      "learning_rate": 0.002,
      "loss": 8.8499,
      "step": 448
    },
    {
      "epoch": 1.7420152625505885e-06,
      "grad_norm": 7638.959222302473,
      "learning_rate": 0.002,
      "loss": 7.8651,
      "step": 480
    },
    {
      "epoch": 1.8581496133872943e-06,
      "grad_norm": 5757.693895996903,
      "learning_rate": 0.002,
      "loss": 7.0638,
      "step": 512
    },
    {
      "epoch": 1.974283964224e-06,
      "grad_norm": 7366.733672395113,
      "learning_rate": 0.002,
      "loss": 6.7561,
      "step": 544
    },
    {
      "epoch": 2.090418315060706e-06,
      "grad_norm": 6237.095958857776,
      "learning_rate": 0.002,
      "loss": 6.2991,
      "step": 576
    },
    {
      "epoch": 2.2065526658974122e-06,
      "grad_norm": 6806.069093096249,
      "learning_rate": 0.002,
      "loss": 5.6183,
      "step": 608
    },
    {
      "epoch": 2.322687016734118e-06,
      "grad_norm": 3817.958944252806,
      "learning_rate": 0.002,
      "loss": 4.9676,
      "step": 640
    },
    {
      "epoch": 2.438821367570824e-06,
      "grad_norm": 5384.017737712238,
      "learning_rate": 0.002,
      "loss": 4.6814,
      "step": 672
    },
    {
      "epoch": 2.5549557184075298e-06,
      "grad_norm": 5141.492293099349,
      "learning_rate": 0.002,
      "loss": 4.3281,
      "step": 704
    },
    {
      "epoch": 2.6710900692442356e-06,
      "grad_norm": 4229.500738857957,
      "learning_rate": 0.002,
      "loss": 4.08,
      "step": 736
    },
    {
      "epoch": 2.7872244200809414e-06,
      "grad_norm": 7080.830495076125,
      "learning_rate": 0.002,
      "loss": 4.0565,
      "step": 768
    },
    {
      "epoch": 2.9033587709176473e-06,
      "grad_norm": 5399.129281652737,
      "learning_rate": 0.002,
      "loss": 3.6685,
      "step": 800
    },
    {
      "epoch": 3.0194931217543536e-06,
      "grad_norm": 4261.404433986524,
      "learning_rate": 0.002,
      "loss": 3.5524,
      "step": 832
    },
    {
      "epoch": 3.1356274725910594e-06,
      "grad_norm": 3588.6112564611954,
      "learning_rate": 0.002,
      "loss": 3.281,
      "step": 864
    },
    {
      "epoch": 3.2517618234277652e-06,
      "grad_norm": 5658.2693909003665,
      "learning_rate": 0.002,
      "loss": 3.4934,
      "step": 896
    },
    {
      "epoch": 3.367896174264471e-06,
      "grad_norm": 3937.2998679297975,
      "learning_rate": 0.002,
      "loss": 3.2193,
      "step": 928
    },
    {
      "epoch": 3.484030525101177e-06,
      "grad_norm": 3751.292810485473,
      "learning_rate": 0.002,
      "loss": 2.9689,
      "step": 960
    },
    {
      "epoch": 3.6001648759378828e-06,
      "grad_norm": 3798.7740785679794,
      "learning_rate": 0.002,
      "loss": 2.9843,
      "step": 992
    },
    {
      "epoch": 3.7162992267745886e-06,
      "grad_norm": 5974.447840595815,
      "learning_rate": 0.002,
      "loss": 2.8554,
      "step": 1024
    },
    {
      "epoch": 3.8324335776112944e-06,
      "grad_norm": 8235.092227777415,
      "learning_rate": 0.002,
      "loss": 2.9834,
      "step": 1056
    },
    {
      "epoch": 3.948567928448e-06,
      "grad_norm": 7271.106380737391,
      "learning_rate": 0.002,
      "loss": 2.7836,
      "step": 1088
    },
    {
      "epoch": 4.064702279284706e-06,
      "grad_norm": 5466.077752831548,
      "learning_rate": 0.002,
      "loss": 2.8092,
      "step": 1120
    },
    {
      "epoch": 4.180836630121412e-06,
      "grad_norm": 8236.143636435683,
      "learning_rate": 0.002,
      "loss": 2.7501,
      "step": 1152
    },
    {
      "epoch": 4.296970980958119e-06,
      "grad_norm": 7018.669247086658,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 1184
    },
    {
      "epoch": 4.4131053317948245e-06,
      "grad_norm": 6594.205714109926,
      "learning_rate": 0.002,
      "loss": 2.6161,
      "step": 1216
    },
    {
      "epoch": 4.52923968263153e-06,
      "grad_norm": 6783.993550999293,
      "learning_rate": 0.002,
      "loss": 2.6676,
      "step": 1248
    },
    {
      "epoch": 4.645374033468236e-06,
      "grad_norm": 7339.988061979392,
      "learning_rate": 0.002,
      "loss": 2.5955,
      "step": 1280
    },
    {
      "epoch": 4.761508384304942e-06,
      "grad_norm": 4498.653756958853,
      "learning_rate": 0.002,
      "loss": 2.6165,
      "step": 1312
    },
    {
      "epoch": 4.877642735141648e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5293,
      "step": 1344
    },
    {
      "epoch": 4.993777085978354e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.51,
      "step": 1376
    },
    {
      "epoch": 5.1099114368150595e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5095,
      "step": 1408
    },
    {
      "epoch": 5.226045787651765e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5377,
      "step": 1440
    },
    {
      "epoch": 5.342180138488471e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5509,
      "step": 1472
    },
    {
      "epoch": 5.458314489325177e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5526,
      "step": 1504
    },
    {
      "epoch": 5.574448840161883e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5431,
      "step": 1536
    },
    {
      "epoch": 5.690583190998589e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.52,
      "step": 1568
    },
    {
      "epoch": 5.806717541835295e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5166,
      "step": 1600
    },
    {
      "epoch": 5.922851892672001e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5487,
      "step": 1632
    },
    {
      "epoch": 6.038986243508707e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5548,
      "step": 1664
    },
    {
      "epoch": 6.155120594345413e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.562,
      "step": 1696
    },
    {
      "epoch": 6.271254945182119e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5504,
      "step": 1728
    },
    {
      "epoch": 6.387389296018825e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5516,
      "step": 1760
    },
    {
      "epoch": 6.5035236468555305e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5553,
      "step": 1792
    },
    {
      "epoch": 6.619657997692236e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5442,
      "step": 1824
    },
    {
      "epoch": 6.735792348528942e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5426,
      "step": 1856
    },
    {
      "epoch": 6.851926699365648e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4981,
      "step": 1888
    },
    {
      "epoch": 6.968061050202354e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5369,
      "step": 1920
    },
    {
      "epoch": 7.08419540103906e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5353,
      "step": 1952
    },
    {
      "epoch": 7.2003297518757655e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5345,
      "step": 1984
    },
    {
      "epoch": 7.316464102712471e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5576,
      "step": 2016
    },
    {
      "epoch": 7.432598453549177e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5426,
      "step": 2048
    },
    {
      "epoch": 7.548732804385883e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5414,
      "step": 2080
    },
    {
      "epoch": 7.664867155222589e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5565,
      "step": 2112
    },
    {
      "epoch": 7.781001506059296e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5321,
      "step": 2144
    },
    {
      "epoch": 7.897135856896e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5323,
      "step": 2176
    },
    {
      "epoch": 8.013270207732707e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5585,
      "step": 2208
    },
    {
      "epoch": 8.129404558569412e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5486,
      "step": 2240
    },
    {
      "epoch": 8.245538909406119e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5373,
      "step": 2272
    },
    {
      "epoch": 8.361673260242824e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5286,
      "step": 2304
    },
    {
      "epoch": 8.47780761107953e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5284,
      "step": 2336
    },
    {
      "epoch": 8.593941961916237e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5471,
      "step": 2368
    },
    {
      "epoch": 8.710076312752942e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5492,
      "step": 2400
    },
    {
      "epoch": 8.826210663589649e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5306,
      "step": 2432
    },
    {
      "epoch": 8.942345014426354e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5395,
      "step": 2464
    },
    {
      "epoch": 9.05847936526306e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 2496
    },
    {
      "epoch": 9.174613716099766e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5569,
      "step": 2528
    },
    {
      "epoch": 9.290748066936472e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5602,
      "step": 2560
    },
    {
      "epoch": 9.406882417773177e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5577,
      "step": 2592
    },
    {
      "epoch": 9.523016768609884e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5488,
      "step": 2624
    },
    {
      "epoch": 9.639151119446589e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5331,
      "step": 2656
    },
    {
      "epoch": 9.755285470283296e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.552,
      "step": 2688
    },
    {
      "epoch": 9.87141982112e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5316,
      "step": 2720
    },
    {
      "epoch": 9.987554171956707e-06,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5128,
      "step": 2752
    },
    {
      "epoch": 1.0103688522793412e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5304,
      "step": 2784
    },
    {
      "epoch": 1.0219822873630119e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5117,
      "step": 2816
    },
    {
      "epoch": 1.0335957224466826e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5178,
      "step": 2848
    },
    {
      "epoch": 1.045209157530353e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5113,
      "step": 2880
    },
    {
      "epoch": 1.0568225926140237e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5152,
      "step": 2912
    },
    {
      "epoch": 1.0684360276976942e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5047,
      "step": 2944
    },
    {
      "epoch": 1.0800494627813649e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5175,
      "step": 2976
    },
    {
      "epoch": 1.0916628978650354e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5071,
      "step": 3008
    },
    {
      "epoch": 1.103276332948706e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.507,
      "step": 3040
    },
    {
      "epoch": 1.1148897680323766e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4938,
      "step": 3072
    },
    {
      "epoch": 1.1265032031160472e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5135,
      "step": 3104
    },
    {
      "epoch": 1.1381166381997177e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5132,
      "step": 3136
    },
    {
      "epoch": 1.1497300732833884e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.501,
      "step": 3168
    },
    {
      "epoch": 1.161343508367059e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4977,
      "step": 3200
    },
    {
      "epoch": 1.1729569434507296e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4848,
      "step": 3232
    },
    {
      "epoch": 1.1845703785344003e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5134,
      "step": 3264
    },
    {
      "epoch": 1.1961838136180708e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5038,
      "step": 3296
    },
    {
      "epoch": 1.2077972487017414e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4903,
      "step": 3328
    },
    {
      "epoch": 1.219410683785412e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4988,
      "step": 3360
    },
    {
      "epoch": 1.2310241188690826e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5051,
      "step": 3392
    },
    {
      "epoch": 1.2426375539527531e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5169,
      "step": 3424
    },
    {
      "epoch": 1.2542509890364238e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5068,
      "step": 3456
    },
    {
      "epoch": 1.2658644241200943e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5103,
      "step": 3488
    },
    {
      "epoch": 1.277477859203765e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5211,
      "step": 3520
    },
    {
      "epoch": 1.2890912942874354e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5246,
      "step": 3552
    },
    {
      "epoch": 1.3007047293711061e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.506,
      "step": 3584
    },
    {
      "epoch": 1.3123181644547766e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4917,
      "step": 3616
    },
    {
      "epoch": 1.3239315995384473e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.483,
      "step": 3648
    },
    {
      "epoch": 1.3355450346221178e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4807,
      "step": 3680
    },
    {
      "epoch": 1.3471584697057884e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5283,
      "step": 3712
    },
    {
      "epoch": 1.3587719047894591e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5187,
      "step": 3744
    },
    {
      "epoch": 1.3703853398731296e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5001,
      "step": 3776
    },
    {
      "epoch": 1.3819987749568003e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5019,
      "step": 3808
    },
    {
      "epoch": 1.3936122100404708e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5046,
      "step": 3840
    },
    {
      "epoch": 1.4052256451241414e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5075,
      "step": 3872
    },
    {
      "epoch": 1.416839080207812e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4989,
      "step": 3904
    },
    {
      "epoch": 1.4284525152914826e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4739,
      "step": 3936
    },
    {
      "epoch": 1.4400659503751531e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5135,
      "step": 3968
    },
    {
      "epoch": 1.4516793854588238e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.513,
      "step": 4000
    },
    {
      "epoch": 1.4632928205424943e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5133,
      "step": 4032
    },
    {
      "epoch": 1.474906255626165e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5014,
      "step": 4064
    },
    {
      "epoch": 1.4865196907098354e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4978,
      "step": 4096
    },
    {
      "epoch": 1.4981331257935061e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4942,
      "step": 4128
    },
    {
      "epoch": 1.5097465608771766e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.516,
      "step": 4160
    },
    {
      "epoch": 1.5213599959608473e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5051,
      "step": 4192
    },
    {
      "epoch": 1.5329734310445178e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5032,
      "step": 4224
    },
    {
      "epoch": 1.5445868661281884e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4935,
      "step": 4256
    },
    {
      "epoch": 1.556200301211859e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5169,
      "step": 4288
    },
    {
      "epoch": 1.5678137362955298e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5113,
      "step": 4320
    },
    {
      "epoch": 1.5794271713792e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5117,
      "step": 4352
    },
    {
      "epoch": 1.5910406064628708e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5128,
      "step": 4384
    },
    {
      "epoch": 1.6026540415465414e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5241,
      "step": 4416
    },
    {
      "epoch": 1.614267476630212e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4999,
      "step": 4448
    },
    {
      "epoch": 1.6258809117138824e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4996,
      "step": 4480
    },
    {
      "epoch": 1.637494346797553e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4819,
      "step": 4512
    },
    {
      "epoch": 1.6491077818812238e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4988,
      "step": 4544
    },
    {
      "epoch": 1.6607212169648945e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5241,
      "step": 4576
    },
    {
      "epoch": 1.6723346520485648e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5323,
      "step": 4608
    },
    {
      "epoch": 1.6839480871322355e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5395,
      "step": 4640
    },
    {
      "epoch": 1.695561522215906e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5273,
      "step": 4672
    },
    {
      "epoch": 1.7071749572995768e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5156,
      "step": 4704
    },
    {
      "epoch": 1.7187883923832475e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5224,
      "step": 4736
    },
    {
      "epoch": 1.7304018274669178e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5263,
      "step": 4768
    },
    {
      "epoch": 1.7420152625505885e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5275,
      "step": 4800
    },
    {
      "epoch": 1.753628697634259e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5078,
      "step": 4832
    },
    {
      "epoch": 1.7652421327179298e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5443,
      "step": 4864
    },
    {
      "epoch": 1.7768555678016e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5298,
      "step": 4896
    },
    {
      "epoch": 1.7884690028852708e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5237,
      "step": 4928
    },
    {
      "epoch": 1.8000824379689415e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5212,
      "step": 4960
    },
    {
      "epoch": 1.811695873052612e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5088,
      "step": 4992
    },
    {
      "epoch": 1.8233093081362825e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5197,
      "step": 5024
    },
    {
      "epoch": 1.834922743219953e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5221,
      "step": 5056
    },
    {
      "epoch": 1.8465361783036238e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5163,
      "step": 5088
    },
    {
      "epoch": 1.8581496133872945e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5135,
      "step": 5120
    },
    {
      "epoch": 1.869763048470965e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5159,
      "step": 5152
    },
    {
      "epoch": 1.8813764835546355e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5323,
      "step": 5184
    },
    {
      "epoch": 1.892989918638306e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5328,
      "step": 5216
    },
    {
      "epoch": 1.9046033537219768e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5471,
      "step": 5248
    },
    {
      "epoch": 1.9162167888056475e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5294,
      "step": 5280
    },
    {
      "epoch": 1.9278302238893178e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5302,
      "step": 5312
    },
    {
      "epoch": 1.9394436589729885e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5281,
      "step": 5344
    },
    {
      "epoch": 1.951057094056659e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5097,
      "step": 5376
    },
    {
      "epoch": 1.9626705291403298e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5177,
      "step": 5408
    },
    {
      "epoch": 1.974283964224e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.507,
      "step": 5440
    },
    {
      "epoch": 1.9858973993076708e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5407,
      "step": 5472
    },
    {
      "epoch": 1.9975108343913415e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5319,
      "step": 5504
    },
    {
      "epoch": 2.009124269475012e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5225,
      "step": 5536
    },
    {
      "epoch": 2.0207377045586825e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5258,
      "step": 5568
    },
    {
      "epoch": 2.032351139642353e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5133,
      "step": 5600
    },
    {
      "epoch": 2.0439645747260238e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5308,
      "step": 5632
    },
    {
      "epoch": 2.0555780098096945e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5046,
      "step": 5664
    },
    {
      "epoch": 2.067191444893365e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.522,
      "step": 5696
    },
    {
      "epoch": 2.0788048799770355e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5206,
      "step": 5728
    },
    {
      "epoch": 2.090418315060706e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5384,
      "step": 5760
    },
    {
      "epoch": 2.1020317501443768e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5294,
      "step": 5792
    },
    {
      "epoch": 2.1136451852280475e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5191,
      "step": 5824
    },
    {
      "epoch": 2.1252586203117178e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5236,
      "step": 5856
    },
    {
      "epoch": 2.1368720553953885e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.508,
      "step": 5888
    },
    {
      "epoch": 2.148485490479059e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5268,
      "step": 5920
    },
    {
      "epoch": 2.1600989255627298e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5288,
      "step": 5952
    },
    {
      "epoch": 2.1717123606464e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5173,
      "step": 5984
    },
    {
      "epoch": 2.1833257957300708e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5121,
      "step": 6016
    },
    {
      "epoch": 2.1949392308137415e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.523,
      "step": 6048
    },
    {
      "epoch": 2.206552665897412e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5473,
      "step": 6080
    },
    {
      "epoch": 2.2181661009810828e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5338,
      "step": 6112
    },
    {
      "epoch": 2.229779536064753e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5278,
      "step": 6144
    },
    {
      "epoch": 2.2413929711484238e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5145,
      "step": 6176
    },
    {
      "epoch": 2.2530064062320945e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5394,
      "step": 6208
    },
    {
      "epoch": 2.264619841315765e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5109,
      "step": 6240
    },
    {
      "epoch": 2.2762332763994355e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5045,
      "step": 6272
    },
    {
      "epoch": 2.287846711483106e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5245,
      "step": 6304
    },
    {
      "epoch": 2.299460146566777e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5171,
      "step": 6336
    },
    {
      "epoch": 2.3110735816504475e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 6368
    },
    {
      "epoch": 2.322687016734118e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5356,
      "step": 6400
    },
    {
      "epoch": 2.3343004518177885e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5168,
      "step": 6432
    },
    {
      "epoch": 2.345913886901459e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5185,
      "step": 6464
    },
    {
      "epoch": 2.35752732198513e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5139,
      "step": 6496
    },
    {
      "epoch": 2.3691407570688005e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5273,
      "step": 6528
    },
    {
      "epoch": 2.380754192152471e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5339,
      "step": 6560
    },
    {
      "epoch": 2.3923676272361415e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5098,
      "step": 6592
    },
    {
      "epoch": 2.4039810623198122e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5302,
      "step": 6624
    },
    {
      "epoch": 2.415594497403483e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5459,
      "step": 6656
    },
    {
      "epoch": 2.4272079324871532e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5284,
      "step": 6688
    },
    {
      "epoch": 2.438821367570824e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5242,
      "step": 6720
    },
    {
      "epoch": 2.4504348026544945e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5043,
      "step": 6752
    },
    {
      "epoch": 2.4620482377381652e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5133,
      "step": 6784
    },
    {
      "epoch": 2.4736616728218355e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5279,
      "step": 6816
    },
    {
      "epoch": 2.4852751079055062e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5225,
      "step": 6848
    },
    {
      "epoch": 2.496888542989177e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5011,
      "step": 6880
    },
    {
      "epoch": 2.5085019780728475e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5169,
      "step": 6912
    },
    {
      "epoch": 2.520115413156518e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5364,
      "step": 6944
    },
    {
      "epoch": 2.5317288482401885e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5433,
      "step": 6976
    },
    {
      "epoch": 2.5433422833238592e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5389,
      "step": 7008
    },
    {
      "epoch": 2.55495571840753e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5157,
      "step": 7040
    },
    {
      "epoch": 2.5665691534912005e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5332,
      "step": 7072
    },
    {
      "epoch": 2.578182588574871e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5195,
      "step": 7104
    },
    {
      "epoch": 2.5897960236585415e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5304,
      "step": 7136
    },
    {
      "epoch": 2.6014094587422122e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5291,
      "step": 7168
    },
    {
      "epoch": 2.613022893825883e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5116,
      "step": 7200
    },
    {
      "epoch": 2.6246363289095532e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5204,
      "step": 7232
    },
    {
      "epoch": 2.636249763993224e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5367,
      "step": 7264
    },
    {
      "epoch": 2.6478631990768945e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5234,
      "step": 7296
    },
    {
      "epoch": 2.6594766341605652e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5217,
      "step": 7328
    },
    {
      "epoch": 2.6710900692442355e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5011,
      "step": 7360
    },
    {
      "epoch": 2.6827035043279062e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5181,
      "step": 7392
    },
    {
      "epoch": 2.694316939411577e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5316,
      "step": 7424
    },
    {
      "epoch": 2.7059303744952475e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5209,
      "step": 7456
    },
    {
      "epoch": 2.7175438095789182e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5167,
      "step": 7488
    },
    {
      "epoch": 2.7291572446625885e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5299,
      "step": 7520
    },
    {
      "epoch": 2.7407706797462592e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5375,
      "step": 7552
    },
    {
      "epoch": 2.75238411482993e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5338,
      "step": 7584
    },
    {
      "epoch": 2.7639975499136005e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5249,
      "step": 7616
    },
    {
      "epoch": 2.775610984997271e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5182,
      "step": 7648
    },
    {
      "epoch": 2.7872244200809415e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.507,
      "step": 7680
    },
    {
      "epoch": 2.7988378551646122e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5311,
      "step": 7712
    },
    {
      "epoch": 2.810451290248283e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.531,
      "step": 7744
    },
    {
      "epoch": 2.8220647253319532e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5046,
      "step": 7776
    },
    {
      "epoch": 2.833678160415624e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5239,
      "step": 7808
    },
    {
      "epoch": 2.8452915954992945e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5383,
      "step": 7840
    },
    {
      "epoch": 2.8569050305829652e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5349,
      "step": 7872
    },
    {
      "epoch": 2.868518465666636e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.524,
      "step": 7904
    },
    {
      "epoch": 2.8801319007503062e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5177,
      "step": 7936
    },
    {
      "epoch": 2.891745335833977e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5172,
      "step": 7968
    },
    {
      "epoch": 2.9033587709176475e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5351,
      "step": 8000
    },
    {
      "epoch": 2.9149722060013182e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5307,
      "step": 8032
    },
    {
      "epoch": 2.9265856410849885e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5193,
      "step": 8064
    },
    {
      "epoch": 2.9381990761686592e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5123,
      "step": 8096
    },
    {
      "epoch": 2.94981251125233e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5051,
      "step": 8128
    },
    {
      "epoch": 2.9614259463360005e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5339,
      "step": 8160
    },
    {
      "epoch": 2.973039381419671e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5321,
      "step": 8192
    },
    {
      "epoch": 2.9846528165033415e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5102,
      "step": 8224
    },
    {
      "epoch": 2.9962662515870122e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5213,
      "step": 8256
    },
    {
      "epoch": 3.007879686670683e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5251,
      "step": 8288
    },
    {
      "epoch": 3.0194931217543532e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.536,
      "step": 8320
    },
    {
      "epoch": 3.031106556838024e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5209,
      "step": 8352
    },
    {
      "epoch": 3.0427199919216946e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5189,
      "step": 8384
    },
    {
      "epoch": 3.054333427005365e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5387,
      "step": 8416
    },
    {
      "epoch": 3.0659468620890356e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5258,
      "step": 8448
    },
    {
      "epoch": 3.077560297172706e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5332,
      "step": 8480
    },
    {
      "epoch": 3.089173732256377e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5185,
      "step": 8512
    },
    {
      "epoch": 3.1007871673400476e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5164,
      "step": 8544
    },
    {
      "epoch": 3.112400602423718e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5121,
      "step": 8576
    },
    {
      "epoch": 3.124014037507389e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5228,
      "step": 8608
    },
    {
      "epoch": 3.1356274725910596e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5165,
      "step": 8640
    },
    {
      "epoch": 3.1472409076747296e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5169,
      "step": 8672
    },
    {
      "epoch": 3.1588543427584e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5374,
      "step": 8704
    },
    {
      "epoch": 3.170467777842071e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5199,
      "step": 8736
    },
    {
      "epoch": 3.1820812129257416e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5324,
      "step": 8768
    },
    {
      "epoch": 3.193694648009412e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5244,
      "step": 8800
    },
    {
      "epoch": 3.205308083093083e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5221,
      "step": 8832
    },
    {
      "epoch": 3.2169215181767536e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5477,
      "step": 8864
    },
    {
      "epoch": 3.228534953260424e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5347,
      "step": 8896
    },
    {
      "epoch": 3.240148388344095e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5361,
      "step": 8928
    },
    {
      "epoch": 3.251761823427765e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5093,
      "step": 8960
    },
    {
      "epoch": 3.2633752585114356e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5233,
      "step": 8992
    },
    {
      "epoch": 3.274988693595106e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5091,
      "step": 9024
    },
    {
      "epoch": 3.286602128678777e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5237,
      "step": 9056
    },
    {
      "epoch": 3.2982155637624476e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.519,
      "step": 9088
    },
    {
      "epoch": 3.309828998846118e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5104,
      "step": 9120
    },
    {
      "epoch": 3.321442433929789e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5271,
      "step": 9152
    },
    {
      "epoch": 3.3330558690134596e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5261,
      "step": 9184
    },
    {
      "epoch": 3.3446693040971296e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5171,
      "step": 9216
    },
    {
      "epoch": 3.3562827391808e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5208,
      "step": 9248
    },
    {
      "epoch": 3.367896174264471e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5242,
      "step": 9280
    },
    {
      "epoch": 3.3795096093481416e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5439,
      "step": 9312
    },
    {
      "epoch": 3.391123044431812e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5236,
      "step": 9344
    },
    {
      "epoch": 3.402736479515483e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5287,
      "step": 9376
    },
    {
      "epoch": 3.4143499145991536e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.523,
      "step": 9408
    },
    {
      "epoch": 3.425963349682824e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5171,
      "step": 9440
    },
    {
      "epoch": 3.437576784766495e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5104,
      "step": 9472
    },
    {
      "epoch": 3.449190219850165e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5298,
      "step": 9504
    },
    {
      "epoch": 3.4608036549338356e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5276,
      "step": 9536
    },
    {
      "epoch": 3.472417090017506e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5286,
      "step": 9568
    },
    {
      "epoch": 3.484030525101177e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.522,
      "step": 9600
    },
    {
      "epoch": 3.4956439601848476e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5251,
      "step": 9632
    },
    {
      "epoch": 3.507257395268518e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5167,
      "step": 9664
    },
    {
      "epoch": 3.518870830352189e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5287,
      "step": 9696
    },
    {
      "epoch": 3.5304842654358596e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5286,
      "step": 9728
    },
    {
      "epoch": 3.54209770051953e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.553,
      "step": 9760
    },
    {
      "epoch": 3.5537111356032e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5258,
      "step": 9792
    },
    {
      "epoch": 3.565324570686871e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.51,
      "step": 9824
    },
    {
      "epoch": 3.5769380057705416e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5224,
      "step": 9856
    },
    {
      "epoch": 3.588551440854212e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5088,
      "step": 9888
    },
    {
      "epoch": 3.600164875937883e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5188,
      "step": 9920
    },
    {
      "epoch": 3.6117783110215536e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5083,
      "step": 9952
    },
    {
      "epoch": 3.623391746105224e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.526,
      "step": 9984
    },
    {
      "epoch": 3.635005181188895e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5276,
      "step": 10016
    },
    {
      "epoch": 3.646618616272565e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5215,
      "step": 10048
    },
    {
      "epoch": 3.6582320513562356e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5337,
      "step": 10080
    },
    {
      "epoch": 3.669845486439906e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5178,
      "step": 10112
    },
    {
      "epoch": 3.681458921523577e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5234,
      "step": 10144
    },
    {
      "epoch": 3.6930723566072476e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5351,
      "step": 10176
    },
    {
      "epoch": 3.704685791690918e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5385,
      "step": 10208
    },
    {
      "epoch": 3.716299226774589e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5243,
      "step": 10240
    },
    {
      "epoch": 3.7279126618582596e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5202,
      "step": 10272
    },
    {
      "epoch": 3.73952609694193e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5185,
      "step": 10304
    },
    {
      "epoch": 3.7511395320256e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5042,
      "step": 10336
    },
    {
      "epoch": 3.762752967109271e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5226,
      "step": 10368
    },
    {
      "epoch": 3.7743664021929416e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5217,
      "step": 10400
    },
    {
      "epoch": 3.785979837276612e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5101,
      "step": 10432
    },
    {
      "epoch": 3.797593272360283e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5239,
      "step": 10464
    },
    {
      "epoch": 3.8092067074439536e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5231,
      "step": 10496
    },
    {
      "epoch": 3.820820142527624e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5252,
      "step": 10528
    },
    {
      "epoch": 3.832433577611295e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5252,
      "step": 10560
    },
    {
      "epoch": 3.844047012694965e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.537,
      "step": 10592
    },
    {
      "epoch": 3.8556604477786356e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5373,
      "step": 10624
    },
    {
      "epoch": 3.867273882862306e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5436,
      "step": 10656
    },
    {
      "epoch": 3.878887317945977e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5316,
      "step": 10688
    },
    {
      "epoch": 3.8905007530296476e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5082,
      "step": 10720
    },
    {
      "epoch": 3.902114188113318e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5176,
      "step": 10752
    },
    {
      "epoch": 3.913727623196989e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5086,
      "step": 10784
    },
    {
      "epoch": 3.9253410582806596e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5114,
      "step": 10816
    },
    {
      "epoch": 3.93695449336433e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5285,
      "step": 10848
    },
    {
      "epoch": 3.948567928448e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5071,
      "step": 10880
    },
    {
      "epoch": 3.960181363531671e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5254,
      "step": 10912
    },
    {
      "epoch": 3.9717947986153416e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5224,
      "step": 10944
    },
    {
      "epoch": 3.983408233699012e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5281,
      "step": 10976
    },
    {
      "epoch": 3.995021668782683e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5223,
      "step": 11008
    },
    {
      "epoch": 4.0066351038663536e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5182,
      "step": 11040
    },
    {
      "epoch": 4.018248538950024e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5325,
      "step": 11072
    },
    {
      "epoch": 4.029861974033695e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.54,
      "step": 11104
    },
    {
      "epoch": 4.041475409117365e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5283,
      "step": 11136
    },
    {
      "epoch": 4.0530888442010356e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5229,
      "step": 11168
    },
    {
      "epoch": 4.064702279284706e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5115,
      "step": 11200
    },
    {
      "epoch": 4.076315714368377e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.522,
      "step": 11232
    },
    {
      "epoch": 4.0879291494520476e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 11264
    },
    {
      "epoch": 4.099542584535718e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5254,
      "step": 11296
    },
    {
      "epoch": 4.111156019619389e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5097,
      "step": 11328
    },
    {
      "epoch": 4.1227694547030596e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5281,
      "step": 11360
    },
    {
      "epoch": 4.13438288978673e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5095,
      "step": 11392
    },
    {
      "epoch": 4.1459963248704e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5376,
      "step": 11424
    },
    {
      "epoch": 4.157609759954071e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5347,
      "step": 11456
    },
    {
      "epoch": 4.1692231950377416e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5299,
      "step": 11488
    },
    {
      "epoch": 4.180836630121412e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.532,
      "step": 11520
    },
    {
      "epoch": 4.192450065205083e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5356,
      "step": 11552
    },
    {
      "epoch": 4.2040635002887536e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5124,
      "step": 11584
    },
    {
      "epoch": 4.215676935372424e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5195,
      "step": 11616
    },
    {
      "epoch": 4.227290370456095e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5033,
      "step": 11648
    },
    {
      "epoch": 4.2389038055397656e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5124,
      "step": 11680
    },
    {
      "epoch": 4.2505172406234356e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5292,
      "step": 11712
    },
    {
      "epoch": 4.262130675707106e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5332,
      "step": 11744
    },
    {
      "epoch": 4.273744110790777e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5172,
      "step": 11776
    },
    {
      "epoch": 4.2853575458744476e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5186,
      "step": 11808
    },
    {
      "epoch": 4.296970980958118e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5275,
      "step": 11840
    },
    {
      "epoch": 4.308584416041789e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5374,
      "step": 11872
    },
    {
      "epoch": 4.3201978511254596e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5195,
      "step": 11904
    },
    {
      "epoch": 4.33181128620913e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5366,
      "step": 11936
    },
    {
      "epoch": 4.3434247212928e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5255,
      "step": 11968
    },
    {
      "epoch": 4.355038156376471e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5346,
      "step": 12000
    },
    {
      "epoch": 4.3666515914601416e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5335,
      "step": 12032
    },
    {
      "epoch": 4.378265026543812e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.518,
      "step": 12064
    },
    {
      "epoch": 4.389878461627483e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5126,
      "step": 12096
    },
    {
      "epoch": 4.4014918967111537e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5149,
      "step": 12128
    },
    {
      "epoch": 4.413105331794824e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5159,
      "step": 12160
    },
    {
      "epoch": 4.424718766878495e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5192,
      "step": 12192
    },
    {
      "epoch": 4.4363322019621657e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5246,
      "step": 12224
    },
    {
      "epoch": 4.4479456370458356e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5015,
      "step": 12256
    },
    {
      "epoch": 4.459559072129506e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5354,
      "step": 12288
    },
    {
      "epoch": 4.471172507213177e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5482,
      "step": 12320
    },
    {
      "epoch": 4.4827859422968477e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5386,
      "step": 12352
    },
    {
      "epoch": 4.494399377380518e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5342,
      "step": 12384
    },
    {
      "epoch": 4.506012812464189e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5173,
      "step": 12416
    },
    {
      "epoch": 4.51762624754786e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5424,
      "step": 12448
    },
    {
      "epoch": 4.52923968263153e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5152,
      "step": 12480
    },
    {
      "epoch": 4.5408531177152e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5167,
      "step": 12512
    },
    {
      "epoch": 4.552466552798871e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5166,
      "step": 12544
    },
    {
      "epoch": 4.5640799878825417e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4968,
      "step": 12576
    },
    {
      "epoch": 4.575693422966212e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5327,
      "step": 12608
    },
    {
      "epoch": 4.587306858049883e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.525,
      "step": 12640
    },
    {
      "epoch": 4.598920293133554e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5207,
      "step": 12672
    },
    {
      "epoch": 4.610533728217224e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5107,
      "step": 12704
    },
    {
      "epoch": 4.622147163300895e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5102,
      "step": 12736
    },
    {
      "epoch": 4.633760598384566e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5302,
      "step": 12768
    },
    {
      "epoch": 4.645374033468236e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5261,
      "step": 12800
    },
    {
      "epoch": 4.656987468551906e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5334,
      "step": 12832
    },
    {
      "epoch": 4.668600903635577e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5255,
      "step": 12864
    },
    {
      "epoch": 4.680214338719248e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5404,
      "step": 12896
    },
    {
      "epoch": 4.691827773802918e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5325,
      "step": 12928
    },
    {
      "epoch": 4.703441208886589e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5261,
      "step": 12960
    },
    {
      "epoch": 4.71505464397026e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5287,
      "step": 12992
    },
    {
      "epoch": 4.7266680790539303e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4975,
      "step": 13024
    },
    {
      "epoch": 4.738281514137601e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5173,
      "step": 13056
    },
    {
      "epoch": 4.749894949221271e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5219,
      "step": 13088
    },
    {
      "epoch": 4.761508384304942e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.521,
      "step": 13120
    },
    {
      "epoch": 4.7731218193886123e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5248,
      "step": 13152
    },
    {
      "epoch": 4.784735254472283e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5206,
      "step": 13184
    },
    {
      "epoch": 4.796348689555954e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5479,
      "step": 13216
    },
    {
      "epoch": 4.8079621246396243e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5313,
      "step": 13248
    },
    {
      "epoch": 4.819575559723295e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5269,
      "step": 13280
    },
    {
      "epoch": 4.831188994806966e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5107,
      "step": 13312
    },
    {
      "epoch": 4.842802429890636e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5119,
      "step": 13344
    },
    {
      "epoch": 4.8544158649743063e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5163,
      "step": 13376
    },
    {
      "epoch": 4.866029300057977e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.518,
      "step": 13408
    },
    {
      "epoch": 4.877642735141648e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5267,
      "step": 13440
    },
    {
      "epoch": 4.8892561702253184e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5084,
      "step": 13472
    },
    {
      "epoch": 4.900869605308989e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5301,
      "step": 13504
    },
    {
      "epoch": 4.91248304039266e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5324,
      "step": 13536
    },
    {
      "epoch": 4.9240964754763304e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5267,
      "step": 13568
    },
    {
      "epoch": 4.935709910560001e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5269,
      "step": 13600
    },
    {
      "epoch": 4.947323345643671e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5165,
      "step": 13632
    },
    {
      "epoch": 4.958936780727342e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5197,
      "step": 13664
    },
    {
      "epoch": 4.9705502158110124e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5403,
      "step": 13696
    },
    {
      "epoch": 4.982163650894683e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5312,
      "step": 13728
    },
    {
      "epoch": 4.993777085978354e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5248,
      "step": 13760
    },
    {
      "epoch": 5.0053905210620244e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5262,
      "step": 13792
    },
    {
      "epoch": 5.017003956145695e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5324,
      "step": 13824
    },
    {
      "epoch": 5.028617391229366e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5323,
      "step": 13856
    },
    {
      "epoch": 5.040230826313036e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.513,
      "step": 13888
    },
    {
      "epoch": 5.0518442613967064e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4844,
      "step": 13920
    },
    {
      "epoch": 5.063457696480377e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5128,
      "step": 13952
    },
    {
      "epoch": 5.075071131564048e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5204,
      "step": 13984
    },
    {
      "epoch": 5.0866845666477184e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5294,
      "step": 14016
    },
    {
      "epoch": 5.098298001731389e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.549,
      "step": 14048
    },
    {
      "epoch": 5.10991143681506e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5261,
      "step": 14080
    },
    {
      "epoch": 5.1215248718987304e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 14112
    },
    {
      "epoch": 5.133138306982401e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5364,
      "step": 14144
    },
    {
      "epoch": 5.144751742066071e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5202,
      "step": 14176
    },
    {
      "epoch": 5.156365177149742e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5379,
      "step": 14208
    },
    {
      "epoch": 5.1679786122334124e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4922,
      "step": 14240
    },
    {
      "epoch": 5.179592047317083e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5223,
      "step": 14272
    },
    {
      "epoch": 5.191205482400754e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5323,
      "step": 14304
    },
    {
      "epoch": 5.2028189174844244e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5154,
      "step": 14336
    },
    {
      "epoch": 5.214432352568095e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5111,
      "step": 14368
    },
    {
      "epoch": 5.226045787651766e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5157,
      "step": 14400
    },
    {
      "epoch": 5.2376592227354364e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.53,
      "step": 14432
    },
    {
      "epoch": 5.2492726578191064e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5219,
      "step": 14464
    },
    {
      "epoch": 5.260886092902777e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5176,
      "step": 14496
    },
    {
      "epoch": 5.272499527986448e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.512,
      "step": 14528
    },
    {
      "epoch": 5.2841129630701184e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5174,
      "step": 14560
    },
    {
      "epoch": 5.295726398153789e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5382,
      "step": 14592
    },
    {
      "epoch": 5.30733983323746e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.528,
      "step": 14624
    },
    {
      "epoch": 5.3189532683211304e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5486,
      "step": 14656
    },
    {
      "epoch": 5.330566703404801e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5369,
      "step": 14688
    },
    {
      "epoch": 5.342180138488471e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.528,
      "step": 14720
    },
    {
      "epoch": 5.353793573572142e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5197,
      "step": 14752
    },
    {
      "epoch": 5.3654070086558124e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5135,
      "step": 14784
    },
    {
      "epoch": 5.377020443739483e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4975,
      "step": 14816
    },
    {
      "epoch": 5.388633878823154e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5087,
      "step": 14848
    },
    {
      "epoch": 5.4002473139068244e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5463,
      "step": 14880
    },
    {
      "epoch": 5.411860748990495e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5358,
      "step": 14912
    },
    {
      "epoch": 5.423474184074166e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5321,
      "step": 14944
    },
    {
      "epoch": 5.4350876191578364e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5283,
      "step": 14976
    },
    {
      "epoch": 5.4467010542415064e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5185,
      "step": 15008
    },
    {
      "epoch": 5.458314489325177e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5262,
      "step": 15040
    },
    {
      "epoch": 5.469927924408848e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5192,
      "step": 15072
    },
    {
      "epoch": 5.4815413594925184e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5099,
      "step": 15104
    },
    {
      "epoch": 5.493154794576189e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.519,
      "step": 15136
    },
    {
      "epoch": 5.50476822965986e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5206,
      "step": 15168
    },
    {
      "epoch": 5.5163816647435304e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 15200
    },
    {
      "epoch": 5.527995099827201e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5189,
      "step": 15232
    },
    {
      "epoch": 5.539608534910871e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5156,
      "step": 15264
    },
    {
      "epoch": 5.551221969994542e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5302,
      "step": 15296
    },
    {
      "epoch": 5.5628354050782124e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5179,
      "step": 15328
    },
    {
      "epoch": 5.574448840161883e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5236,
      "step": 15360
    },
    {
      "epoch": 5.586062275245554e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5285,
      "step": 15392
    },
    {
      "epoch": 5.5976757103292244e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.516,
      "step": 15424
    },
    {
      "epoch": 5.609289145412895e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5321,
      "step": 15456
    },
    {
      "epoch": 5.620902580496566e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5243,
      "step": 15488
    },
    {
      "epoch": 5.6325160155802364e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5326,
      "step": 15520
    },
    {
      "epoch": 5.6441294506639064e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5504,
      "step": 15552
    },
    {
      "epoch": 5.655742885747577e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5287,
      "step": 15584
    },
    {
      "epoch": 5.667356320831248e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5154,
      "step": 15616
    },
    {
      "epoch": 5.6789697559149184e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5204,
      "step": 15648
    },
    {
      "epoch": 5.690583190998589e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.493,
      "step": 15680
    },
    {
      "epoch": 5.70219662608226e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5067,
      "step": 15712
    },
    {
      "epoch": 5.7138100611659304e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5358,
      "step": 15744
    },
    {
      "epoch": 5.725423496249601e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.531,
      "step": 15776
    },
    {
      "epoch": 5.737036931333272e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5381,
      "step": 15808
    },
    {
      "epoch": 5.748650366416942e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5261,
      "step": 15840
    },
    {
      "epoch": 5.7602638015006124e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5299,
      "step": 15872
    },
    {
      "epoch": 5.771877236584283e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5198,
      "step": 15904
    },
    {
      "epoch": 5.783490671667954e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5195,
      "step": 15936
    },
    {
      "epoch": 5.7951041067516244e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5142,
      "step": 15968
    },
    {
      "epoch": 5.806717541835295e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5316,
      "step": 16000
    },
    {
      "epoch": 5.818330976918966e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5269,
      "step": 16032
    },
    {
      "epoch": 5.8299444120026364e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.526,
      "step": 16064
    },
    {
      "epoch": 5.8415578470863064e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.516,
      "step": 16096
    },
    {
      "epoch": 5.853171282169977e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5215,
      "step": 16128
    },
    {
      "epoch": 5.864784717253648e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5166,
      "step": 16160
    },
    {
      "epoch": 5.8763981523373184e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5271,
      "step": 16192
    },
    {
      "epoch": 5.888011587420989e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5176,
      "step": 16224
    },
    {
      "epoch": 5.89962502250466e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5228,
      "step": 16256
    },
    {
      "epoch": 5.9112384575883304e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5062,
      "step": 16288
    },
    {
      "epoch": 5.922851892672001e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5314,
      "step": 16320
    },
    {
      "epoch": 5.934465327755672e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5244,
      "step": 16352
    },
    {
      "epoch": 5.946078762839342e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5368,
      "step": 16384
    },
    {
      "epoch": 5.9576921979230124e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5323,
      "step": 16416
    },
    {
      "epoch": 5.969305633006683e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5423,
      "step": 16448
    },
    {
      "epoch": 5.980919068090354e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 16480
    },
    {
      "epoch": 5.9925325031740244e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5323,
      "step": 16512
    },
    {
      "epoch": 6.004145938257695e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.498,
      "step": 16544
    },
    {
      "epoch": 6.015759373341366e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5134,
      "step": 16576
    },
    {
      "epoch": 6.0273728084250364e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5214,
      "step": 16608
    },
    {
      "epoch": 6.0389862435087064e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5408,
      "step": 16640
    },
    {
      "epoch": 6.050599678592377e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5299,
      "step": 16672
    },
    {
      "epoch": 6.062213113676048e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5137,
      "step": 16704
    },
    {
      "epoch": 6.0738265487597184e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5259,
      "step": 16736
    },
    {
      "epoch": 6.085439983843389e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.523,
      "step": 16768
    },
    {
      "epoch": 6.09705341892706e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5239,
      "step": 16800
    },
    {
      "epoch": 6.10866685401073e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5239,
      "step": 16832
    },
    {
      "epoch": 6.120280289094401e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5103,
      "step": 16864
    },
    {
      "epoch": 6.131893724178071e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5325,
      "step": 16896
    },
    {
      "epoch": 6.143507159261742e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5311,
      "step": 16928
    },
    {
      "epoch": 6.155120594345412e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5277,
      "step": 16960
    },
    {
      "epoch": 6.166734029429084e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.513,
      "step": 16992
    },
    {
      "epoch": 6.178347464512754e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5103,
      "step": 17024
    },
    {
      "epoch": 6.189960899596424e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.531,
      "step": 17056
    },
    {
      "epoch": 6.201574334680095e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5319,
      "step": 17088
    },
    {
      "epoch": 6.213187769763765e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.524,
      "step": 17120
    },
    {
      "epoch": 6.224801204847436e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5157,
      "step": 17152
    },
    {
      "epoch": 6.236414639931106e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5145,
      "step": 17184
    },
    {
      "epoch": 6.248028075014778e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5322,
      "step": 17216
    },
    {
      "epoch": 6.259641510098448e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5424,
      "step": 17248
    },
    {
      "epoch": 6.271254945182119e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5346,
      "step": 17280
    },
    {
      "epoch": 6.282868380265789e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5154,
      "step": 17312
    },
    {
      "epoch": 6.294481815349459e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5307,
      "step": 17344
    },
    {
      "epoch": 6.30609525043313e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5258,
      "step": 17376
    },
    {
      "epoch": 6.3177086855168e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5079,
      "step": 17408
    },
    {
      "epoch": 6.329322120600472e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5162,
      "step": 17440
    },
    {
      "epoch": 6.340935555684142e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4966,
      "step": 17472
    },
    {
      "epoch": 6.352548990767813e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.537,
      "step": 17504
    },
    {
      "epoch": 6.364162425851483e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5306,
      "step": 17536
    },
    {
      "epoch": 6.375775860935154e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5315,
      "step": 17568
    },
    {
      "epoch": 6.387389296018824e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.512,
      "step": 17600
    },
    {
      "epoch": 6.399002731102494e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.515,
      "step": 17632
    },
    {
      "epoch": 6.410616166186166e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5254,
      "step": 17664
    },
    {
      "epoch": 6.422229601269836e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5278,
      "step": 17696
    },
    {
      "epoch": 6.433843036353507e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5255,
      "step": 17728
    },
    {
      "epoch": 6.445456471437177e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5206,
      "step": 17760
    },
    {
      "epoch": 6.457069906520848e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5274,
      "step": 17792
    },
    {
      "epoch": 6.468683341604518e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.539,
      "step": 17824
    },
    {
      "epoch": 6.48029677668819e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5245,
      "step": 17856
    },
    {
      "epoch": 6.49191021177186e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5217,
      "step": 17888
    },
    {
      "epoch": 6.50352364685553e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4999,
      "step": 17920
    },
    {
      "epoch": 6.515137081939201e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5258,
      "step": 17952
    },
    {
      "epoch": 6.526750517022871e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5329,
      "step": 17984
    },
    {
      "epoch": 6.538363952106542e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5185,
      "step": 18016
    },
    {
      "epoch": 6.549977387190212e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5103,
      "step": 18048
    },
    {
      "epoch": 6.561590822273884e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5072,
      "step": 18080
    },
    {
      "epoch": 6.573204257357554e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.544,
      "step": 18112
    },
    {
      "epoch": 6.584817692441225e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5493,
      "step": 18144
    },
    {
      "epoch": 6.596431127524895e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5293,
      "step": 18176
    },
    {
      "epoch": 6.608044562608565e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5152,
      "step": 18208
    },
    {
      "epoch": 6.619657997692236e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5288,
      "step": 18240
    },
    {
      "epoch": 6.631271432775906e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5219,
      "step": 18272
    },
    {
      "epoch": 6.642884867859578e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5247,
      "step": 18304
    },
    {
      "epoch": 6.654498302943248e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5382,
      "step": 18336
    },
    {
      "epoch": 6.666111738026919e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4962,
      "step": 18368
    },
    {
      "epoch": 6.677725173110589e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.525,
      "step": 18400
    },
    {
      "epoch": 6.689338608194259e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5388,
      "step": 18432
    },
    {
      "epoch": 6.70095204327793e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5179,
      "step": 18464
    },
    {
      "epoch": 6.7125654783616e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5226,
      "step": 18496
    },
    {
      "epoch": 6.724178913445272e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.498,
      "step": 18528
    },
    {
      "epoch": 6.735792348528942e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5284,
      "step": 18560
    },
    {
      "epoch": 6.747405783612613e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5339,
      "step": 18592
    },
    {
      "epoch": 6.759019218696283e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5178,
      "step": 18624
    },
    {
      "epoch": 6.770632653779954e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.522,
      "step": 18656
    },
    {
      "epoch": 6.782246088863624e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5206,
      "step": 18688
    },
    {
      "epoch": 6.793859523947294e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5352,
      "step": 18720
    },
    {
      "epoch": 6.805472959030966e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.531,
      "step": 18752
    },
    {
      "epoch": 6.817086394114636e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5162,
      "step": 18784
    },
    {
      "epoch": 6.828699829198307e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.505,
      "step": 18816
    },
    {
      "epoch": 6.840313264281977e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.521,
      "step": 18848
    },
    {
      "epoch": 6.851926699365649e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.539,
      "step": 18880
    },
    {
      "epoch": 6.863540134449318e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.515,
      "step": 18912
    },
    {
      "epoch": 6.87515356953299e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5262,
      "step": 18944
    },
    {
      "epoch": 6.88676700461666e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5157,
      "step": 18976
    },
    {
      "epoch": 6.89838043970033e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5428,
      "step": 19008
    },
    {
      "epoch": 6.909993874784001e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5335,
      "step": 19040
    },
    {
      "epoch": 6.921607309867671e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5207,
      "step": 19072
    },
    {
      "epoch": 6.933220744951343e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5295,
      "step": 19104
    },
    {
      "epoch": 6.944834180035012e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5103,
      "step": 19136
    },
    {
      "epoch": 6.956447615118684e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 19168
    },
    {
      "epoch": 6.968061050202354e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5323,
      "step": 19200
    },
    {
      "epoch": 6.979674485286025e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5123,
      "step": 19232
    },
    {
      "epoch": 6.991287920369695e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5058,
      "step": 19264
    },
    {
      "epoch": 7.002901355453365e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5255,
      "step": 19296
    },
    {
      "epoch": 7.014514790537037e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5267,
      "step": 19328
    },
    {
      "epoch": 7.026128225620706e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5232,
      "step": 19360
    },
    {
      "epoch": 7.037741660704378e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5112,
      "step": 19392
    },
    {
      "epoch": 7.049355095788048e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5208,
      "step": 19424
    },
    {
      "epoch": 7.060968530871719e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5262,
      "step": 19456
    },
    {
      "epoch": 7.072581965955389e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5357,
      "step": 19488
    },
    {
      "epoch": 7.08419540103906e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5285,
      "step": 19520
    },
    {
      "epoch": 7.09580883612273e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5233,
      "step": 19552
    },
    {
      "epoch": 7.1074222712064e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5362,
      "step": 19584
    },
    {
      "epoch": 7.119035706290072e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5275,
      "step": 19616
    },
    {
      "epoch": 7.130649141373742e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.527,
      "step": 19648
    },
    {
      "epoch": 7.142262576457413e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.518,
      "step": 19680
    },
    {
      "epoch": 7.153876011541083e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5013,
      "step": 19712
    },
    {
      "epoch": 7.165489446624755e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5244,
      "step": 19744
    },
    {
      "epoch": 7.177102881708425e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5147,
      "step": 19776
    },
    {
      "epoch": 7.188716316792095e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.519,
      "step": 19808
    },
    {
      "epoch": 7.200329751875766e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5274,
      "step": 19840
    },
    {
      "epoch": 7.211943186959436e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5335,
      "step": 19872
    },
    {
      "epoch": 7.223556622043107e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.525,
      "step": 19904
    },
    {
      "epoch": 7.235170057126777e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5261,
      "step": 19936
    },
    {
      "epoch": 7.246783492210449e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5208,
      "step": 19968
    },
    {
      "epoch": 7.258396927294119e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5347,
      "step": 20000
    },
    {
      "epoch": 7.27001036237779e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5342,
      "step": 20032
    },
    {
      "epoch": 7.28162379746146e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5287,
      "step": 20064
    },
    {
      "epoch": 7.29323723254513e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5282,
      "step": 20096
    },
    {
      "epoch": 7.304850667628801e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5128,
      "step": 20128
    },
    {
      "epoch": 7.316464102712471e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5062,
      "step": 20160
    },
    {
      "epoch": 7.328077537796143e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5326,
      "step": 20192
    },
    {
      "epoch": 7.339690972879813e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5157,
      "step": 20224
    },
    {
      "epoch": 7.351304407963484e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.513,
      "step": 20256
    },
    {
      "epoch": 7.362917843047154e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5228,
      "step": 20288
    },
    {
      "epoch": 7.374531278130825e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5262,
      "step": 20320
    },
    {
      "epoch": 7.386144713214495e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5298,
      "step": 20352
    },
    {
      "epoch": 7.397758148298165e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5162,
      "step": 20384
    },
    {
      "epoch": 7.409371583381837e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5166,
      "step": 20416
    },
    {
      "epoch": 7.420985018465507e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5349,
      "step": 20448
    },
    {
      "epoch": 7.432598453549178e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 20480
    },
    {
      "epoch": 7.444211888632848e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5267,
      "step": 20512
    },
    {
      "epoch": 7.455825323716519e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5174,
      "step": 20544
    },
    {
      "epoch": 7.467438758800189e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5186,
      "step": 20576
    },
    {
      "epoch": 7.47905219388386e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.516,
      "step": 20608
    },
    {
      "epoch": 7.49066562896753e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5276,
      "step": 20640
    },
    {
      "epoch": 7.5022790640512e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5217,
      "step": 20672
    },
    {
      "epoch": 7.513892499134872e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5239,
      "step": 20704
    },
    {
      "epoch": 7.525505934218542e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.526,
      "step": 20736
    },
    {
      "epoch": 7.537119369302213e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.537,
      "step": 20768
    },
    {
      "epoch": 7.548732804385883e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5337,
      "step": 20800
    },
    {
      "epoch": 7.560346239469555e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5072,
      "step": 20832
    },
    {
      "epoch": 7.571959674553225e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5283,
      "step": 20864
    },
    {
      "epoch": 7.583573109636895e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5473,
      "step": 20896
    },
    {
      "epoch": 7.595186544720566e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.537,
      "step": 20928
    },
    {
      "epoch": 7.606799979804236e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5222,
      "step": 20960
    },
    {
      "epoch": 7.618413414887907e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4991,
      "step": 20992
    },
    {
      "epoch": 7.630026849971577e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5098,
      "step": 21024
    },
    {
      "epoch": 7.641640285055249e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5071,
      "step": 21056
    },
    {
      "epoch": 7.653253720138919e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5322,
      "step": 21088
    },
    {
      "epoch": 7.66486715522259e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5161,
      "step": 21120
    },
    {
      "epoch": 7.67648059030626e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5106,
      "step": 21152
    },
    {
      "epoch": 7.68809402538993e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5309,
      "step": 21184
    },
    {
      "epoch": 7.699707460473601e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5327,
      "step": 21216
    },
    {
      "epoch": 7.711320895557271e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5326,
      "step": 21248
    },
    {
      "epoch": 7.722934330640943e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5304,
      "step": 21280
    },
    {
      "epoch": 7.734547765724613e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5065,
      "step": 21312
    },
    {
      "epoch": 7.746161200808284e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5539,
      "step": 21344
    },
    {
      "epoch": 7.757774635891954e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5358,
      "step": 21376
    },
    {
      "epoch": 7.769388070975625e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.526,
      "step": 21408
    },
    {
      "epoch": 7.781001506059295e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5165,
      "step": 21440
    },
    {
      "epoch": 7.792614941142965e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5052,
      "step": 21472
    },
    {
      "epoch": 7.804228376226637e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5159,
      "step": 21504
    },
    {
      "epoch": 7.815841811310307e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5349,
      "step": 21536
    },
    {
      "epoch": 7.827455246393978e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5212,
      "step": 21568
    },
    {
      "epoch": 7.839068681477648e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5085,
      "step": 21600
    },
    {
      "epoch": 7.850682116561319e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5098,
      "step": 21632
    },
    {
      "epoch": 7.862295551644989e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5375,
      "step": 21664
    },
    {
      "epoch": 7.87390898672866e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5215,
      "step": 21696
    },
    {
      "epoch": 7.88552242181233e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5338,
      "step": 21728
    },
    {
      "epoch": 7.897135856896e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5212,
      "step": 21760
    },
    {
      "epoch": 7.908749291979672e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5536,
      "step": 21792
    },
    {
      "epoch": 7.920362727063342e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5348,
      "step": 21824
    },
    {
      "epoch": 7.931976162147013e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5255,
      "step": 21856
    },
    {
      "epoch": 7.943589597230683e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5077,
      "step": 21888
    },
    {
      "epoch": 7.955203032314355e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4897,
      "step": 21920
    },
    {
      "epoch": 7.966816467398025e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5293,
      "step": 21952
    },
    {
      "epoch": 7.978429902481696e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5216,
      "step": 21984
    },
    {
      "epoch": 7.990043337565366e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5266,
      "step": 22016
    },
    {
      "epoch": 8.001656772649036e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5161,
      "step": 22048
    },
    {
      "epoch": 8.013270207732707e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5111,
      "step": 22080
    },
    {
      "epoch": 8.024883642816377e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5363,
      "step": 22112
    },
    {
      "epoch": 8.036497077900049e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.527,
      "step": 22144
    },
    {
      "epoch": 8.048110512983719e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5201,
      "step": 22176
    },
    {
      "epoch": 8.05972394806739e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5087,
      "step": 22208
    },
    {
      "epoch": 8.07133738315106e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5393,
      "step": 22240
    },
    {
      "epoch": 8.08295081823473e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.539,
      "step": 22272
    },
    {
      "epoch": 8.094564253318401e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5342,
      "step": 22304
    },
    {
      "epoch": 8.106177688402071e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5157,
      "step": 22336
    },
    {
      "epoch": 8.117791123485743e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4952,
      "step": 22368
    },
    {
      "epoch": 8.129404558569413e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5391,
      "step": 22400
    },
    {
      "epoch": 8.141017993653084e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.535,
      "step": 22432
    },
    {
      "epoch": 8.152631428736754e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5228,
      "step": 22464
    },
    {
      "epoch": 8.164244863820425e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4995,
      "step": 22496
    },
    {
      "epoch": 8.175858298904095e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5205,
      "step": 22528
    },
    {
      "epoch": 8.187471733987765e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5284,
      "step": 22560
    },
    {
      "epoch": 8.199085169071437e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5297,
      "step": 22592
    },
    {
      "epoch": 8.210698604155107e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5458,
      "step": 22624
    },
    {
      "epoch": 8.222312039238778e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5261,
      "step": 22656
    },
    {
      "epoch": 8.233925474322448e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5259,
      "step": 22688
    },
    {
      "epoch": 8.245538909406119e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5353,
      "step": 22720
    },
    {
      "epoch": 8.257152344489789e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5152,
      "step": 22752
    },
    {
      "epoch": 8.26876577957346e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5045,
      "step": 22784
    },
    {
      "epoch": 8.28037921465713e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4878,
      "step": 22816
    },
    {
      "epoch": 8.2919926497408e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5184,
      "step": 22848
    },
    {
      "epoch": 8.303606084824472e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5378,
      "step": 22880
    },
    {
      "epoch": 8.315219519908142e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5244,
      "step": 22912
    },
    {
      "epoch": 8.326832954991813e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5232,
      "step": 22944
    },
    {
      "epoch": 8.338446390075483e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5157,
      "step": 22976
    },
    {
      "epoch": 8.350059825159155e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.535,
      "step": 23008
    },
    {
      "epoch": 8.361673260242825e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5392,
      "step": 23040
    },
    {
      "epoch": 8.373286695326496e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5198,
      "step": 23072
    },
    {
      "epoch": 8.384900130410166e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5238,
      "step": 23104
    },
    {
      "epoch": 8.396513565493836e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.533,
      "step": 23136
    },
    {
      "epoch": 8.408127000577507e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.531,
      "step": 23168
    },
    {
      "epoch": 8.419740435661177e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.531,
      "step": 23200
    },
    {
      "epoch": 8.431353870744849e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5172,
      "step": 23232
    },
    {
      "epoch": 8.442967305828519e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5098,
      "step": 23264
    },
    {
      "epoch": 8.45458074091219e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5257,
      "step": 23296
    },
    {
      "epoch": 8.46619417599586e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5237,
      "step": 23328
    },
    {
      "epoch": 8.477807611079531e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5002,
      "step": 23360
    },
    {
      "epoch": 8.489421046163201e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5151,
      "step": 23392
    },
    {
      "epoch": 8.501034481246871e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5056,
      "step": 23424
    },
    {
      "epoch": 8.512647916330543e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5411,
      "step": 23456
    },
    {
      "epoch": 8.524261351414213e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5482,
      "step": 23488
    },
    {
      "epoch": 8.535874786497884e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5403,
      "step": 23520
    },
    {
      "epoch": 8.547488221581554e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5249,
      "step": 23552
    },
    {
      "epoch": 8.559101656665225e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5387,
      "step": 23584
    },
    {
      "epoch": 8.570715091748895e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.523,
      "step": 23616
    },
    {
      "epoch": 8.582328526832565e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5158,
      "step": 23648
    },
    {
      "epoch": 8.593941961916237e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4967,
      "step": 23680
    },
    {
      "epoch": 8.605555396999907e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5114,
      "step": 23712
    },
    {
      "epoch": 8.617168832083578e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5191,
      "step": 23744
    },
    {
      "epoch": 8.628782267167248e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5285,
      "step": 23776
    },
    {
      "epoch": 8.640395702250919e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5267,
      "step": 23808
    },
    {
      "epoch": 8.652009137334589e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5188,
      "step": 23840
    },
    {
      "epoch": 8.66362257241826e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5235,
      "step": 23872
    },
    {
      "epoch": 8.67523600750193e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5212,
      "step": 23904
    },
    {
      "epoch": 8.6868494425856e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5245,
      "step": 23936
    },
    {
      "epoch": 8.698462877669272e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5273,
      "step": 23968
    },
    {
      "epoch": 8.710076312752942e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5283,
      "step": 24000
    },
    {
      "epoch": 8.721689747836613e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5354,
      "step": 24032
    },
    {
      "epoch": 8.733303182920283e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5236,
      "step": 24064
    },
    {
      "epoch": 8.744916618003955e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5296,
      "step": 24096
    },
    {
      "epoch": 8.756530053087625e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5267,
      "step": 24128
    },
    {
      "epoch": 8.768143488171296e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.522,
      "step": 24160
    },
    {
      "epoch": 8.779756923254966e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.52,
      "step": 24192
    },
    {
      "epoch": 8.791370358338636e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5162,
      "step": 24224
    },
    {
      "epoch": 8.802983793422307e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5061,
      "step": 24256
    },
    {
      "epoch": 8.814597228505977e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5203,
      "step": 24288
    },
    {
      "epoch": 8.826210663589649e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5339,
      "step": 24320
    },
    {
      "epoch": 8.837824098673319e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5352,
      "step": 24352
    },
    {
      "epoch": 8.84943753375699e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5394,
      "step": 24384
    },
    {
      "epoch": 8.86105096884066e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.529,
      "step": 24416
    },
    {
      "epoch": 8.872664403924331e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5379,
      "step": 24448
    },
    {
      "epoch": 8.884277839008001e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5232,
      "step": 24480
    },
    {
      "epoch": 8.895891274091671e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5073,
      "step": 24512
    },
    {
      "epoch": 8.907504709175343e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5028,
      "step": 24544
    },
    {
      "epoch": 8.919118144259013e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.511,
      "step": 24576
    },
    {
      "epoch": 8.930731579342684e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5137,
      "step": 24608
    },
    {
      "epoch": 8.942345014426354e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5336,
      "step": 24640
    },
    {
      "epoch": 8.953958449510025e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5207,
      "step": 24672
    },
    {
      "epoch": 8.965571884593695e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5261,
      "step": 24704
    },
    {
      "epoch": 8.977185319677367e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5259,
      "step": 24736
    },
    {
      "epoch": 8.988798754761037e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5252,
      "step": 24768
    },
    {
      "epoch": 9.000412189844707e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5326,
      "step": 24800
    },
    {
      "epoch": 9.012025624928378e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5138,
      "step": 24832
    },
    {
      "epoch": 9.023639060012048e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5285,
      "step": 24864
    },
    {
      "epoch": 9.03525249509572e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5469,
      "step": 24896
    },
    {
      "epoch": 9.046865930179389e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5266,
      "step": 24928
    },
    {
      "epoch": 9.05847936526306e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5246,
      "step": 24960
    },
    {
      "epoch": 9.07009280034673e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5184,
      "step": 24992
    },
    {
      "epoch": 9.0817062354304e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5302,
      "step": 25024
    },
    {
      "epoch": 9.093319670514072e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5055,
      "step": 25056
    },
    {
      "epoch": 9.104933105597742e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5203,
      "step": 25088
    },
    {
      "epoch": 9.116546540681413e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5063,
      "step": 25120
    },
    {
      "epoch": 9.128159975765083e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5077,
      "step": 25152
    },
    {
      "epoch": 9.139773410848755e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5365,
      "step": 25184
    },
    {
      "epoch": 9.151386845932425e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5426,
      "step": 25216
    },
    {
      "epoch": 9.163000281016096e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5347,
      "step": 25248
    },
    {
      "epoch": 9.174613716099766e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5229,
      "step": 25280
    },
    {
      "epoch": 9.186227151183436e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5284,
      "step": 25312
    },
    {
      "epoch": 9.197840586267107e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5346,
      "step": 25344
    },
    {
      "epoch": 9.209454021350777e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5306,
      "step": 25376
    },
    {
      "epoch": 9.221067456434449e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5091,
      "step": 25408
    },
    {
      "epoch": 9.232680891518119e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4926,
      "step": 25440
    },
    {
      "epoch": 9.24429432660179e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5283,
      "step": 25472
    },
    {
      "epoch": 9.25590776168546e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5163,
      "step": 25504
    },
    {
      "epoch": 9.267521196769131e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5261,
      "step": 25536
    },
    {
      "epoch": 9.279134631852801e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5288,
      "step": 25568
    },
    {
      "epoch": 9.290748066936471e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5099,
      "step": 25600
    },
    {
      "epoch": 9.302361502020143e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5316,
      "step": 25632
    },
    {
      "epoch": 9.313974937103813e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5246,
      "step": 25664
    },
    {
      "epoch": 9.325588372187484e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5232,
      "step": 25696
    },
    {
      "epoch": 9.337201807271154e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5218,
      "step": 25728
    },
    {
      "epoch": 9.348815242354825e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5212,
      "step": 25760
    },
    {
      "epoch": 9.360428677438495e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5368,
      "step": 25792
    },
    {
      "epoch": 9.372042112522167e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5444,
      "step": 25824
    },
    {
      "epoch": 9.383655547605837e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5344,
      "step": 25856
    },
    {
      "epoch": 9.395268982689507e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.517,
      "step": 25888
    },
    {
      "epoch": 9.406882417773178e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5143,
      "step": 25920
    },
    {
      "epoch": 9.418495852856848e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5149,
      "step": 25952
    },
    {
      "epoch": 9.43010928794052e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.527,
      "step": 25984
    },
    {
      "epoch": 9.44172272302419e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5108,
      "step": 26016
    },
    {
      "epoch": 9.453336158107861e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5119,
      "step": 26048
    },
    {
      "epoch": 9.464949593191531e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5469,
      "step": 26080
    },
    {
      "epoch": 9.476563028275202e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5334,
      "step": 26112
    },
    {
      "epoch": 9.488176463358872e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5343,
      "step": 26144
    },
    {
      "epoch": 9.499789898442542e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5253,
      "step": 26176
    },
    {
      "epoch": 9.511403333526213e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.504,
      "step": 26208
    },
    {
      "epoch": 9.523016768609883e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5444,
      "step": 26240
    },
    {
      "epoch": 9.534630203693555e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.505,
      "step": 26272
    },
    {
      "epoch": 9.546243638777225e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5068,
      "step": 26304
    },
    {
      "epoch": 9.557857073860896e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5192,
      "step": 26336
    },
    {
      "epoch": 9.569470508944566e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.505,
      "step": 26368
    },
    {
      "epoch": 9.581083944028236e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5262,
      "step": 26400
    },
    {
      "epoch": 9.592697379111907e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5349,
      "step": 26432
    },
    {
      "epoch": 9.604310814195577e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5255,
      "step": 26464
    },
    {
      "epoch": 9.615924249279249e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5133,
      "step": 26496
    },
    {
      "epoch": 9.627537684362919e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5206,
      "step": 26528
    },
    {
      "epoch": 9.63915111944659e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5318,
      "step": 26560
    },
    {
      "epoch": 9.65076455453026e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5315,
      "step": 26592
    },
    {
      "epoch": 9.662377989613931e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5158,
      "step": 26624
    },
    {
      "epoch": 9.673991424697601e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5182,
      "step": 26656
    },
    {
      "epoch": 9.685604859781271e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5458,
      "step": 26688
    },
    {
      "epoch": 9.697218294864943e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5377,
      "step": 26720
    },
    {
      "epoch": 9.708831729948613e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5296,
      "step": 26752
    },
    {
      "epoch": 9.720445165032284e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5101,
      "step": 26784
    },
    {
      "epoch": 9.732058600115954e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5039,
      "step": 26816
    },
    {
      "epoch": 9.743672035199625e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5093,
      "step": 26848
    },
    {
      "epoch": 9.755285470283295e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5232,
      "step": 26880
    },
    {
      "epoch": 9.766898905366967e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5246,
      "step": 26912
    },
    {
      "epoch": 9.778512340450637e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5325,
      "step": 26944
    },
    {
      "epoch": 9.790125775534307e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5161,
      "step": 26976
    },
    {
      "epoch": 9.801739210617978e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5441,
      "step": 27008
    },
    {
      "epoch": 9.813352645701648e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5312,
      "step": 27040
    },
    {
      "epoch": 9.82496608078532e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5231,
      "step": 27072
    },
    {
      "epoch": 9.83657951586899e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.513,
      "step": 27104
    },
    {
      "epoch": 9.848192950952661e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5233,
      "step": 27136
    },
    {
      "epoch": 9.859806386036331e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5354,
      "step": 27168
    },
    {
      "epoch": 9.871419821120002e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5179,
      "step": 27200
    },
    {
      "epoch": 9.883033256203672e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5263,
      "step": 27232
    },
    {
      "epoch": 9.894646691287342e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5137,
      "step": 27264
    },
    {
      "epoch": 9.906260126371013e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5206,
      "step": 27296
    },
    {
      "epoch": 9.917873561454683e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5343,
      "step": 27328
    },
    {
      "epoch": 9.929486996538355e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.524,
      "step": 27360
    },
    {
      "epoch": 9.941100431622025e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5251,
      "step": 27392
    },
    {
      "epoch": 9.952713866705696e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5055,
      "step": 27424
    },
    {
      "epoch": 9.964327301789366e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5273,
      "step": 27456
    },
    {
      "epoch": 9.975940736873037e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5237,
      "step": 27488
    },
    {
      "epoch": 9.987554171956707e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5237,
      "step": 27520
    },
    {
      "epoch": 9.999167607040377e-05,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5331,
      "step": 27552
    },
    {
      "epoch": 0.00010010781042124049,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5428,
      "step": 27584
    },
    {
      "epoch": 0.00010022394477207719,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5351,
      "step": 27616
    },
    {
      "epoch": 0.0001003400791229139,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5256,
      "step": 27648
    },
    {
      "epoch": 0.0001004562134737506,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5185,
      "step": 27680
    },
    {
      "epoch": 0.00010057234782458731,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.492,
      "step": 27712
    },
    {
      "epoch": 0.00010068848217542401,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5129,
      "step": 27744
    },
    {
      "epoch": 0.00010080461652626071,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5391,
      "step": 27776
    },
    {
      "epoch": 0.00010092075087709743,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5268,
      "step": 27808
    },
    {
      "epoch": 0.00010103688522793413,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5365,
      "step": 27840
    },
    {
      "epoch": 0.00010115301957877084,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5185,
      "step": 27872
    },
    {
      "epoch": 0.00010126915392960754,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5267,
      "step": 27904
    },
    {
      "epoch": 0.00010138528828044425,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.523,
      "step": 27936
    },
    {
      "epoch": 0.00010150142263128095,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5239,
      "step": 27968
    },
    {
      "epoch": 0.00010161755698211767,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5115,
      "step": 28000
    },
    {
      "epoch": 0.00010173369133295437,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5233,
      "step": 28032
    },
    {
      "epoch": 0.00010184982568379107,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5166,
      "step": 28064
    },
    {
      "epoch": 0.00010196596003462778,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5279,
      "step": 28096
    },
    {
      "epoch": 0.00010208209438546448,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.522,
      "step": 28128
    },
    {
      "epoch": 0.0001021982287363012,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5139,
      "step": 28160
    },
    {
      "epoch": 0.0001023143630871379,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5245,
      "step": 28192
    },
    {
      "epoch": 0.00010243049743797461,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5303,
      "step": 28224
    },
    {
      "epoch": 0.00010254663178881131,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5278,
      "step": 28256
    },
    {
      "epoch": 0.00010266276613964802,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5228,
      "step": 28288
    },
    {
      "epoch": 0.00010277890049048472,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5206,
      "step": 28320
    },
    {
      "epoch": 0.00010289503484132142,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5212,
      "step": 28352
    },
    {
      "epoch": 0.00010301116919215813,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5155,
      "step": 28384
    },
    {
      "epoch": 0.00010312730354299483,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5495,
      "step": 28416
    },
    {
      "epoch": 0.00010324343789383155,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5369,
      "step": 28448
    },
    {
      "epoch": 0.00010335957224466825,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5314,
      "step": 28480
    },
    {
      "epoch": 0.00010347570659550496,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5123,
      "step": 28512
    },
    {
      "epoch": 0.00010359184094634166,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5302,
      "step": 28544
    },
    {
      "epoch": 0.00010370797529717837,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5059,
      "step": 28576
    },
    {
      "epoch": 0.00010382410964801507,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5066,
      "step": 28608
    },
    {
      "epoch": 0.00010394024399885177,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.52,
      "step": 28640
    },
    {
      "epoch": 0.00010405637834968849,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.528,
      "step": 28672
    },
    {
      "epoch": 0.00010417251270052519,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5282,
      "step": 28704
    },
    {
      "epoch": 0.0001042886470513619,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5278,
      "step": 28736
    },
    {
      "epoch": 0.0001044047814021986,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5204,
      "step": 28768
    },
    {
      "epoch": 0.00010452091575303531,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5228,
      "step": 28800
    },
    {
      "epoch": 0.00010463705010387201,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5222,
      "step": 28832
    },
    {
      "epoch": 0.00010475318445470873,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.528,
      "step": 28864
    },
    {
      "epoch": 0.00010486931880554543,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5238,
      "step": 28896
    },
    {
      "epoch": 0.00010498545315638213,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5403,
      "step": 28928
    },
    {
      "epoch": 0.00010510158750721884,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5095,
      "step": 28960
    },
    {
      "epoch": 0.00010521772185805554,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5212,
      "step": 28992
    },
    {
      "epoch": 0.00010533385620889225,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5331,
      "step": 29024
    },
    {
      "epoch": 0.00010544999055972895,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5037,
      "step": 29056
    },
    {
      "epoch": 0.00010556612491056567,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5275,
      "step": 29088
    },
    {
      "epoch": 0.00010568225926140237,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5175,
      "step": 29120
    },
    {
      "epoch": 0.00010579839361223907,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 29152
    },
    {
      "epoch": 0.00010591452796307578,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5228,
      "step": 29184
    },
    {
      "epoch": 0.00010603066231391248,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5083,
      "step": 29216
    },
    {
      "epoch": 0.0001061467966647492,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5198,
      "step": 29248
    },
    {
      "epoch": 0.0001062629310155859,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5239,
      "step": 29280
    },
    {
      "epoch": 0.00010637906536642261,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5451,
      "step": 29312
    },
    {
      "epoch": 0.00010649519971725931,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5314,
      "step": 29344
    },
    {
      "epoch": 0.00010661133406809602,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5355,
      "step": 29376
    },
    {
      "epoch": 0.00010672746841893272,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5122,
      "step": 29408
    },
    {
      "epoch": 0.00010684360276976942,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4986,
      "step": 29440
    },
    {
      "epoch": 0.00010695973712060613,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5123,
      "step": 29472
    },
    {
      "epoch": 0.00010707587147144283,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5237,
      "step": 29504
    },
    {
      "epoch": 0.00010719200582227955,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5085,
      "step": 29536
    },
    {
      "epoch": 0.00010730814017311625,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4856,
      "step": 29568
    },
    {
      "epoch": 0.00010742427452395296,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5101,
      "step": 29600
    },
    {
      "epoch": 0.00010754040887478966,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5028,
      "step": 29632
    },
    {
      "epoch": 0.00010765654322562637,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5162,
      "step": 29664
    },
    {
      "epoch": 0.00010777267757646307,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4978,
      "step": 29696
    },
    {
      "epoch": 0.00010788881192729977,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4932,
      "step": 29728
    },
    {
      "epoch": 0.00010800494627813649,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5178,
      "step": 29760
    },
    {
      "epoch": 0.00010812108062897319,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5061,
      "step": 29792
    },
    {
      "epoch": 0.0001082372149798099,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4944,
      "step": 29824
    },
    {
      "epoch": 0.0001083533493306466,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4888,
      "step": 29856
    },
    {
      "epoch": 0.00010846948368148331,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5149,
      "step": 29888
    },
    {
      "epoch": 0.00010858561803232001,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5275,
      "step": 29920
    },
    {
      "epoch": 0.00010870175238315673,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5514,
      "step": 29952
    },
    {
      "epoch": 0.00010881788673399343,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5479,
      "step": 29984
    },
    {
      "epoch": 0.00010893402108483013,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5448,
      "step": 30016
    },
    {
      "epoch": 0.00010905015543566684,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5383,
      "step": 30048
    },
    {
      "epoch": 0.00010916628978650354,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5469,
      "step": 30080
    },
    {
      "epoch": 0.00010928242413734025,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5555,
      "step": 30112
    },
    {
      "epoch": 0.00010939855848817695,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5345,
      "step": 30144
    },
    {
      "epoch": 0.00010951469283901367,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5286,
      "step": 30176
    },
    {
      "epoch": 0.00010963082718985037,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5121,
      "step": 30208
    },
    {
      "epoch": 0.00010974696154068708,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5014,
      "step": 30240
    },
    {
      "epoch": 0.00010986309589152378,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5021,
      "step": 30272
    },
    {
      "epoch": 0.00010997923024236048,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5001,
      "step": 30304
    },
    {
      "epoch": 0.0001100953645931972,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.506,
      "step": 30336
    },
    {
      "epoch": 0.0001102114989440339,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5105,
      "step": 30368
    },
    {
      "epoch": 0.00011032763329487061,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4994,
      "step": 30400
    },
    {
      "epoch": 0.00011044376764570731,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5159,
      "step": 30432
    },
    {
      "epoch": 0.00011055990199654402,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5095,
      "step": 30464
    },
    {
      "epoch": 0.00011067603634738072,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5014,
      "step": 30496
    },
    {
      "epoch": 0.00011079217069821742,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5189,
      "step": 30528
    },
    {
      "epoch": 0.00011090830504905413,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4998,
      "step": 30560
    },
    {
      "epoch": 0.00011102443939989083,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4961,
      "step": 30592
    },
    {
      "epoch": 0.00011114057375072755,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5081,
      "step": 30624
    },
    {
      "epoch": 0.00011125670810156425,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5132,
      "step": 30656
    },
    {
      "epoch": 0.00011137284245240096,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5393,
      "step": 30688
    },
    {
      "epoch": 0.00011148897680323766,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5379,
      "step": 30720
    },
    {
      "epoch": 0.00011160511115407437,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5439,
      "step": 30752
    },
    {
      "epoch": 0.00011172124550491107,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5466,
      "step": 30784
    },
    {
      "epoch": 0.00011183737985574777,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5382,
      "step": 30816
    },
    {
      "epoch": 0.00011195351420658449,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5526,
      "step": 30848
    },
    {
      "epoch": 0.00011206964855742119,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5443,
      "step": 30880
    },
    {
      "epoch": 0.0001121857829082579,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5428,
      "step": 30912
    },
    {
      "epoch": 0.0001123019172590946,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5006,
      "step": 30944
    },
    {
      "epoch": 0.00011241805160993131,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5082,
      "step": 30976
    },
    {
      "epoch": 0.00011253418596076801,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5074,
      "step": 31008
    },
    {
      "epoch": 0.00011265032031160473,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5109,
      "step": 31040
    },
    {
      "epoch": 0.00011276645466244143,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5072,
      "step": 31072
    },
    {
      "epoch": 0.00011288258901327813,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4944,
      "step": 31104
    },
    {
      "epoch": 0.00011299872336411484,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.49,
      "step": 31136
    },
    {
      "epoch": 0.00011311485771495154,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5046,
      "step": 31168
    },
    {
      "epoch": 0.00011323099206578825,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5313,
      "step": 31200
    },
    {
      "epoch": 0.00011334712641662495,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5197,
      "step": 31232
    },
    {
      "epoch": 0.00011346326076746167,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.509,
      "step": 31264
    },
    {
      "epoch": 0.00011357939511829837,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5117,
      "step": 31296
    },
    {
      "epoch": 0.00011369552946913508,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.502,
      "step": 31328
    },
    {
      "epoch": 0.00011381166381997178,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4963,
      "step": 31360
    },
    {
      "epoch": 0.00011392779817080848,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5137,
      "step": 31392
    },
    {
      "epoch": 0.0001140439325216452,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4924,
      "step": 31424
    },
    {
      "epoch": 0.0001141600668724819,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5415,
      "step": 31456
    },
    {
      "epoch": 0.00011427620122331861,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5416,
      "step": 31488
    },
    {
      "epoch": 0.00011439233557415531,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5505,
      "step": 31520
    },
    {
      "epoch": 0.00011450846992499202,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5441,
      "step": 31552
    },
    {
      "epoch": 0.00011462460427582872,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5305,
      "step": 31584
    },
    {
      "epoch": 0.00011474073862666544,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5407,
      "step": 31616
    },
    {
      "epoch": 0.00011485687297750213,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5512,
      "step": 31648
    },
    {
      "epoch": 0.00011497300732833883,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5326,
      "step": 31680
    },
    {
      "epoch": 0.00011508914167917555,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5099,
      "step": 31712
    },
    {
      "epoch": 0.00011520527603001225,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5048,
      "step": 31744
    },
    {
      "epoch": 0.00011532141038084896,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5154,
      "step": 31776
    },
    {
      "epoch": 0.00011543754473168566,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5076,
      "step": 31808
    },
    {
      "epoch": 0.00011555367908252238,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5125,
      "step": 31840
    },
    {
      "epoch": 0.00011566981343335907,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4997,
      "step": 31872
    },
    {
      "epoch": 0.00011578594778419577,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4955,
      "step": 31904
    },
    {
      "epoch": 0.00011590208213503249,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5151,
      "step": 31936
    },
    {
      "epoch": 0.00011601821648586919,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5218,
      "step": 31968
    },
    {
      "epoch": 0.0001161343508367059,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4951,
      "step": 32000
    },
    {
      "epoch": 0.0001162504851875426,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5051,
      "step": 32032
    },
    {
      "epoch": 0.00011636661953837932,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5168,
      "step": 32064
    },
    {
      "epoch": 0.00011648275388921602,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5177,
      "step": 32096
    },
    {
      "epoch": 0.00011659888824005273,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.499,
      "step": 32128
    },
    {
      "epoch": 0.00011671502259088943,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5144,
      "step": 32160
    },
    {
      "epoch": 0.00011683115694172613,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4975,
      "step": 32192
    },
    {
      "epoch": 0.00011694729129256284,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5416,
      "step": 32224
    },
    {
      "epoch": 0.00011706342564339954,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5461,
      "step": 32256
    },
    {
      "epoch": 0.00011717955999423626,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5368,
      "step": 32288
    },
    {
      "epoch": 0.00011729569434507296,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5455,
      "step": 32320
    },
    {
      "epoch": 0.00011741182869590967,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5414,
      "step": 32352
    },
    {
      "epoch": 0.00011752796304674637,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.551,
      "step": 32384
    },
    {
      "epoch": 0.00011764409739758308,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5474,
      "step": 32416
    },
    {
      "epoch": 0.00011776023174841978,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5197,
      "step": 32448
    },
    {
      "epoch": 0.00011787636609925648,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5007,
      "step": 32480
    },
    {
      "epoch": 0.0001179925004500932,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5025,
      "step": 32512
    },
    {
      "epoch": 0.0001181086348009299,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5174,
      "step": 32544
    },
    {
      "epoch": 0.00011822476915176661,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5123,
      "step": 32576
    },
    {
      "epoch": 0.00011834090350260331,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5037,
      "step": 32608
    },
    {
      "epoch": 0.00011845703785344002,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4904,
      "step": 32640
    },
    {
      "epoch": 0.00011857317220427672,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4954,
      "step": 32672
    },
    {
      "epoch": 0.00011868930655511344,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5286,
      "step": 32704
    },
    {
      "epoch": 0.00011880544090595014,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5137,
      "step": 32736
    },
    {
      "epoch": 0.00011892157525678684,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.502,
      "step": 32768
    },
    {
      "epoch": 0.00011903770960762355,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4868,
      "step": 32800
    },
    {
      "epoch": 0.00011915384395846025,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5152,
      "step": 32832
    },
    {
      "epoch": 0.00011926997830929696,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4934,
      "step": 32864
    },
    {
      "epoch": 0.00011938611266013366,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5053,
      "step": 32896
    },
    {
      "epoch": 0.00011950224701097038,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5246,
      "step": 32928
    },
    {
      "epoch": 0.00011961838136180708,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5274,
      "step": 32960
    },
    {
      "epoch": 0.00011973451571264378,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5557,
      "step": 32992
    },
    {
      "epoch": 0.00011985065006348049,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5544,
      "step": 33024
    },
    {
      "epoch": 0.00011996678441431719,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5486,
      "step": 33056
    },
    {
      "epoch": 0.0001200829187651539,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5197,
      "step": 33088
    },
    {
      "epoch": 0.0001201990531159906,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5393,
      "step": 33120
    },
    {
      "epoch": 0.00012031518746682732,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5418,
      "step": 33152
    },
    {
      "epoch": 0.00012043132181766402,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5453,
      "step": 33184
    },
    {
      "epoch": 0.00012054745616850073,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5154,
      "step": 33216
    },
    {
      "epoch": 0.00012066359051933743,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4926,
      "step": 33248
    },
    {
      "epoch": 0.00012077972487017413,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5115,
      "step": 33280
    },
    {
      "epoch": 0.00012089585922101084,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5062,
      "step": 33312
    },
    {
      "epoch": 0.00012101199357184754,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5055,
      "step": 33344
    },
    {
      "epoch": 0.00012112812792268426,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4947,
      "step": 33376
    },
    {
      "epoch": 0.00012124426227352096,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.482,
      "step": 33408
    },
    {
      "epoch": 0.00012136039662435767,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5192,
      "step": 33440
    },
    {
      "epoch": 0.00012147653097519437,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5282,
      "step": 33472
    },
    {
      "epoch": 0.00012159266532603108,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5101,
      "step": 33504
    },
    {
      "epoch": 0.00012170879967686778,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5089,
      "step": 33536
    },
    {
      "epoch": 0.00012182493402770448,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5059,
      "step": 33568
    },
    {
      "epoch": 0.0001219410683785412,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5282,
      "step": 33600
    },
    {
      "epoch": 0.0001220572027293779,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5019,
      "step": 33632
    },
    {
      "epoch": 0.0001221733370802146,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4945,
      "step": 33664
    },
    {
      "epoch": 0.00012228947143105132,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5148,
      "step": 33696
    },
    {
      "epoch": 0.00012240560578188802,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5241,
      "step": 33728
    },
    {
      "epoch": 0.00012252174013272472,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5538,
      "step": 33760
    },
    {
      "epoch": 0.00012263787448356142,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5603,
      "step": 33792
    },
    {
      "epoch": 0.00012275400883439812,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5478,
      "step": 33824
    },
    {
      "epoch": 0.00012287014318523485,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5366,
      "step": 33856
    },
    {
      "epoch": 0.00012298627753607155,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.547,
      "step": 33888
    },
    {
      "epoch": 0.00012310241188690825,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5363,
      "step": 33920
    },
    {
      "epoch": 0.00012321854623774495,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5191,
      "step": 33952
    },
    {
      "epoch": 0.00012333468058858168,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4997,
      "step": 33984
    },
    {
      "epoch": 0.00012345081493941838,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4962,
      "step": 34016
    },
    {
      "epoch": 0.00012356694929025508,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5166,
      "step": 34048
    },
    {
      "epoch": 0.00012368308364109178,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.514,
      "step": 34080
    },
    {
      "epoch": 0.00012379921799192848,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5122,
      "step": 34112
    },
    {
      "epoch": 0.0001239153523427652,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5026,
      "step": 34144
    },
    {
      "epoch": 0.0001240314866936019,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4914,
      "step": 34176
    },
    {
      "epoch": 0.0001241476210444386,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5142,
      "step": 34208
    },
    {
      "epoch": 0.0001242637553952753,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5183,
      "step": 34240
    },
    {
      "epoch": 0.00012437988974611203,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4982,
      "step": 34272
    },
    {
      "epoch": 0.00012449602409694873,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.521,
      "step": 34304
    },
    {
      "epoch": 0.00012461215844778543,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.502,
      "step": 34336
    },
    {
      "epoch": 0.00012472829279862213,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5161,
      "step": 34368
    },
    {
      "epoch": 0.00012484442714945883,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5016,
      "step": 34400
    },
    {
      "epoch": 0.00012496056150029556,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5164,
      "step": 34432
    },
    {
      "epoch": 0.00012507669585113226,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5119,
      "step": 34464
    },
    {
      "epoch": 0.00012519283020196896,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5432,
      "step": 34496
    },
    {
      "epoch": 0.00012530896455280566,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5288,
      "step": 34528
    },
    {
      "epoch": 0.00012542509890364238,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.542,
      "step": 34560
    },
    {
      "epoch": 0.00012554123325447908,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.533,
      "step": 34592
    },
    {
      "epoch": 0.00012565736760531578,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5527,
      "step": 34624
    },
    {
      "epoch": 0.00012577350195615248,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5628,
      "step": 34656
    },
    {
      "epoch": 0.00012588963630698918,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5559,
      "step": 34688
    },
    {
      "epoch": 0.0001260057706578259,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5264,
      "step": 34720
    },
    {
      "epoch": 0.0001261219050086626,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5168,
      "step": 34752
    },
    {
      "epoch": 0.0001262380393594993,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4925,
      "step": 34784
    },
    {
      "epoch": 0.000126354173710336,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.513,
      "step": 34816
    },
    {
      "epoch": 0.00012647030806117274,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4843,
      "step": 34848
    },
    {
      "epoch": 0.00012658644241200944,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5045,
      "step": 34880
    },
    {
      "epoch": 0.00012670257676284614,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5055,
      "step": 34912
    },
    {
      "epoch": 0.00012681871111368284,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4898,
      "step": 34944
    },
    {
      "epoch": 0.00012693484546451954,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5248,
      "step": 34976
    },
    {
      "epoch": 0.00012705097981535626,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5123,
      "step": 35008
    },
    {
      "epoch": 0.00012716711416619296,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5092,
      "step": 35040
    },
    {
      "epoch": 0.00012728324851702966,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5058,
      "step": 35072
    },
    {
      "epoch": 0.00012739938286786636,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.495,
      "step": 35104
    },
    {
      "epoch": 0.0001275155172187031,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4992,
      "step": 35136
    },
    {
      "epoch": 0.0001276316515695398,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4954,
      "step": 35168
    },
    {
      "epoch": 0.0001277477859203765,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.527,
      "step": 35200
    },
    {
      "epoch": 0.0001278639202712132,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5184,
      "step": 35232
    },
    {
      "epoch": 0.0001279800546220499,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5511,
      "step": 35264
    },
    {
      "epoch": 0.00012809618897288662,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5504,
      "step": 35296
    },
    {
      "epoch": 0.00012821232332372332,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5526,
      "step": 35328
    },
    {
      "epoch": 0.00012832845767456002,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5428,
      "step": 35360
    },
    {
      "epoch": 0.00012844459202539672,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5295,
      "step": 35392
    },
    {
      "epoch": 0.00012856072637623344,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5402,
      "step": 35424
    },
    {
      "epoch": 0.00012867686072707014,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5318,
      "step": 35456
    },
    {
      "epoch": 0.00012879299507790684,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5318,
      "step": 35488
    },
    {
      "epoch": 0.00012890912942874354,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5259,
      "step": 35520
    },
    {
      "epoch": 0.00012902526377958024,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5005,
      "step": 35552
    },
    {
      "epoch": 0.00012914139813041697,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5147,
      "step": 35584
    },
    {
      "epoch": 0.00012925753248125367,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5136,
      "step": 35616
    },
    {
      "epoch": 0.00012937366683209037,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5004,
      "step": 35648
    },
    {
      "epoch": 0.00012948980118292707,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4881,
      "step": 35680
    },
    {
      "epoch": 0.0001296059355337638,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4724,
      "step": 35712
    },
    {
      "epoch": 0.0001297220698846005,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5105,
      "step": 35744
    },
    {
      "epoch": 0.0001298382042354372,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.52,
      "step": 35776
    },
    {
      "epoch": 0.0001299543385862739,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5194,
      "step": 35808
    },
    {
      "epoch": 0.0001300704729371106,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5087,
      "step": 35840
    },
    {
      "epoch": 0.00013018660728794732,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5095,
      "step": 35872
    },
    {
      "epoch": 0.00013030274163878402,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5045,
      "step": 35904
    },
    {
      "epoch": 0.00013041887598962072,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5093,
      "step": 35936
    },
    {
      "epoch": 0.00013053501034045742,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5234,
      "step": 35968
    },
    {
      "epoch": 0.00013065114469129415,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5199,
      "step": 36000
    },
    {
      "epoch": 0.00013076727904213085,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5327,
      "step": 36032
    },
    {
      "epoch": 0.00013088341339296755,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5537,
      "step": 36064
    },
    {
      "epoch": 0.00013099954774380425,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5507,
      "step": 36096
    },
    {
      "epoch": 0.00013111568209464095,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5472,
      "step": 36128
    },
    {
      "epoch": 0.00013123181644547768,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5486,
      "step": 36160
    },
    {
      "epoch": 0.00013134795079631438,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5507,
      "step": 36192
    },
    {
      "epoch": 0.00013146408514715108,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5382,
      "step": 36224
    },
    {
      "epoch": 0.00013158021949798778,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5064,
      "step": 36256
    },
    {
      "epoch": 0.0001316963538488245,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4837,
      "step": 36288
    },
    {
      "epoch": 0.0001318124881996612,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4933,
      "step": 36320
    },
    {
      "epoch": 0.0001319286225504979,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.517,
      "step": 36352
    },
    {
      "epoch": 0.0001320447569013346,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.525,
      "step": 36384
    },
    {
      "epoch": 0.0001321608912521713,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5144,
      "step": 36416
    },
    {
      "epoch": 0.00013227702560300803,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4999,
      "step": 36448
    },
    {
      "epoch": 0.00013239315995384473,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5021,
      "step": 36480
    },
    {
      "epoch": 0.00013250929430468143,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5178,
      "step": 36512
    },
    {
      "epoch": 0.00013262542865551813,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5084,
      "step": 36544
    },
    {
      "epoch": 0.00013274156300635483,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5011,
      "step": 36576
    },
    {
      "epoch": 0.00013285769735719156,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.484,
      "step": 36608
    },
    {
      "epoch": 0.00013297383170802826,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5097,
      "step": 36640
    },
    {
      "epoch": 0.00013308996605886496,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5138,
      "step": 36672
    },
    {
      "epoch": 0.00013320610040970166,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5144,
      "step": 36704
    },
    {
      "epoch": 0.00013332223476053838,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5219,
      "step": 36736
    },
    {
      "epoch": 0.00013343836911137508,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5267,
      "step": 36768
    },
    {
      "epoch": 0.00013355450346221178,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5469,
      "step": 36800
    },
    {
      "epoch": 0.00013367063781304848,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5481,
      "step": 36832
    },
    {
      "epoch": 0.00013378677216388518,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5355,
      "step": 36864
    },
    {
      "epoch": 0.0001339029065147219,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5312,
      "step": 36896
    },
    {
      "epoch": 0.0001340190408655586,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5314,
      "step": 36928
    },
    {
      "epoch": 0.0001341351752163953,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.546,
      "step": 36960
    },
    {
      "epoch": 0.000134251309567232,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5428,
      "step": 36992
    },
    {
      "epoch": 0.00013436744391806874,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5233,
      "step": 37024
    },
    {
      "epoch": 0.00013448357826890544,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5083,
      "step": 37056
    },
    {
      "epoch": 0.00013459971261974214,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4953,
      "step": 37088
    },
    {
      "epoch": 0.00013471584697057884,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.515,
      "step": 37120
    },
    {
      "epoch": 0.00013483198132141554,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.499,
      "step": 37152
    },
    {
      "epoch": 0.00013494811567225226,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.494,
      "step": 37184
    },
    {
      "epoch": 0.00013506425002308896,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4928,
      "step": 37216
    },
    {
      "epoch": 0.00013518038437392566,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.526,
      "step": 37248
    },
    {
      "epoch": 0.00013529651872476236,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5247,
      "step": 37280
    },
    {
      "epoch": 0.0001354126530755991,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5111,
      "step": 37312
    },
    {
      "epoch": 0.0001355287874264358,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5145,
      "step": 37344
    },
    {
      "epoch": 0.0001356449217772725,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4941,
      "step": 37376
    },
    {
      "epoch": 0.0001357610561281092,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5002,
      "step": 37408
    },
    {
      "epoch": 0.0001358771904789459,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4835,
      "step": 37440
    },
    {
      "epoch": 0.00013599332482978262,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5127,
      "step": 37472
    },
    {
      "epoch": 0.00013610945918061932,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5082,
      "step": 37504
    },
    {
      "epoch": 0.00013622559353145602,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5378,
      "step": 37536
    },
    {
      "epoch": 0.00013634172788229272,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.551,
      "step": 37568
    },
    {
      "epoch": 0.00013645786223312944,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5519,
      "step": 37600
    },
    {
      "epoch": 0.00013657399658396614,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5476,
      "step": 37632
    },
    {
      "epoch": 0.00013669013093480284,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5471,
      "step": 37664
    },
    {
      "epoch": 0.00013680626528563954,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5396,
      "step": 37696
    },
    {
      "epoch": 0.00013692239963647624,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5502,
      "step": 37728
    },
    {
      "epoch": 0.00013703853398731297,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5239,
      "step": 37760
    },
    {
      "epoch": 0.00013715466833814967,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4957,
      "step": 37792
    },
    {
      "epoch": 0.00013727080268898637,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5031,
      "step": 37824
    },
    {
      "epoch": 0.00013738693703982307,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5088,
      "step": 37856
    },
    {
      "epoch": 0.0001375030713906598,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5225,
      "step": 37888
    },
    {
      "epoch": 0.0001376192057414965,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5086,
      "step": 37920
    },
    {
      "epoch": 0.0001377353400923332,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4908,
      "step": 37952
    },
    {
      "epoch": 0.0001378514744431699,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5056,
      "step": 37984
    },
    {
      "epoch": 0.0001379676087940066,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4969,
      "step": 38016
    },
    {
      "epoch": 0.00013808374314484332,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.509,
      "step": 38048
    },
    {
      "epoch": 0.00013819987749568002,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5214,
      "step": 38080
    },
    {
      "epoch": 0.00013831601184651672,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5148,
      "step": 38112
    },
    {
      "epoch": 0.00013843214619735342,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5053,
      "step": 38144
    },
    {
      "epoch": 0.00013854828054819015,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5078,
      "step": 38176
    },
    {
      "epoch": 0.00013866441489902685,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5085,
      "step": 38208
    },
    {
      "epoch": 0.00013878054924986355,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5174,
      "step": 38240
    },
    {
      "epoch": 0.00013889668360070025,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5229,
      "step": 38272
    },
    {
      "epoch": 0.00013901281795153695,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5354,
      "step": 38304
    },
    {
      "epoch": 0.00013912895230237368,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5509,
      "step": 38336
    },
    {
      "epoch": 0.00013924508665321038,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5406,
      "step": 38368
    },
    {
      "epoch": 0.00013936122100404708,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5422,
      "step": 38400
    },
    {
      "epoch": 0.00013947735535488378,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5518,
      "step": 38432
    },
    {
      "epoch": 0.0001395934897057205,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5362,
      "step": 38464
    },
    {
      "epoch": 0.0001397096240565572,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5538,
      "step": 38496
    },
    {
      "epoch": 0.0001398257584073939,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5083,
      "step": 38528
    },
    {
      "epoch": 0.0001399418927582306,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5067,
      "step": 38560
    },
    {
      "epoch": 0.0001400580271090673,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5096,
      "step": 38592
    },
    {
      "epoch": 0.00014017416145990403,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4924,
      "step": 38624
    },
    {
      "epoch": 0.00014029029581074073,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5027,
      "step": 38656
    },
    {
      "epoch": 0.00014040643016157743,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4982,
      "step": 38688
    },
    {
      "epoch": 0.00014052256451241413,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5018,
      "step": 38720
    },
    {
      "epoch": 0.00014063869886325086,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5132,
      "step": 38752
    },
    {
      "epoch": 0.00014075483321408756,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5185,
      "step": 38784
    },
    {
      "epoch": 0.00014087096756492426,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5089,
      "step": 38816
    },
    {
      "epoch": 0.00014098710191576096,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.516,
      "step": 38848
    },
    {
      "epoch": 0.00014110323626659766,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4948,
      "step": 38880
    },
    {
      "epoch": 0.00014121937061743438,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.513,
      "step": 38912
    },
    {
      "epoch": 0.00014133550496827108,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.509,
      "step": 38944
    },
    {
      "epoch": 0.00014145163931910778,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5134,
      "step": 38976
    },
    {
      "epoch": 0.00014156777366994448,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5251,
      "step": 39008
    },
    {
      "epoch": 0.0001416839080207812,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5481,
      "step": 39040
    },
    {
      "epoch": 0.0001418000423716179,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5315,
      "step": 39072
    },
    {
      "epoch": 0.0001419161767224546,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5467,
      "step": 39104
    },
    {
      "epoch": 0.0001420323110732913,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5336,
      "step": 39136
    },
    {
      "epoch": 0.000142148445424128,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.542,
      "step": 39168
    },
    {
      "epoch": 0.00014226457977496474,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5448,
      "step": 39200
    },
    {
      "epoch": 0.00014238071412580144,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5234,
      "step": 39232
    },
    {
      "epoch": 0.00014249684847663814,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5292,
      "step": 39264
    },
    {
      "epoch": 0.00014261298282747484,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5128,
      "step": 39296
    },
    {
      "epoch": 0.00014272911717831154,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.508,
      "step": 39328
    },
    {
      "epoch": 0.00014284525152914826,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5101,
      "step": 39360
    },
    {
      "epoch": 0.00014296138587998496,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.506,
      "step": 39392
    },
    {
      "epoch": 0.00014307752023082166,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5144,
      "step": 39424
    },
    {
      "epoch": 0.00014319365458165836,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5049,
      "step": 39456
    },
    {
      "epoch": 0.0001433097889324951,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5025,
      "step": 39488
    },
    {
      "epoch": 0.0001434259232833318,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5125,
      "step": 39520
    },
    {
      "epoch": 0.0001435420576341685,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4971,
      "step": 39552
    },
    {
      "epoch": 0.0001436581919850052,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5188,
      "step": 39584
    },
    {
      "epoch": 0.0001437743263358419,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5289,
      "step": 39616
    },
    {
      "epoch": 0.00014389046068667862,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5098,
      "step": 39648
    },
    {
      "epoch": 0.00014400659503751532,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4915,
      "step": 39680
    },
    {
      "epoch": 0.00014412272938835202,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4921,
      "step": 39712
    },
    {
      "epoch": 0.00014423886373918872,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.51,
      "step": 39744
    },
    {
      "epoch": 0.00014435499809002544,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5219,
      "step": 39776
    },
    {
      "epoch": 0.00014447113244086214,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5477,
      "step": 39808
    },
    {
      "epoch": 0.00014458726679169884,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5319,
      "step": 39840
    },
    {
      "epoch": 0.00014470340114253554,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5435,
      "step": 39872
    },
    {
      "epoch": 0.00014481953549337224,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5525,
      "step": 39904
    },
    {
      "epoch": 0.00014493566984420897,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5432,
      "step": 39936
    },
    {
      "epoch": 0.00014505180419504567,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5452,
      "step": 39968
    },
    {
      "epoch": 0.00014516793854588237,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5232,
      "step": 40000
    },
    {
      "epoch": 0.00014528407289671907,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5223,
      "step": 40032
    },
    {
      "epoch": 0.0001454002072475558,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.517,
      "step": 40064
    },
    {
      "epoch": 0.0001455163415983925,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5074,
      "step": 40096
    },
    {
      "epoch": 0.0001456324759492292,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.501,
      "step": 40128
    },
    {
      "epoch": 0.0001457486103000659,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4961,
      "step": 40160
    },
    {
      "epoch": 0.0001458647446509026,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5198,
      "step": 40192
    },
    {
      "epoch": 0.00014598087900173932,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.501,
      "step": 40224
    },
    {
      "epoch": 0.00014609701335257602,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5023,
      "step": 40256
    },
    {
      "epoch": 0.00014621314770341272,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5087,
      "step": 40288
    },
    {
      "epoch": 0.00014632928205424942,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5091,
      "step": 40320
    },
    {
      "epoch": 0.00014644541640508615,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5142,
      "step": 40352
    },
    {
      "epoch": 0.00014656155075592285,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4986,
      "step": 40384
    },
    {
      "epoch": 0.00014667768510675955,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.497,
      "step": 40416
    },
    {
      "epoch": 0.00014679381945759625,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4982,
      "step": 40448
    },
    {
      "epoch": 0.00014690995380843295,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5152,
      "step": 40480
    },
    {
      "epoch": 0.00014702608815926968,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5238,
      "step": 40512
    },
    {
      "epoch": 0.00014714222251010638,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5203,
      "step": 40544
    },
    {
      "epoch": 0.00014725835686094308,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5429,
      "step": 40576
    },
    {
      "epoch": 0.00014737449121177978,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5303,
      "step": 40608
    },
    {
      "epoch": 0.0001474906255626165,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5557,
      "step": 40640
    },
    {
      "epoch": 0.0001476067599134532,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5576,
      "step": 40672
    },
    {
      "epoch": 0.0001477228942642899,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5527,
      "step": 40704
    },
    {
      "epoch": 0.0001478390286151266,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5355,
      "step": 40736
    },
    {
      "epoch": 0.0001479551629659633,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5448,
      "step": 40768
    },
    {
      "epoch": 0.00014807129731680003,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.517,
      "step": 40800
    },
    {
      "epoch": 0.00014818743166763673,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5031,
      "step": 40832
    },
    {
      "epoch": 0.00014830356601847343,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4923,
      "step": 40864
    },
    {
      "epoch": 0.00014841970036931013,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4959,
      "step": 40896
    },
    {
      "epoch": 0.00014853583472014686,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5074,
      "step": 40928
    },
    {
      "epoch": 0.00014865196907098356,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5105,
      "step": 40960
    },
    {
      "epoch": 0.00014876810342182026,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.4839,
      "step": 40992
    },
    {
      "epoch": 0.00014888423777265696,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5021,
      "step": 41024
    },
    {
      "epoch": 0.00014900037212349366,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.514,
      "step": 41056
    },
    {
      "epoch": 0.00014911650647433038,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5131,
      "step": 41088
    },
    {
      "epoch": 0.00014923264082516708,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5206,
      "step": 41120
    },
    {
      "epoch": 0.00014934877517600378,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5125,
      "step": 41152
    },
    {
      "epoch": 0.00014946490952684048,
      "grad_norm": 3.953936225974965,
      "learning_rate": 0.002,
      "loss": 2.5117,
      "step": 41184
    },
    {
      "epoch": 0.0001495810438776772,
      "grad_norm": 0.28403663967624937,
      "learning_rate": 0.002,
      "loss": 2.4871,
      "step": 41216
    },
    {
      "epoch": 0.0001496971782285139,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 41248
    },
    {
      "epoch": 0.0001498133125793506,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 41280
    },
    {
      "epoch": 0.0001499294469301873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 41312
    },
    {
      "epoch": 0.000150045581281024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 41344
    },
    {
      "epoch": 0.00015016171563186074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 41376
    },
    {
      "epoch": 0.00015027784998269744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7102,
      "step": 41408
    },
    {
      "epoch": 0.00015039398433353414,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 41440
    },
    {
      "epoch": 0.00015051011868437084,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 41472
    },
    {
      "epoch": 0.00015062625303520756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 41504
    },
    {
      "epoch": 0.00015074238738604426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7302,
      "step": 41536
    },
    {
      "epoch": 0.00015085852173688096,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 41568
    },
    {
      "epoch": 0.00015097465608771766,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 41600
    },
    {
      "epoch": 0.00015109079043855436,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 41632
    },
    {
      "epoch": 0.0001512069247893911,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 41664
    },
    {
      "epoch": 0.0001513230591402278,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7365,
      "step": 41696
    },
    {
      "epoch": 0.0001514391934910645,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 41728
    },
    {
      "epoch": 0.0001515553278419012,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 41760
    },
    {
      "epoch": 0.0001516714621927379,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 41792
    },
    {
      "epoch": 0.00015178759654357462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 41824
    },
    {
      "epoch": 0.00015190373089441132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 41856
    },
    {
      "epoch": 0.00015201986524524802,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 41888
    },
    {
      "epoch": 0.00015213599959608472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 41920
    },
    {
      "epoch": 0.00015225213394692144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 41952
    },
    {
      "epoch": 0.00015236826829775814,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 41984
    },
    {
      "epoch": 0.00015248440264859484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 42016
    },
    {
      "epoch": 0.00015260053699943154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 42048
    },
    {
      "epoch": 0.00015271667135026824,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6916,
      "step": 42080
    },
    {
      "epoch": 0.00015283280570110497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6843,
      "step": 42112
    },
    {
      "epoch": 0.00015294894005194167,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 42144
    },
    {
      "epoch": 0.00015306507440277837,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 42176
    },
    {
      "epoch": 0.00015318120875361507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 42208
    },
    {
      "epoch": 0.0001532973431044518,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 42240
    },
    {
      "epoch": 0.0001534134774552885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 42272
    },
    {
      "epoch": 0.0001535296118061252,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7467,
      "step": 42304
    },
    {
      "epoch": 0.0001536457461569619,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7293,
      "step": 42336
    },
    {
      "epoch": 0.0001537618805077986,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 42368
    },
    {
      "epoch": 0.00015387801485863532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 42400
    },
    {
      "epoch": 0.00015399414920947202,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 42432
    },
    {
      "epoch": 0.00015411028356030872,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 42464
    },
    {
      "epoch": 0.00015422641791114542,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 42496
    },
    {
      "epoch": 0.00015434255226198215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 42528
    },
    {
      "epoch": 0.00015445868661281885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 42560
    },
    {
      "epoch": 0.00015457482096365555,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 42592
    },
    {
      "epoch": 0.00015469095531449225,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 42624
    },
    {
      "epoch": 0.00015480708966532895,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 42656
    },
    {
      "epoch": 0.00015492322401616568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6934,
      "step": 42688
    },
    {
      "epoch": 0.00015503935836700238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 42720
    },
    {
      "epoch": 0.00015515549271783908,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 42752
    },
    {
      "epoch": 0.00015527162706867578,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 42784
    },
    {
      "epoch": 0.0001553877614195125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 42816
    },
    {
      "epoch": 0.0001555038957703492,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6932,
      "step": 42848
    },
    {
      "epoch": 0.0001556200301211859,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 42880
    },
    {
      "epoch": 0.0001557361644720226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.691,
      "step": 42912
    },
    {
      "epoch": 0.0001558522988228593,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6909,
      "step": 42944
    },
    {
      "epoch": 0.00015596843317369603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6741,
      "step": 42976
    },
    {
      "epoch": 0.00015608456752453273,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6908,
      "step": 43008
    },
    {
      "epoch": 0.00015620070187536943,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 43040
    },
    {
      "epoch": 0.00015631683622620613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7315,
      "step": 43072
    },
    {
      "epoch": 0.00015643297057704286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7337,
      "step": 43104
    },
    {
      "epoch": 0.00015654910492787956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 43136
    },
    {
      "epoch": 0.00015666523927871626,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 43168
    },
    {
      "epoch": 0.00015678137362955296,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 43200
    },
    {
      "epoch": 0.00015689750798038966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.748,
      "step": 43232
    },
    {
      "epoch": 0.00015701364233122638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7363,
      "step": 43264
    },
    {
      "epoch": 0.00015712977668206308,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 43296
    },
    {
      "epoch": 0.00015724591103289978,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7323,
      "step": 43328
    },
    {
      "epoch": 0.00015736204538373648,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 43360
    },
    {
      "epoch": 0.0001574781797345732,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 43392
    },
    {
      "epoch": 0.0001575943140854099,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 43424
    },
    {
      "epoch": 0.0001577104484362466,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 43456
    },
    {
      "epoch": 0.0001578265827870833,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 43488
    },
    {
      "epoch": 0.00015794271713792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 43520
    },
    {
      "epoch": 0.00015805885148875674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 43552
    },
    {
      "epoch": 0.00015817498583959344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6902,
      "step": 43584
    },
    {
      "epoch": 0.00015829112019043014,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6866,
      "step": 43616
    },
    {
      "epoch": 0.00015840725454126684,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6907,
      "step": 43648
    },
    {
      "epoch": 0.00015852338889210356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6877,
      "step": 43680
    },
    {
      "epoch": 0.00015863952324294026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 43712
    },
    {
      "epoch": 0.00015875565759377696,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 43744
    },
    {
      "epoch": 0.00015887179194461366,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.674,
      "step": 43776
    },
    {
      "epoch": 0.00015898792629545036,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6897,
      "step": 43808
    },
    {
      "epoch": 0.0001591040606462871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 43840
    },
    {
      "epoch": 0.0001592201949971238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 43872
    },
    {
      "epoch": 0.0001593363293479605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 43904
    },
    {
      "epoch": 0.0001594524636987972,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 43936
    },
    {
      "epoch": 0.00015956859804963392,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 43968
    },
    {
      "epoch": 0.00015968473240047062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 44000
    },
    {
      "epoch": 0.00015980086675130732,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7509,
      "step": 44032
    },
    {
      "epoch": 0.00015991700110214402,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7302,
      "step": 44064
    },
    {
      "epoch": 0.00016003313545298072,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7443,
      "step": 44096
    },
    {
      "epoch": 0.00016014926980381745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 44128
    },
    {
      "epoch": 0.00016026540415465414,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 44160
    },
    {
      "epoch": 0.00016038153850549084,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6905,
      "step": 44192
    },
    {
      "epoch": 0.00016049767285632754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 44224
    },
    {
      "epoch": 0.00016061380720716427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 44256
    },
    {
      "epoch": 0.00016072994155800097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 44288
    },
    {
      "epoch": 0.00016084607590883767,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7325,
      "step": 44320
    },
    {
      "epoch": 0.00016096221025967437,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6936,
      "step": 44352
    },
    {
      "epoch": 0.00016107834461051107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.679,
      "step": 44384
    },
    {
      "epoch": 0.0001611944789613478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 44416
    },
    {
      "epoch": 0.0001613106133121845,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6864,
      "step": 44448
    },
    {
      "epoch": 0.0001614267476630212,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 44480
    },
    {
      "epoch": 0.0001615428820138579,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.689,
      "step": 44512
    },
    {
      "epoch": 0.0001616590163646946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6899,
      "step": 44544
    },
    {
      "epoch": 0.00016177515071553133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 44576
    },
    {
      "epoch": 0.00016189128506636803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 44608
    },
    {
      "epoch": 0.00016200741941720472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 44640
    },
    {
      "epoch": 0.00016212355376804142,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 44672
    },
    {
      "epoch": 0.00016223968811887815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6963,
      "step": 44704
    },
    {
      "epoch": 0.00016235582246971485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 44736
    },
    {
      "epoch": 0.00016247195682055155,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 44768
    },
    {
      "epoch": 0.00016258809117138825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7205,
      "step": 44800
    },
    {
      "epoch": 0.00016270422552222495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 44832
    },
    {
      "epoch": 0.00016282035987306168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7377,
      "step": 44864
    },
    {
      "epoch": 0.00016293649422389838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7411,
      "step": 44896
    },
    {
      "epoch": 0.00016305262857473508,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7353,
      "step": 44928
    },
    {
      "epoch": 0.00016316876292557178,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 44960
    },
    {
      "epoch": 0.0001632848972764085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 44992
    },
    {
      "epoch": 0.0001634010316272452,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 45024
    },
    {
      "epoch": 0.0001635171659780819,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 45056
    },
    {
      "epoch": 0.0001636333003289186,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 45088
    },
    {
      "epoch": 0.0001637494346797553,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6869,
      "step": 45120
    },
    {
      "epoch": 0.00016386556903059203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6837,
      "step": 45152
    },
    {
      "epoch": 0.00016398170338142873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6973,
      "step": 45184
    },
    {
      "epoch": 0.00016409783773226543,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 45216
    },
    {
      "epoch": 0.00016421397208310213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 45248
    },
    {
      "epoch": 0.00016433010643393886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6867,
      "step": 45280
    },
    {
      "epoch": 0.00016444624078477556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6881,
      "step": 45312
    },
    {
      "epoch": 0.00016456237513561226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 45344
    },
    {
      "epoch": 0.00016467850948644896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 45376
    },
    {
      "epoch": 0.00016479464383728566,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 45408
    },
    {
      "epoch": 0.00016491077818812239,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 45440
    },
    {
      "epoch": 0.00016502691253895909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 45472
    },
    {
      "epoch": 0.00016514304688979579,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7351,
      "step": 45504
    },
    {
      "epoch": 0.00016525918124063249,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 45536
    },
    {
      "epoch": 0.0001653753155914692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 45568
    },
    {
      "epoch": 0.0001654914499423059,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 45600
    },
    {
      "epoch": 0.0001656075842931426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 45632
    },
    {
      "epoch": 0.0001657237186439793,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7348,
      "step": 45664
    },
    {
      "epoch": 0.000165839852994816,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 45696
    },
    {
      "epoch": 0.00016595598734565274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 45728
    },
    {
      "epoch": 0.00016607212169648944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 45760
    },
    {
      "epoch": 0.00016618825604732614,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.739,
      "step": 45792
    },
    {
      "epoch": 0.00016630439039816284,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7542,
      "step": 45824
    },
    {
      "epoch": 0.00016642052474899957,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7237,
      "step": 45856
    },
    {
      "epoch": 0.00016653665909983627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.679,
      "step": 45888
    },
    {
      "epoch": 0.00016665279345067297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6826,
      "step": 45920
    },
    {
      "epoch": 0.00016676892780150967,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6887,
      "step": 45952
    },
    {
      "epoch": 0.00016688506215234637,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 45984
    },
    {
      "epoch": 0.0001670011965031831,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6996,
      "step": 46016
    },
    {
      "epoch": 0.0001671173308540198,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6889,
      "step": 46048
    },
    {
      "epoch": 0.0001672334652048565,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 46080
    },
    {
      "epoch": 0.0001673495995556932,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 46112
    },
    {
      "epoch": 0.00016746573390652992,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7013,
      "step": 46144
    },
    {
      "epoch": 0.00016758186825736662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 46176
    },
    {
      "epoch": 0.00016769800260820332,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 46208
    },
    {
      "epoch": 0.00016781413695904002,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 46240
    },
    {
      "epoch": 0.00016793027130987672,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 46272
    },
    {
      "epoch": 0.00016804640566071345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 46304
    },
    {
      "epoch": 0.00016816254001155015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 46336
    },
    {
      "epoch": 0.00016827867436238685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 46368
    },
    {
      "epoch": 0.00016839480871322355,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 46400
    },
    {
      "epoch": 0.00016851094306406027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 46432
    },
    {
      "epoch": 0.00016862707741489697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 46464
    },
    {
      "epoch": 0.00016874321176573367,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 46496
    },
    {
      "epoch": 0.00016885934611657037,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 46528
    },
    {
      "epoch": 0.00016897548046740707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 46560
    },
    {
      "epoch": 0.0001690916148182438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 46592
    },
    {
      "epoch": 0.0001692077491690805,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 46624
    },
    {
      "epoch": 0.0001693238835199172,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7076,
      "step": 46656
    },
    {
      "epoch": 0.0001694400178707539,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 46688
    },
    {
      "epoch": 0.00016955615222159063,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6878,
      "step": 46720
    },
    {
      "epoch": 0.00016967228657242733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6843,
      "step": 46752
    },
    {
      "epoch": 0.00016978842092326403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 46784
    },
    {
      "epoch": 0.00016990455527410073,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6807,
      "step": 46816
    },
    {
      "epoch": 0.00017002068962493743,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 46848
    },
    {
      "epoch": 0.00017013682397577415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 46880
    },
    {
      "epoch": 0.00017025295832661085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 46912
    },
    {
      "epoch": 0.00017036909267744755,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 46944
    },
    {
      "epoch": 0.00017048522702828425,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 46976
    },
    {
      "epoch": 0.00017060136137912098,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 47008
    },
    {
      "epoch": 0.00017071749572995768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 47040
    },
    {
      "epoch": 0.00017083363008079438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 47072
    },
    {
      "epoch": 0.00017094976443163108,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 47104
    },
    {
      "epoch": 0.00017106589878246778,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 47136
    },
    {
      "epoch": 0.0001711820331333045,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 47168
    },
    {
      "epoch": 0.0001712981674841412,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 47200
    },
    {
      "epoch": 0.0001714143018349779,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 47232
    },
    {
      "epoch": 0.0001715304361858146,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 47264
    },
    {
      "epoch": 0.0001716465705366513,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 47296
    },
    {
      "epoch": 0.00017176270488748803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 47328
    },
    {
      "epoch": 0.00017187883923832473,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 47360
    },
    {
      "epoch": 0.00017199497358916143,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 47392
    },
    {
      "epoch": 0.00017211110793999813,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 47424
    },
    {
      "epoch": 0.00017222724229083486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 47456
    },
    {
      "epoch": 0.00017234337664167156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 47488
    },
    {
      "epoch": 0.00017245951099250826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 47520
    },
    {
      "epoch": 0.00017257564534334496,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7297,
      "step": 47552
    },
    {
      "epoch": 0.00017269177969418166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 47584
    },
    {
      "epoch": 0.00017280791404501839,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 47616
    },
    {
      "epoch": 0.00017292404839585509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 47648
    },
    {
      "epoch": 0.00017304018274669179,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6897,
      "step": 47680
    },
    {
      "epoch": 0.00017315631709752849,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 47712
    },
    {
      "epoch": 0.0001732724514483652,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 47744
    },
    {
      "epoch": 0.0001733885857992019,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 47776
    },
    {
      "epoch": 0.0001735047201500386,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 47808
    },
    {
      "epoch": 0.0001736208545008753,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 47840
    },
    {
      "epoch": 0.000173736988851712,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 47872
    },
    {
      "epoch": 0.00017385312320254874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 47904
    },
    {
      "epoch": 0.00017396925755338544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 47936
    },
    {
      "epoch": 0.00017408539190422214,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6985,
      "step": 47968
    },
    {
      "epoch": 0.00017420152625505884,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 48000
    },
    {
      "epoch": 0.00017431766060589557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 48032
    },
    {
      "epoch": 0.00017443379495673227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 48064
    },
    {
      "epoch": 0.00017454992930756897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 48096
    },
    {
      "epoch": 0.00017466606365840567,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 48128
    },
    {
      "epoch": 0.00017478219800924237,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 48160
    },
    {
      "epoch": 0.0001748983323600791,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 48192
    },
    {
      "epoch": 0.0001750144667109158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6996,
      "step": 48224
    },
    {
      "epoch": 0.0001751306010617525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 48256
    },
    {
      "epoch": 0.0001752467354125892,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.692,
      "step": 48288
    },
    {
      "epoch": 0.00017536286976342592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7205,
      "step": 48320
    },
    {
      "epoch": 0.00017547900411426262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 48352
    },
    {
      "epoch": 0.00017559513846509932,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 48384
    },
    {
      "epoch": 0.00017571127281593602,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7359,
      "step": 48416
    },
    {
      "epoch": 0.00017582740716677272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 48448
    },
    {
      "epoch": 0.00017594354151760945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6913,
      "step": 48480
    },
    {
      "epoch": 0.00017605967586844615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 48512
    },
    {
      "epoch": 0.00017617581021928285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 48544
    },
    {
      "epoch": 0.00017629194457011955,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 48576
    },
    {
      "epoch": 0.00017640807892095627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 48608
    },
    {
      "epoch": 0.00017652421327179297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 48640
    },
    {
      "epoch": 0.00017664034762262967,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 48672
    },
    {
      "epoch": 0.00017675648197346637,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 48704
    },
    {
      "epoch": 0.00017687261632430307,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 48736
    },
    {
      "epoch": 0.0001769887506751398,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 48768
    },
    {
      "epoch": 0.0001771048850259765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 48800
    },
    {
      "epoch": 0.0001772210193768132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 48832
    },
    {
      "epoch": 0.0001773371537276499,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 48864
    },
    {
      "epoch": 0.00017745328807848663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 48896
    },
    {
      "epoch": 0.00017756942242932333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 48928
    },
    {
      "epoch": 0.00017768555678016003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6879,
      "step": 48960
    },
    {
      "epoch": 0.00017780169113099673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6781,
      "step": 48992
    },
    {
      "epoch": 0.00017791782548183343,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 49024
    },
    {
      "epoch": 0.00017803395983267015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 49056
    },
    {
      "epoch": 0.00017815009418350685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 49088
    },
    {
      "epoch": 0.00017826622853434355,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 49120
    },
    {
      "epoch": 0.00017838236288518025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 49152
    },
    {
      "epoch": 0.00017849849723601698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 49184
    },
    {
      "epoch": 0.00017861463158685368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 49216
    },
    {
      "epoch": 0.00017873076593769038,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7336,
      "step": 49248
    },
    {
      "epoch": 0.00017884690028852708,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 49280
    },
    {
      "epoch": 0.00017896303463936378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 49312
    },
    {
      "epoch": 0.0001790791689902005,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7334,
      "step": 49344
    },
    {
      "epoch": 0.0001791953033410372,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 49376
    },
    {
      "epoch": 0.0001793114376918739,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 49408
    },
    {
      "epoch": 0.0001794275720427106,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 49440
    },
    {
      "epoch": 0.00017954370639354733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7008,
      "step": 49472
    },
    {
      "epoch": 0.00017965984074438403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 49504
    },
    {
      "epoch": 0.00017977597509522073,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 49536
    },
    {
      "epoch": 0.00017989210944605743,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 49568
    },
    {
      "epoch": 0.00018000824379689413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 49600
    },
    {
      "epoch": 0.00018012437814773086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 49632
    },
    {
      "epoch": 0.00018024051249856756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 49664
    },
    {
      "epoch": 0.00018035664684940426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 49696
    },
    {
      "epoch": 0.00018047278120024096,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6887,
      "step": 49728
    },
    {
      "epoch": 0.0001805889155510777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6838,
      "step": 49760
    },
    {
      "epoch": 0.0001807050499019144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 49792
    },
    {
      "epoch": 0.00018082118425275109,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 49824
    },
    {
      "epoch": 0.00018093731860358779,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6954,
      "step": 49856
    },
    {
      "epoch": 0.00018105345295442449,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 49888
    },
    {
      "epoch": 0.0001811695873052612,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 49920
    },
    {
      "epoch": 0.0001812857216560979,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 49952
    },
    {
      "epoch": 0.0001814018560069346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 49984
    },
    {
      "epoch": 0.0001815179903577713,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 50016
    },
    {
      "epoch": 0.000181634124708608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 50048
    },
    {
      "epoch": 0.00018175025905944474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 50080
    },
    {
      "epoch": 0.00018186639341028144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7423,
      "step": 50112
    },
    {
      "epoch": 0.00018198252776111814,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.737,
      "step": 50144
    },
    {
      "epoch": 0.00018209866211195484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 50176
    },
    {
      "epoch": 0.00018221479646279157,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 50208
    },
    {
      "epoch": 0.00018233093081362827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 50240
    },
    {
      "epoch": 0.00018244706516446497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 50272
    },
    {
      "epoch": 0.00018256319951530167,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 50304
    },
    {
      "epoch": 0.00018267933386613837,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 50336
    },
    {
      "epoch": 0.0001827954682169751,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 50368
    },
    {
      "epoch": 0.0001829116025678118,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 50400
    },
    {
      "epoch": 0.0001830277369186485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6877,
      "step": 50432
    },
    {
      "epoch": 0.0001831438712694852,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 50464
    },
    {
      "epoch": 0.00018326000562032192,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6918,
      "step": 50496
    },
    {
      "epoch": 0.00018337613997115862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 50528
    },
    {
      "epoch": 0.00018349227432199532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6954,
      "step": 50560
    },
    {
      "epoch": 0.00018360840867283202,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6921,
      "step": 50592
    },
    {
      "epoch": 0.00018372454302366872,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6803,
      "step": 50624
    },
    {
      "epoch": 0.00018384067737450545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 50656
    },
    {
      "epoch": 0.00018395681172534215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 50688
    },
    {
      "epoch": 0.00018407294607617885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 50720
    },
    {
      "epoch": 0.00018418908042701555,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 50752
    },
    {
      "epoch": 0.00018430521477785227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7272,
      "step": 50784
    },
    {
      "epoch": 0.00018442134912868897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 50816
    },
    {
      "epoch": 0.00018453748347952567,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 50848
    },
    {
      "epoch": 0.00018465361783036237,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 50880
    },
    {
      "epoch": 0.00018476975218119907,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7492,
      "step": 50912
    },
    {
      "epoch": 0.0001848858865320358,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 50944
    },
    {
      "epoch": 0.0001850020208828725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7414,
      "step": 50976
    },
    {
      "epoch": 0.0001851181552337092,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 51008
    },
    {
      "epoch": 0.0001852342895845459,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6901,
      "step": 51040
    },
    {
      "epoch": 0.00018535042393538263,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 51072
    },
    {
      "epoch": 0.00018546655828621933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 51104
    },
    {
      "epoch": 0.00018558269263705603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 51136
    },
    {
      "epoch": 0.00018569882698789273,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 51168
    },
    {
      "epoch": 0.00018581496133872943,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6896,
      "step": 51200
    },
    {
      "epoch": 0.00018593109568956615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 51232
    },
    {
      "epoch": 0.00018604723004040285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6886,
      "step": 51264
    },
    {
      "epoch": 0.00018616336439123955,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6917,
      "step": 51296
    },
    {
      "epoch": 0.00018627949874207625,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 51328
    },
    {
      "epoch": 0.00018639563309291298,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 51360
    },
    {
      "epoch": 0.00018651176744374968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 51392
    },
    {
      "epoch": 0.00018662790179458638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 51424
    },
    {
      "epoch": 0.00018674403614542308,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 51456
    },
    {
      "epoch": 0.00018686017049625978,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 51488
    },
    {
      "epoch": 0.0001869763048470965,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7037,
      "step": 51520
    },
    {
      "epoch": 0.0001870924391979332,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 51552
    },
    {
      "epoch": 0.0001872085735487699,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 51584
    },
    {
      "epoch": 0.0001873247078996066,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 51616
    },
    {
      "epoch": 0.00018744084225044333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 51648
    },
    {
      "epoch": 0.00018755697660128003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7644,
      "step": 51680
    },
    {
      "epoch": 0.00018767311095211673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 51712
    },
    {
      "epoch": 0.00018778924530295343,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 51744
    },
    {
      "epoch": 0.00018790537965379013,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 51776
    },
    {
      "epoch": 0.00018802151400462686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 51808
    },
    {
      "epoch": 0.00018813764835546356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7422,
      "step": 51840
    },
    {
      "epoch": 0.00018825378270630026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6903,
      "step": 51872
    },
    {
      "epoch": 0.00018836991705713696,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 51904
    },
    {
      "epoch": 0.0001884860514079737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 51936
    },
    {
      "epoch": 0.0001886021857588104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 51968
    },
    {
      "epoch": 0.0001887183201096471,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 52000
    },
    {
      "epoch": 0.0001888344544604838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6807,
      "step": 52032
    },
    {
      "epoch": 0.0001889505888113205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6849,
      "step": 52064
    },
    {
      "epoch": 0.00018906672316215721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6986,
      "step": 52096
    },
    {
      "epoch": 0.00018918285751299391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 52128
    },
    {
      "epoch": 0.00018929899186383061,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6917,
      "step": 52160
    },
    {
      "epoch": 0.0001894151262146673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 52192
    },
    {
      "epoch": 0.00018953126056550404,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 52224
    },
    {
      "epoch": 0.00018964739491634074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 52256
    },
    {
      "epoch": 0.00018976352926717744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 52288
    },
    {
      "epoch": 0.00018987966361801414,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 52320
    },
    {
      "epoch": 0.00018999579796885084,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 52352
    },
    {
      "epoch": 0.00019011193231968757,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 52384
    },
    {
      "epoch": 0.00019022806667052427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 52416
    },
    {
      "epoch": 0.00019034420102136097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7372,
      "step": 52448
    },
    {
      "epoch": 0.00019046033537219767,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 52480
    },
    {
      "epoch": 0.00019057646972303437,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 52512
    },
    {
      "epoch": 0.0001906926040738711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7302,
      "step": 52544
    },
    {
      "epoch": 0.0001908087384247078,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 52576
    },
    {
      "epoch": 0.0001909248727755445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 52608
    },
    {
      "epoch": 0.0001910410071263812,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 52640
    },
    {
      "epoch": 0.00019115714147721792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 52672
    },
    {
      "epoch": 0.00019127327582805462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 52704
    },
    {
      "epoch": 0.00019138941017889132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 52736
    },
    {
      "epoch": 0.00019150554452972802,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6854,
      "step": 52768
    },
    {
      "epoch": 0.00019162167888056472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6884,
      "step": 52800
    },
    {
      "epoch": 0.00019173781323140145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 52832
    },
    {
      "epoch": 0.00019185394758223815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 52864
    },
    {
      "epoch": 0.00019197008193307485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 52896
    },
    {
      "epoch": 0.00019208621628391155,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 52928
    },
    {
      "epoch": 0.00019220235063474827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 52960
    },
    {
      "epoch": 0.00019231848498558497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6911,
      "step": 52992
    },
    {
      "epoch": 0.00019243461933642167,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 53024
    },
    {
      "epoch": 0.00019255075368725837,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 53056
    },
    {
      "epoch": 0.00019266688803809507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 53088
    },
    {
      "epoch": 0.0001927830223889318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 53120
    },
    {
      "epoch": 0.0001928991567397685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 53152
    },
    {
      "epoch": 0.0001930152910906052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 53184
    },
    {
      "epoch": 0.0001931314254414419,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 53216
    },
    {
      "epoch": 0.00019324755979227863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 53248
    },
    {
      "epoch": 0.00019336369414311533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6909,
      "step": 53280
    },
    {
      "epoch": 0.00019347982849395203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 53312
    },
    {
      "epoch": 0.00019359596284478873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 53344
    },
    {
      "epoch": 0.00019371209719562543,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 53376
    },
    {
      "epoch": 0.00019382823154646215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 53408
    },
    {
      "epoch": 0.00019394436589729885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7286,
      "step": 53440
    },
    {
      "epoch": 0.00019406050024813555,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7304,
      "step": 53472
    },
    {
      "epoch": 0.00019417663459897225,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 53504
    },
    {
      "epoch": 0.00019429276894980898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 53536
    },
    {
      "epoch": 0.00019440890330064568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 53568
    },
    {
      "epoch": 0.00019452503765148238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6794,
      "step": 53600
    },
    {
      "epoch": 0.00019464117200231908,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6915,
      "step": 53632
    },
    {
      "epoch": 0.00019475730635315578,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 53664
    },
    {
      "epoch": 0.0001948734407039925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 53696
    },
    {
      "epoch": 0.0001949895750548292,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 53728
    },
    {
      "epoch": 0.0001951057094056659,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 53760
    },
    {
      "epoch": 0.0001952218437565026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 53792
    },
    {
      "epoch": 0.00019533797810733933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 53824
    },
    {
      "epoch": 0.00019545411245817603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 53856
    },
    {
      "epoch": 0.00019557024680901273,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 53888
    },
    {
      "epoch": 0.00019568638115984943,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 53920
    },
    {
      "epoch": 0.00019580251551068613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7308,
      "step": 53952
    },
    {
      "epoch": 0.00019591864986152286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 53984
    },
    {
      "epoch": 0.00019603478421235956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 54016
    },
    {
      "epoch": 0.00019615091856319626,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 54048
    },
    {
      "epoch": 0.00019626705291403296,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7056,
      "step": 54080
    },
    {
      "epoch": 0.0001963831872648697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 54112
    },
    {
      "epoch": 0.0001964993216157064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 54144
    },
    {
      "epoch": 0.0001966154559665431,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 54176
    },
    {
      "epoch": 0.0001967315903173798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 54208
    },
    {
      "epoch": 0.0001968477246682165,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 54240
    },
    {
      "epoch": 0.00019696385901905321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 54272
    },
    {
      "epoch": 0.00019707999336988991,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 54304
    },
    {
      "epoch": 0.00019719612772072661,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7266,
      "step": 54336
    },
    {
      "epoch": 0.00019731226207156331,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 54368
    },
    {
      "epoch": 0.00019742839642240004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 54400
    },
    {
      "epoch": 0.00019754453077323674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 54432
    },
    {
      "epoch": 0.00019766066512407344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 54464
    },
    {
      "epoch": 0.00019777679947491014,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 54496
    },
    {
      "epoch": 0.00019789293382574684,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 54528
    },
    {
      "epoch": 0.00019800906817658357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 54560
    },
    {
      "epoch": 0.00019812520252742027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 54592
    },
    {
      "epoch": 0.00019824133687825697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 54624
    },
    {
      "epoch": 0.00019835747122909367,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7327,
      "step": 54656
    },
    {
      "epoch": 0.0001984736055799304,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 54688
    },
    {
      "epoch": 0.0001985897399307671,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 54720
    },
    {
      "epoch": 0.0001987058742816038,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 54752
    },
    {
      "epoch": 0.0001988220086324405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 54784
    },
    {
      "epoch": 0.0001989381429832772,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6961,
      "step": 54816
    },
    {
      "epoch": 0.00019905427733411392,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 54848
    },
    {
      "epoch": 0.00019917041168495062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 54880
    },
    {
      "epoch": 0.00019928654603578732,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 54912
    },
    {
      "epoch": 0.00019940268038662402,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 54944
    },
    {
      "epoch": 0.00019951881473746075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6926,
      "step": 54976
    },
    {
      "epoch": 0.00019963494908829745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 55008
    },
    {
      "epoch": 0.00019975108343913415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 55040
    },
    {
      "epoch": 0.00019986721778997085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 55072
    },
    {
      "epoch": 0.00019998335214080755,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 55104
    },
    {
      "epoch": 0.00020009948649164427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 55136
    },
    {
      "epoch": 0.00020021562084248097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 55168
    },
    {
      "epoch": 0.00020033175519331767,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 55200
    },
    {
      "epoch": 0.00020044788954415437,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7398,
      "step": 55232
    },
    {
      "epoch": 0.00020056402389499107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 55264
    },
    {
      "epoch": 0.0002006801582458278,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 55296
    },
    {
      "epoch": 0.0002007962925966645,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6887,
      "step": 55328
    },
    {
      "epoch": 0.0002009124269475012,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 55360
    },
    {
      "epoch": 0.0002010285612983379,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 55392
    },
    {
      "epoch": 0.00020114469564917463,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 55424
    },
    {
      "epoch": 0.00020126083000001133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 55456
    },
    {
      "epoch": 0.00020137696435084803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.74,
      "step": 55488
    },
    {
      "epoch": 0.00020149309870168473,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 55520
    },
    {
      "epoch": 0.00020160923305252143,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6946,
      "step": 55552
    },
    {
      "epoch": 0.00020172536740335815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 55584
    },
    {
      "epoch": 0.00020184150175419485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 55616
    },
    {
      "epoch": 0.00020195763610503155,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 55648
    },
    {
      "epoch": 0.00020207377045586825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 55680
    },
    {
      "epoch": 0.00020218990480670498,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 55712
    },
    {
      "epoch": 0.00020230603915754168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6859,
      "step": 55744
    },
    {
      "epoch": 0.00020242217350837838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 55776
    },
    {
      "epoch": 0.00020253830785921508,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 55808
    },
    {
      "epoch": 0.00020265444221005178,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6893,
      "step": 55840
    },
    {
      "epoch": 0.0002027705765608885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6873,
      "step": 55872
    },
    {
      "epoch": 0.0002028867109117252,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 55904
    },
    {
      "epoch": 0.0002030028452625619,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6907,
      "step": 55936
    },
    {
      "epoch": 0.0002031189796133986,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7357,
      "step": 55968
    },
    {
      "epoch": 0.00020323511396423533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 56000
    },
    {
      "epoch": 0.00020335124831507203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 56032
    },
    {
      "epoch": 0.00020346738266590873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 56064
    },
    {
      "epoch": 0.00020358351701674543,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7381,
      "step": 56096
    },
    {
      "epoch": 0.00020369965136758213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7456,
      "step": 56128
    },
    {
      "epoch": 0.00020381578571841886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 56160
    },
    {
      "epoch": 0.00020393192006925556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 56192
    },
    {
      "epoch": 0.00020404805442009226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 56224
    },
    {
      "epoch": 0.00020416418877092896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 56256
    },
    {
      "epoch": 0.0002042803231217657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 56288
    },
    {
      "epoch": 0.0002043964574726024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 56320
    },
    {
      "epoch": 0.0002045125918234391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 56352
    },
    {
      "epoch": 0.0002046287261742758,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7342,
      "step": 56384
    },
    {
      "epoch": 0.0002047448605251125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 56416
    },
    {
      "epoch": 0.00020486099487594921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 56448
    },
    {
      "epoch": 0.00020497712922678591,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6996,
      "step": 56480
    },
    {
      "epoch": 0.00020509326357762261,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6859,
      "step": 56512
    },
    {
      "epoch": 0.00020520939792845931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6915,
      "step": 56544
    },
    {
      "epoch": 0.00020532553227929604,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 56576
    },
    {
      "epoch": 0.00020544166663013274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 56608
    },
    {
      "epoch": 0.00020555780098096944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6789,
      "step": 56640
    },
    {
      "epoch": 0.00020567393533180614,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 56672
    },
    {
      "epoch": 0.00020579006968264284,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.681,
      "step": 56704
    },
    {
      "epoch": 0.00020590620403347957,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 56736
    },
    {
      "epoch": 0.00020602233838431627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 56768
    },
    {
      "epoch": 0.00020613847273515297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 56800
    },
    {
      "epoch": 0.00020625460708598967,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 56832
    },
    {
      "epoch": 0.0002063707414368264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 56864
    },
    {
      "epoch": 0.0002064868757876631,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7461,
      "step": 56896
    },
    {
      "epoch": 0.0002066030101384998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7218,
      "step": 56928
    },
    {
      "epoch": 0.0002067191444893365,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 56960
    },
    {
      "epoch": 0.0002068352788401732,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7783,
      "step": 56992
    },
    {
      "epoch": 0.00020695141319100992,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 57024
    },
    {
      "epoch": 0.00020706754754184662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 57056
    },
    {
      "epoch": 0.00020718368189268332,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6867,
      "step": 57088
    },
    {
      "epoch": 0.00020729981624352002,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6932,
      "step": 57120
    },
    {
      "epoch": 0.00020741595059435675,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 57152
    },
    {
      "epoch": 0.00020753208494519345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 57184
    },
    {
      "epoch": 0.00020764821929603015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 57216
    },
    {
      "epoch": 0.00020776435364686685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7102,
      "step": 57248
    },
    {
      "epoch": 0.00020788048799770355,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6976,
      "step": 57280
    },
    {
      "epoch": 0.00020799662234854028,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6803,
      "step": 57312
    },
    {
      "epoch": 0.00020811275669937698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 57344
    },
    {
      "epoch": 0.00020822889105021367,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6883,
      "step": 57376
    },
    {
      "epoch": 0.00020834502540105037,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6831,
      "step": 57408
    },
    {
      "epoch": 0.0002084611597518871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 57440
    },
    {
      "epoch": 0.0002085772941027238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.694,
      "step": 57472
    },
    {
      "epoch": 0.0002086934284535605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 57504
    },
    {
      "epoch": 0.0002088095628043972,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 57536
    },
    {
      "epoch": 0.0002089256971552339,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 57568
    },
    {
      "epoch": 0.00020904183150607063,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 57600
    },
    {
      "epoch": 0.00020915796585690733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 57632
    },
    {
      "epoch": 0.00020927410020774403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 57664
    },
    {
      "epoch": 0.00020939023455858073,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 57696
    },
    {
      "epoch": 0.00020950636890941746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 57728
    },
    {
      "epoch": 0.00020962250326025416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7508,
      "step": 57760
    },
    {
      "epoch": 0.00020973863761109086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 57792
    },
    {
      "epoch": 0.00020985477196192756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7364,
      "step": 57824
    },
    {
      "epoch": 0.00020997090631276425,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 57856
    },
    {
      "epoch": 0.00021008704066360098,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6908,
      "step": 57888
    },
    {
      "epoch": 0.00021020317501443768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 57920
    },
    {
      "epoch": 0.00021031930936527438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 57952
    },
    {
      "epoch": 0.00021043544371611108,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6943,
      "step": 57984
    },
    {
      "epoch": 0.00021055157806694778,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 58016
    },
    {
      "epoch": 0.0002106677124177845,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6952,
      "step": 58048
    },
    {
      "epoch": 0.0002107838467686212,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6898,
      "step": 58080
    },
    {
      "epoch": 0.0002108999811194579,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 58112
    },
    {
      "epoch": 0.0002110161154702946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 58144
    },
    {
      "epoch": 0.00021113224982113134,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6957,
      "step": 58176
    },
    {
      "epoch": 0.00021124838417196804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6946,
      "step": 58208
    },
    {
      "epoch": 0.00021136451852280474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 58240
    },
    {
      "epoch": 0.00021148065287364144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 58272
    },
    {
      "epoch": 0.00021159678722447814,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6902,
      "step": 58304
    },
    {
      "epoch": 0.00021171292157531486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 58336
    },
    {
      "epoch": 0.00021182905592615156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 58368
    },
    {
      "epoch": 0.00021194519027698826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 58400
    },
    {
      "epoch": 0.00021206132462782496,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 58432
    },
    {
      "epoch": 0.0002121774589786617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 58464
    },
    {
      "epoch": 0.0002122935933294984,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 58496
    },
    {
      "epoch": 0.0002124097276803351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.739,
      "step": 58528
    },
    {
      "epoch": 0.0002125258620311718,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 58560
    },
    {
      "epoch": 0.0002126419963820085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 58592
    },
    {
      "epoch": 0.00021275813073284522,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7268,
      "step": 58624
    },
    {
      "epoch": 0.00021287426508368192,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 58656
    },
    {
      "epoch": 0.00021299039943451862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 58688
    },
    {
      "epoch": 0.00021310653378535532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7474,
      "step": 58720
    },
    {
      "epoch": 0.00021322266813619204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 58752
    },
    {
      "epoch": 0.00021333880248702874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6869,
      "step": 58784
    },
    {
      "epoch": 0.00021345493683786544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6918,
      "step": 58816
    },
    {
      "epoch": 0.00021357107118870214,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6883,
      "step": 58848
    },
    {
      "epoch": 0.00021368720553953884,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 58880
    },
    {
      "epoch": 0.00021380333989037557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6813,
      "step": 58912
    },
    {
      "epoch": 0.00021391947424121227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6917,
      "step": 58944
    },
    {
      "epoch": 0.00021403560859204897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 58976
    },
    {
      "epoch": 0.00021415174294288567,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 59008
    },
    {
      "epoch": 0.0002142678772937224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 59040
    },
    {
      "epoch": 0.0002143840116445591,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6888,
      "step": 59072
    },
    {
      "epoch": 0.0002145001459953958,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7008,
      "step": 59104
    },
    {
      "epoch": 0.0002146162803462325,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 59136
    },
    {
      "epoch": 0.0002147324146970692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 59168
    },
    {
      "epoch": 0.00021484854904790592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 59200
    },
    {
      "epoch": 0.00021496468339874262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 59232
    },
    {
      "epoch": 0.00021508081774957932,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 59264
    },
    {
      "epoch": 0.00021519695210041602,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 59296
    },
    {
      "epoch": 0.00021531308645125275,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7375,
      "step": 59328
    },
    {
      "epoch": 0.00021542922080208945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 59360
    },
    {
      "epoch": 0.00021554535515292615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 59392
    },
    {
      "epoch": 0.00021566148950376285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 59424
    },
    {
      "epoch": 0.00021577762385459955,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 59456
    },
    {
      "epoch": 0.00021589375820543628,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7378,
      "step": 59488
    },
    {
      "epoch": 0.00021600989255627298,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 59520
    },
    {
      "epoch": 0.00021612602690710968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7153,
      "step": 59552
    },
    {
      "epoch": 0.00021624216125794638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 59584
    },
    {
      "epoch": 0.0002163582956087831,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 59616
    },
    {
      "epoch": 0.0002164744299596198,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 59648
    },
    {
      "epoch": 0.0002165905643104565,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6866,
      "step": 59680
    },
    {
      "epoch": 0.0002167066986612932,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.68,
      "step": 59712
    },
    {
      "epoch": 0.0002168228330121299,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6934,
      "step": 59744
    },
    {
      "epoch": 0.00021693896736296663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 59776
    },
    {
      "epoch": 0.00021705510171380333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 59808
    },
    {
      "epoch": 0.00021717123606464003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 59840
    },
    {
      "epoch": 0.00021728737041547673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 59872
    },
    {
      "epoch": 0.00021740350476631346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 59904
    },
    {
      "epoch": 0.00021751963911715016,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 59936
    },
    {
      "epoch": 0.00021763577346798686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7205,
      "step": 59968
    },
    {
      "epoch": 0.00021775190781882356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 60000
    },
    {
      "epoch": 0.00021786804216966026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 60032
    },
    {
      "epoch": 0.00021798417652049698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 60064
    },
    {
      "epoch": 0.00021810031087133368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 60096
    },
    {
      "epoch": 0.00021821644522217038,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6853,
      "step": 60128
    },
    {
      "epoch": 0.00021833257957300708,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 60160
    },
    {
      "epoch": 0.0002184487139238438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 60192
    },
    {
      "epoch": 0.0002185648482746805,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 60224
    },
    {
      "epoch": 0.0002186809826255172,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 60256
    },
    {
      "epoch": 0.0002187971169763539,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 60288
    },
    {
      "epoch": 0.0002189132513271906,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6946,
      "step": 60320
    },
    {
      "epoch": 0.00021902938567802734,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 60352
    },
    {
      "epoch": 0.00021914552002886404,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 60384
    },
    {
      "epoch": 0.00021926165437970074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7342,
      "step": 60416
    },
    {
      "epoch": 0.00021937778873053744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6858,
      "step": 60448
    },
    {
      "epoch": 0.00021949392308137416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6926,
      "step": 60480
    },
    {
      "epoch": 0.00021961005743221086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 60512
    },
    {
      "epoch": 0.00021972619178304756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 60544
    },
    {
      "epoch": 0.00021984232613388426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 60576
    },
    {
      "epoch": 0.00021995846048472096,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 60608
    },
    {
      "epoch": 0.0002200745948355577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 60640
    },
    {
      "epoch": 0.0002201907291863944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 60672
    },
    {
      "epoch": 0.0002203068635372311,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 60704
    },
    {
      "epoch": 0.0002204229978880678,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 60736
    },
    {
      "epoch": 0.0002205391322389045,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 60768
    },
    {
      "epoch": 0.00022065526658974122,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 60800
    },
    {
      "epoch": 0.00022077140094057792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 60832
    },
    {
      "epoch": 0.00022088753529141462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 60864
    },
    {
      "epoch": 0.00022100366964225132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 60896
    },
    {
      "epoch": 0.00022111980399308804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6908,
      "step": 60928
    },
    {
      "epoch": 0.00022123593834392474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 60960
    },
    {
      "epoch": 0.00022135207269476144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 60992
    },
    {
      "epoch": 0.00022146820704559814,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 61024
    },
    {
      "epoch": 0.00022158434139643484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 61056
    },
    {
      "epoch": 0.00022170047574727157,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 61088
    },
    {
      "epoch": 0.00022181661009810827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 61120
    },
    {
      "epoch": 0.00022193274444894497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 61152
    },
    {
      "epoch": 0.00022204887879978167,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 61184
    },
    {
      "epoch": 0.0002221650131506184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6994,
      "step": 61216
    },
    {
      "epoch": 0.0002222811475014551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 61248
    },
    {
      "epoch": 0.0002223972818522918,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7419,
      "step": 61280
    },
    {
      "epoch": 0.0002225134162031285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 61312
    },
    {
      "epoch": 0.0002226295505539652,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6951,
      "step": 61344
    },
    {
      "epoch": 0.00022274568490480192,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 61376
    },
    {
      "epoch": 0.00022286181925563862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 61408
    },
    {
      "epoch": 0.00022297795360647532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 61440
    },
    {
      "epoch": 0.00022309408795731202,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 61472
    },
    {
      "epoch": 0.00022321022230814875,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 61504
    },
    {
      "epoch": 0.00022332635665898545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 61536
    },
    {
      "epoch": 0.00022344249100982215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 61568
    },
    {
      "epoch": 0.00022355862536065885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 61600
    },
    {
      "epoch": 0.00022367475971149555,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 61632
    },
    {
      "epoch": 0.00022379089406233228,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 61664
    },
    {
      "epoch": 0.00022390702841316898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 61696
    },
    {
      "epoch": 0.00022402316276400568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 61728
    },
    {
      "epoch": 0.00022413929711484238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 61760
    },
    {
      "epoch": 0.0002242554314656791,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 61792
    },
    {
      "epoch": 0.0002243715658165158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6848,
      "step": 61824
    },
    {
      "epoch": 0.0002244877001673525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6743,
      "step": 61856
    },
    {
      "epoch": 0.0002246038345181892,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 61888
    },
    {
      "epoch": 0.0002247199688690259,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 61920
    },
    {
      "epoch": 0.00022483610321986263,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 61952
    },
    {
      "epoch": 0.00022495223757069933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7177,
      "step": 61984
    },
    {
      "epoch": 0.00022506837192153603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6921,
      "step": 62016
    },
    {
      "epoch": 0.00022518450627237273,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7395,
      "step": 62048
    },
    {
      "epoch": 0.00022530064062320946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 62080
    },
    {
      "epoch": 0.00022541677497404616,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 62112
    },
    {
      "epoch": 0.00022553290932488286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7425,
      "step": 62144
    },
    {
      "epoch": 0.00022564904367571956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 62176
    },
    {
      "epoch": 0.00022576517802655626,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 62208
    },
    {
      "epoch": 0.00022588131237739298,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 62240
    },
    {
      "epoch": 0.00022599744672822968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 62272
    },
    {
      "epoch": 0.00022611358107906638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7349,
      "step": 62304
    },
    {
      "epoch": 0.00022622971542990308,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 62336
    },
    {
      "epoch": 0.0002263458497807398,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 62368
    },
    {
      "epoch": 0.0002264619841315765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 62400
    },
    {
      "epoch": 0.0002265781184824132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 62432
    },
    {
      "epoch": 0.0002266942528332499,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 62464
    },
    {
      "epoch": 0.0002268103871840866,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 62496
    },
    {
      "epoch": 0.00022692652153492334,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 62528
    },
    {
      "epoch": 0.00022704265588576004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 62560
    },
    {
      "epoch": 0.00022715879023659674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6806,
      "step": 62592
    },
    {
      "epoch": 0.00022727492458743344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6857,
      "step": 62624
    },
    {
      "epoch": 0.00022739105893827016,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 62656
    },
    {
      "epoch": 0.00022750719328910686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6854,
      "step": 62688
    },
    {
      "epoch": 0.00022762332763994356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 62720
    },
    {
      "epoch": 0.00022773946199078026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6927,
      "step": 62752
    },
    {
      "epoch": 0.00022785559634161696,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 62784
    },
    {
      "epoch": 0.0002279717306924537,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 62816
    },
    {
      "epoch": 0.0002280878650432904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7394,
      "step": 62848
    },
    {
      "epoch": 0.0002282039993941271,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 62880
    },
    {
      "epoch": 0.0002283201337449638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 62912
    },
    {
      "epoch": 0.00022843626809580052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 62944
    },
    {
      "epoch": 0.00022855240244663722,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7323,
      "step": 62976
    },
    {
      "epoch": 0.00022866853679747392,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7455,
      "step": 63008
    },
    {
      "epoch": 0.00022878467114831062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 63040
    },
    {
      "epoch": 0.00022890080549914732,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 63072
    },
    {
      "epoch": 0.00022901693984998404,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 63104
    },
    {
      "epoch": 0.00022913307420082074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 63136
    },
    {
      "epoch": 0.00022924920855165744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 63168
    },
    {
      "epoch": 0.00022936534290249414,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6919,
      "step": 63200
    },
    {
      "epoch": 0.00022948147725333087,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 63232
    },
    {
      "epoch": 0.00022959761160416757,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 63264
    },
    {
      "epoch": 0.00022971374595500427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 63296
    },
    {
      "epoch": 0.00022982988030584097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 63328
    },
    {
      "epoch": 0.00022994601465667767,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6889,
      "step": 63360
    },
    {
      "epoch": 0.0002300621490075144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6801,
      "step": 63392
    },
    {
      "epoch": 0.0002301782833583511,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 63424
    },
    {
      "epoch": 0.0002302944177091878,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 63456
    },
    {
      "epoch": 0.0002304105520600245,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6902,
      "step": 63488
    },
    {
      "epoch": 0.0002305266864108612,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6825,
      "step": 63520
    },
    {
      "epoch": 0.00023064282076169792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6926,
      "step": 63552
    },
    {
      "epoch": 0.00023075895511253462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 63584
    },
    {
      "epoch": 0.00023087508946337132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 63616
    },
    {
      "epoch": 0.00023099122381420802,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 63648
    },
    {
      "epoch": 0.00023110735816504475,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 63680
    },
    {
      "epoch": 0.00023122349251588145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7346,
      "step": 63712
    },
    {
      "epoch": 0.00023133962686671815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7411,
      "step": 63744
    },
    {
      "epoch": 0.00023145576121755485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 63776
    },
    {
      "epoch": 0.00023157189556839155,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 63808
    },
    {
      "epoch": 0.00023168802991922828,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7452,
      "step": 63840
    },
    {
      "epoch": 0.00023180416427006498,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 63872
    },
    {
      "epoch": 0.00023192029862090168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 63904
    },
    {
      "epoch": 0.00023203643297173838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 63936
    },
    {
      "epoch": 0.0002321525673225751,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 63968
    },
    {
      "epoch": 0.0002322687016734118,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7008,
      "step": 64000
    },
    {
      "epoch": 0.0002323848360242485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 64032
    },
    {
      "epoch": 0.0002325009703750852,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 64064
    },
    {
      "epoch": 0.0002326171047259219,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6961,
      "step": 64096
    },
    {
      "epoch": 0.00023273323907675863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 64128
    },
    {
      "epoch": 0.00023284937342759533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6787,
      "step": 64160
    },
    {
      "epoch": 0.00023296550777843203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 64192
    },
    {
      "epoch": 0.00023308164212926873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6872,
      "step": 64224
    },
    {
      "epoch": 0.00023319777648010546,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 64256
    },
    {
      "epoch": 0.00023331391083094216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6834,
      "step": 64288
    },
    {
      "epoch": 0.00023343004518177886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 64320
    },
    {
      "epoch": 0.00023354617953261556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 64352
    },
    {
      "epoch": 0.00023366231388345226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 64384
    },
    {
      "epoch": 0.00023377844823428898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 64416
    },
    {
      "epoch": 0.00023389458258512568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 64448
    },
    {
      "epoch": 0.00023401071693596238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 64480
    },
    {
      "epoch": 0.00023412685128679908,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7315,
      "step": 64512
    },
    {
      "epoch": 0.0002342429856376358,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 64544
    },
    {
      "epoch": 0.0002343591199884725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7407,
      "step": 64576
    },
    {
      "epoch": 0.0002344752543393092,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 64608
    },
    {
      "epoch": 0.0002345913886901459,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7442,
      "step": 64640
    },
    {
      "epoch": 0.0002347075230409826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 64672
    },
    {
      "epoch": 0.00023482365739181934,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 64704
    },
    {
      "epoch": 0.00023493979174265604,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 64736
    },
    {
      "epoch": 0.00023505592609349274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6898,
      "step": 64768
    },
    {
      "epoch": 0.00023517206044432944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 64800
    },
    {
      "epoch": 0.00023528819479516616,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 64832
    },
    {
      "epoch": 0.00023540432914600286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 64864
    },
    {
      "epoch": 0.00023552046349683956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 64896
    },
    {
      "epoch": 0.00023563659784767626,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6859,
      "step": 64928
    },
    {
      "epoch": 0.00023575273219851296,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6929,
      "step": 64960
    },
    {
      "epoch": 0.0002358688665493497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 64992
    },
    {
      "epoch": 0.0002359850009001864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 65024
    },
    {
      "epoch": 0.0002361011352510231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6814,
      "step": 65056
    },
    {
      "epoch": 0.0002362172696018598,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 65088
    },
    {
      "epoch": 0.00023633340395269652,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 65120
    },
    {
      "epoch": 0.00023644953830353322,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6976,
      "step": 65152
    },
    {
      "epoch": 0.00023656567265436992,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 65184
    },
    {
      "epoch": 0.00023668180700520662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 65216
    },
    {
      "epoch": 0.00023679794135604332,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 65248
    },
    {
      "epoch": 0.00023691407570688004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 65280
    },
    {
      "epoch": 0.00023703021005771674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 65312
    },
    {
      "epoch": 0.00023714634440855344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 65344
    },
    {
      "epoch": 0.00023726247875939014,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 65376
    },
    {
      "epoch": 0.00023737861311022687,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7284,
      "step": 65408
    },
    {
      "epoch": 0.00023749474746106357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 65440
    },
    {
      "epoch": 0.00023761088181190027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7352,
      "step": 65472
    },
    {
      "epoch": 0.00023772701616273697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7478,
      "step": 65504
    },
    {
      "epoch": 0.00023784315051357367,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 65536
    },
    {
      "epoch": 0.0002379592848644104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7368,
      "step": 65568
    },
    {
      "epoch": 0.0002380754192152471,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 65600
    },
    {
      "epoch": 0.0002381915535660838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6904,
      "step": 65632
    },
    {
      "epoch": 0.0002383076879169205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 65664
    },
    {
      "epoch": 0.00023842382226775722,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6857,
      "step": 65696
    },
    {
      "epoch": 0.00023853995661859392,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 65728
    },
    {
      "epoch": 0.00023865609096943062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6894,
      "step": 65760
    },
    {
      "epoch": 0.00023877222532026732,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 65792
    },
    {
      "epoch": 0.00023888835967110402,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 65824
    },
    {
      "epoch": 0.00023900449402194075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 65856
    },
    {
      "epoch": 0.00023912062837277745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 65888
    },
    {
      "epoch": 0.00023923676272361415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 65920
    },
    {
      "epoch": 0.00023935289707445085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 65952
    },
    {
      "epoch": 0.00023946903142528755,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 65984
    },
    {
      "epoch": 0.00023958516577612428,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 66016
    },
    {
      "epoch": 0.00023970130012696098,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 66048
    },
    {
      "epoch": 0.00023981743447779768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7396,
      "step": 66080
    },
    {
      "epoch": 0.00023993356882863438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 66112
    },
    {
      "epoch": 0.0002400497031794711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 66144
    },
    {
      "epoch": 0.0002401658375303078,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 66176
    },
    {
      "epoch": 0.0002402819718811445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 66208
    },
    {
      "epoch": 0.0002403981062319812,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7291,
      "step": 66240
    },
    {
      "epoch": 0.0002405142405828179,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 66272
    },
    {
      "epoch": 0.00024063037493365463,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 66304
    },
    {
      "epoch": 0.00024074650928449133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 66336
    },
    {
      "epoch": 0.00024086264363532803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 66368
    },
    {
      "epoch": 0.00024097877798616473,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7357,
      "step": 66400
    },
    {
      "epoch": 0.00024109491233700146,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 66432
    },
    {
      "epoch": 0.00024121104668783816,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6874,
      "step": 66464
    },
    {
      "epoch": 0.00024132718103867486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6828,
      "step": 66496
    },
    {
      "epoch": 0.00024144331538951156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6927,
      "step": 66528
    },
    {
      "epoch": 0.00024155944974034826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6898,
      "step": 66560
    },
    {
      "epoch": 0.00024167558409118498,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 66592
    },
    {
      "epoch": 0.00024179171844202168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 66624
    },
    {
      "epoch": 0.00024190785279285838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 66656
    },
    {
      "epoch": 0.00024202398714369508,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 66688
    },
    {
      "epoch": 0.0002421401214945318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 66720
    },
    {
      "epoch": 0.0002422562558453685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 66752
    },
    {
      "epoch": 0.0002423723901962052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 66784
    },
    {
      "epoch": 0.0002424885245470419,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 66816
    },
    {
      "epoch": 0.0002426046588978786,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7367,
      "step": 66848
    },
    {
      "epoch": 0.00024272079324871534,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 66880
    },
    {
      "epoch": 0.00024283692759955204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6997,
      "step": 66912
    },
    {
      "epoch": 0.00024295306195038874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 66944
    },
    {
      "epoch": 0.00024306919630122544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 66976
    },
    {
      "epoch": 0.00024318533065206216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 67008
    },
    {
      "epoch": 0.00024330146500289886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 67040
    },
    {
      "epoch": 0.00024341759935373556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 67072
    },
    {
      "epoch": 0.00024353373370457226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 67104
    },
    {
      "epoch": 0.00024364986805540896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 67136
    },
    {
      "epoch": 0.0002437660024062457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 67168
    },
    {
      "epoch": 0.0002438821367570824,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 67200
    },
    {
      "epoch": 0.0002439982711079191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 67232
    },
    {
      "epoch": 0.0002441144054587558,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 67264
    },
    {
      "epoch": 0.0002442305398095925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 67296
    },
    {
      "epoch": 0.0002443466741604292,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 67328
    },
    {
      "epoch": 0.0002444628085112659,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 67360
    },
    {
      "epoch": 0.00024457894286210264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 67392
    },
    {
      "epoch": 0.00024469507721293934,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 67424
    },
    {
      "epoch": 0.00024481121156377604,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 67456
    },
    {
      "epoch": 0.00024492734591461274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 67488
    },
    {
      "epoch": 0.00024504348026544944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 67520
    },
    {
      "epoch": 0.00024515961461628614,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 67552
    },
    {
      "epoch": 0.00024527574896712284,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 67584
    },
    {
      "epoch": 0.00024539188331795954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.739,
      "step": 67616
    },
    {
      "epoch": 0.00024550801766879624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 67648
    },
    {
      "epoch": 0.000245624152019633,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 67680
    },
    {
      "epoch": 0.0002457402863704697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6895,
      "step": 67712
    },
    {
      "epoch": 0.0002458564207213064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 67744
    },
    {
      "epoch": 0.0002459725550721431,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7281,
      "step": 67776
    },
    {
      "epoch": 0.0002460886894229798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 67808
    },
    {
      "epoch": 0.0002462048237738165,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 67840
    },
    {
      "epoch": 0.0002463209581246532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7013,
      "step": 67872
    },
    {
      "epoch": 0.0002464370924754899,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6876,
      "step": 67904
    },
    {
      "epoch": 0.0002465532268263266,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 67936
    },
    {
      "epoch": 0.00024666936117716335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 67968
    },
    {
      "epoch": 0.00024678549552800005,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 68000
    },
    {
      "epoch": 0.00024690162987883675,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 68032
    },
    {
      "epoch": 0.00024701776422967345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 68064
    },
    {
      "epoch": 0.00024713389858051015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 68096
    },
    {
      "epoch": 0.00024725003293134685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.742,
      "step": 68128
    },
    {
      "epoch": 0.00024736616728218355,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7536,
      "step": 68160
    },
    {
      "epoch": 0.00024748230163302025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 68192
    },
    {
      "epoch": 0.00024759843598385695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 68224
    },
    {
      "epoch": 0.0002477145703346937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 68256
    },
    {
      "epoch": 0.0002478307046855304,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 68288
    },
    {
      "epoch": 0.0002479468390363671,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 68320
    },
    {
      "epoch": 0.0002480629733872038,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 68352
    },
    {
      "epoch": 0.0002481791077380405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7409,
      "step": 68384
    },
    {
      "epoch": 0.0002482952420888772,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 68416
    },
    {
      "epoch": 0.0002484113764397139,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 68448
    },
    {
      "epoch": 0.0002485275107905506,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 68480
    },
    {
      "epoch": 0.0002486436451413873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 68512
    },
    {
      "epoch": 0.00024875977949222406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 68544
    },
    {
      "epoch": 0.00024887591384306076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 68576
    },
    {
      "epoch": 0.00024899204819389746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 68608
    },
    {
      "epoch": 0.00024910818254473416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 68640
    },
    {
      "epoch": 0.00024922431689557086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6925,
      "step": 68672
    },
    {
      "epoch": 0.00024934045124640756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 68704
    },
    {
      "epoch": 0.00024945658559724426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 68736
    },
    {
      "epoch": 0.00024957271994808096,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 68768
    },
    {
      "epoch": 0.00024968885429891766,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 68800
    },
    {
      "epoch": 0.0002498049886497544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7056,
      "step": 68832
    },
    {
      "epoch": 0.0002499211230005911,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 68864
    },
    {
      "epoch": 0.0002500372573514278,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 68896
    },
    {
      "epoch": 0.0002501533917022645,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 68928
    },
    {
      "epoch": 0.0002502695260531012,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 68960
    },
    {
      "epoch": 0.0002503856604039379,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7337,
      "step": 68992
    },
    {
      "epoch": 0.0002505017947547746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7486,
      "step": 69024
    },
    {
      "epoch": 0.0002506179291056113,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 69056
    },
    {
      "epoch": 0.000250734063456448,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 69088
    },
    {
      "epoch": 0.00025085019780728477,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 69120
    },
    {
      "epoch": 0.00025096633215812147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 69152
    },
    {
      "epoch": 0.00025108246650895816,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 69184
    },
    {
      "epoch": 0.00025119860085979486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6921,
      "step": 69216
    },
    {
      "epoch": 0.00025131473521063156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 69248
    },
    {
      "epoch": 0.00025143086956146826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 69280
    },
    {
      "epoch": 0.00025154700391230496,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 69312
    },
    {
      "epoch": 0.00025166313826314166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 69344
    },
    {
      "epoch": 0.00025177927261397836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 69376
    },
    {
      "epoch": 0.0002518954069648151,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6897,
      "step": 69408
    },
    {
      "epoch": 0.0002520115413156518,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6875,
      "step": 69440
    },
    {
      "epoch": 0.0002521276756664885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6914,
      "step": 69472
    },
    {
      "epoch": 0.0002522438100173252,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6799,
      "step": 69504
    },
    {
      "epoch": 0.0002523599443681619,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 69536
    },
    {
      "epoch": 0.0002524760787189986,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6952,
      "step": 69568
    },
    {
      "epoch": 0.0002525922130698353,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 69600
    },
    {
      "epoch": 0.000252708347420672,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 69632
    },
    {
      "epoch": 0.0002528244817715087,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 69664
    },
    {
      "epoch": 0.00025294061612234547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 69696
    },
    {
      "epoch": 0.00025305675047318217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 69728
    },
    {
      "epoch": 0.00025317288482401887,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 69760
    },
    {
      "epoch": 0.00025328901917485557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7462,
      "step": 69792
    },
    {
      "epoch": 0.00025340515352569227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 69824
    },
    {
      "epoch": 0.00025352128787652897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 69856
    },
    {
      "epoch": 0.00025363742222736567,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7569,
      "step": 69888
    },
    {
      "epoch": 0.00025375355657820237,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 69920
    },
    {
      "epoch": 0.00025386969092903907,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 69952
    },
    {
      "epoch": 0.0002539858252798758,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6892,
      "step": 69984
    },
    {
      "epoch": 0.0002541019596307125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 70016
    },
    {
      "epoch": 0.0002542180939815492,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 70048
    },
    {
      "epoch": 0.0002543342283323859,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 70080
    },
    {
      "epoch": 0.0002544503626832226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 70112
    },
    {
      "epoch": 0.0002545664970340593,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 70144
    },
    {
      "epoch": 0.000254682631384896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 70176
    },
    {
      "epoch": 0.0002547987657357327,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 70208
    },
    {
      "epoch": 0.0002549149000865694,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6776,
      "step": 70240
    },
    {
      "epoch": 0.0002550310344374062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6873,
      "step": 70272
    },
    {
      "epoch": 0.0002551471687882429,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6904,
      "step": 70304
    },
    {
      "epoch": 0.0002552633031390796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6844,
      "step": 70336
    },
    {
      "epoch": 0.0002553794374899163,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 70368
    },
    {
      "epoch": 0.000255495571840753,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 70400
    },
    {
      "epoch": 0.0002556117061915897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6909,
      "step": 70432
    },
    {
      "epoch": 0.0002557278405424264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 70464
    },
    {
      "epoch": 0.0002558439748932631,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 70496
    },
    {
      "epoch": 0.0002559601092440998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7453,
      "step": 70528
    },
    {
      "epoch": 0.00025607624359493653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 70560
    },
    {
      "epoch": 0.00025619237794577323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 70592
    },
    {
      "epoch": 0.00025630851229660993,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 70624
    },
    {
      "epoch": 0.00025642464664744663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7465,
      "step": 70656
    },
    {
      "epoch": 0.00025654078099828333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 70688
    },
    {
      "epoch": 0.00025665691534912003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7359,
      "step": 70720
    },
    {
      "epoch": 0.00025677304969995673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 70752
    },
    {
      "epoch": 0.00025688918405079343,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 70784
    },
    {
      "epoch": 0.00025700531840163013,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 70816
    },
    {
      "epoch": 0.0002571214527524669,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 70848
    },
    {
      "epoch": 0.0002572375871033036,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 70880
    },
    {
      "epoch": 0.0002573537214541403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6912,
      "step": 70912
    },
    {
      "epoch": 0.000257469855804977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 70944
    },
    {
      "epoch": 0.0002575859901558137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 70976
    },
    {
      "epoch": 0.0002577021245066504,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.694,
      "step": 71008
    },
    {
      "epoch": 0.0002578182588574871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.683,
      "step": 71040
    },
    {
      "epoch": 0.0002579343932083238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 71072
    },
    {
      "epoch": 0.0002580505275591605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 71104
    },
    {
      "epoch": 0.00025816666190999724,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 71136
    },
    {
      "epoch": 0.00025828279626083394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 71168
    },
    {
      "epoch": 0.00025839893061167064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 71200
    },
    {
      "epoch": 0.00025851506496250734,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 71232
    },
    {
      "epoch": 0.00025863119931334404,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 71264
    },
    {
      "epoch": 0.00025874733366418074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 71296
    },
    {
      "epoch": 0.00025886346801501744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 71328
    },
    {
      "epoch": 0.00025897960236585414,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 71360
    },
    {
      "epoch": 0.00025909573671669084,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 71392
    },
    {
      "epoch": 0.0002592118710675276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7302,
      "step": 71424
    },
    {
      "epoch": 0.0002593280054183643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 71456
    },
    {
      "epoch": 0.000259444139769201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 71488
    },
    {
      "epoch": 0.0002595602741200377,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 71520
    },
    {
      "epoch": 0.0002596764084708744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7304,
      "step": 71552
    },
    {
      "epoch": 0.0002597925428217111,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7444,
      "step": 71584
    },
    {
      "epoch": 0.0002599086771725478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 71616
    },
    {
      "epoch": 0.0002600248115233845,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 71648
    },
    {
      "epoch": 0.0002601409458742212,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 71680
    },
    {
      "epoch": 0.00026025708022505795,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 71712
    },
    {
      "epoch": 0.00026037321457589465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6898,
      "step": 71744
    },
    {
      "epoch": 0.00026048934892673135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6851,
      "step": 71776
    },
    {
      "epoch": 0.00026060548327756805,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6822,
      "step": 71808
    },
    {
      "epoch": 0.00026072161762840475,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7037,
      "step": 71840
    },
    {
      "epoch": 0.00026083775197924145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6909,
      "step": 71872
    },
    {
      "epoch": 0.00026095388633007815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 71904
    },
    {
      "epoch": 0.00026107002068091485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 71936
    },
    {
      "epoch": 0.00026118615503175155,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7037,
      "step": 71968
    },
    {
      "epoch": 0.0002613022893825883,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 72000
    },
    {
      "epoch": 0.000261418423733425,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 72032
    },
    {
      "epoch": 0.0002615345580842617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 72064
    },
    {
      "epoch": 0.0002616506924350984,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 72096
    },
    {
      "epoch": 0.0002617668267859351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 72128
    },
    {
      "epoch": 0.0002618829611367718,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 72160
    },
    {
      "epoch": 0.0002619990954876085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 72192
    },
    {
      "epoch": 0.0002621152298384452,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 72224
    },
    {
      "epoch": 0.0002622313641892819,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 72256
    },
    {
      "epoch": 0.00026234749854011865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 72288
    },
    {
      "epoch": 0.00026246363289095535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7273,
      "step": 72320
    },
    {
      "epoch": 0.00026257976724179205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.736,
      "step": 72352
    },
    {
      "epoch": 0.00026269590159262875,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 72384
    },
    {
      "epoch": 0.00026281203594346545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 72416
    },
    {
      "epoch": 0.00026292817029430215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 72448
    },
    {
      "epoch": 0.00026304430464513885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 72480
    },
    {
      "epoch": 0.00026316043899597555,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 72512
    },
    {
      "epoch": 0.00026327657334681225,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 72544
    },
    {
      "epoch": 0.000263392707697649,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6812,
      "step": 72576
    },
    {
      "epoch": 0.0002635088420484857,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6896,
      "step": 72608
    },
    {
      "epoch": 0.0002636249763993224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6925,
      "step": 72640
    },
    {
      "epoch": 0.0002637411107501591,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 72672
    },
    {
      "epoch": 0.0002638572451009958,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 72704
    },
    {
      "epoch": 0.0002639733794518325,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 72736
    },
    {
      "epoch": 0.0002640895138026692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 72768
    },
    {
      "epoch": 0.0002642056481535059,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 72800
    },
    {
      "epoch": 0.0002643217825043426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 72832
    },
    {
      "epoch": 0.0002644379168551793,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 72864
    },
    {
      "epoch": 0.00026455405120601606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 72896
    },
    {
      "epoch": 0.00026467018555685276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 72928
    },
    {
      "epoch": 0.00026478631990768946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 72960
    },
    {
      "epoch": 0.00026490245425852616,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 72992
    },
    {
      "epoch": 0.00026501858860936286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6837,
      "step": 73024
    },
    {
      "epoch": 0.00026513472296019956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 73056
    },
    {
      "epoch": 0.00026525085731103626,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 73088
    },
    {
      "epoch": 0.00026536699166187296,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7297,
      "step": 73120
    },
    {
      "epoch": 0.00026548312601270966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 73152
    },
    {
      "epoch": 0.0002655992603635464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6948,
      "step": 73184
    },
    {
      "epoch": 0.0002657153947143831,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 73216
    },
    {
      "epoch": 0.0002658315290652198,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 73248
    },
    {
      "epoch": 0.0002659476634160565,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 73280
    },
    {
      "epoch": 0.0002660637977668932,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 73312
    },
    {
      "epoch": 0.0002661799321177299,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.687,
      "step": 73344
    },
    {
      "epoch": 0.0002662960664685666,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6867,
      "step": 73376
    },
    {
      "epoch": 0.0002664122008194033,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 73408
    },
    {
      "epoch": 0.00026652833517024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7406,
      "step": 73440
    },
    {
      "epoch": 0.00026664446952107677,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 73472
    },
    {
      "epoch": 0.00026676060387191347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 73504
    },
    {
      "epoch": 0.00026687673822275017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 73536
    },
    {
      "epoch": 0.00026699287257358687,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 73568
    },
    {
      "epoch": 0.00026710900692442357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 73600
    },
    {
      "epoch": 0.00026722514127526027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 73632
    },
    {
      "epoch": 0.00026734127562609697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7153,
      "step": 73664
    },
    {
      "epoch": 0.00026745740997693367,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 73696
    },
    {
      "epoch": 0.00026757354432777037,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 73728
    },
    {
      "epoch": 0.0002676896786786071,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6986,
      "step": 73760
    },
    {
      "epoch": 0.0002678058130294438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6921,
      "step": 73792
    },
    {
      "epoch": 0.0002679219473802805,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 73824
    },
    {
      "epoch": 0.0002680380817311172,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 73856
    },
    {
      "epoch": 0.0002681542160819539,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7288,
      "step": 73888
    },
    {
      "epoch": 0.0002682703504327906,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 73920
    },
    {
      "epoch": 0.0002683864847836273,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 73952
    },
    {
      "epoch": 0.000268502619134464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 73984
    },
    {
      "epoch": 0.0002686187534853007,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 74016
    },
    {
      "epoch": 0.0002687348878361375,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7352,
      "step": 74048
    },
    {
      "epoch": 0.0002688510221869742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 74080
    },
    {
      "epoch": 0.00026896715653781087,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6963,
      "step": 74112
    },
    {
      "epoch": 0.00026908329088864757,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 74144
    },
    {
      "epoch": 0.00026919942523948427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 74176
    },
    {
      "epoch": 0.00026931555959032097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 74208
    },
    {
      "epoch": 0.00026943169394115767,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6972,
      "step": 74240
    },
    {
      "epoch": 0.00026954782829199437,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 74272
    },
    {
      "epoch": 0.00026966396264283107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 74304
    },
    {
      "epoch": 0.0002697800969936678,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 74336
    },
    {
      "epoch": 0.0002698962313445045,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 74368
    },
    {
      "epoch": 0.0002700123656953412,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 74400
    },
    {
      "epoch": 0.0002701285000461779,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 74432
    },
    {
      "epoch": 0.0002702446343970146,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 74464
    },
    {
      "epoch": 0.0002703607687478513,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 74496
    },
    {
      "epoch": 0.000270476903098688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6891,
      "step": 74528
    },
    {
      "epoch": 0.0002705930374495247,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 74560
    },
    {
      "epoch": 0.0002707091718003614,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 74592
    },
    {
      "epoch": 0.0002708253061511982,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 74624
    },
    {
      "epoch": 0.0002709414405020349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 74656
    },
    {
      "epoch": 0.0002710575748528716,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 74688
    },
    {
      "epoch": 0.0002711737092037083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6772,
      "step": 74720
    },
    {
      "epoch": 0.000271289843554545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6831,
      "step": 74752
    },
    {
      "epoch": 0.0002714059779053817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 74784
    },
    {
      "epoch": 0.0002715221122562184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 74816
    },
    {
      "epoch": 0.0002716382466070551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 74848
    },
    {
      "epoch": 0.0002717543809578918,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 74880
    },
    {
      "epoch": 0.00027187051530872853,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 74912
    },
    {
      "epoch": 0.00027198664965956523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7296,
      "step": 74944
    },
    {
      "epoch": 0.00027210278401040193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7363,
      "step": 74976
    },
    {
      "epoch": 0.00027221891836123863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 75008
    },
    {
      "epoch": 0.00027233505271207533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 75040
    },
    {
      "epoch": 0.00027245118706291203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 75072
    },
    {
      "epoch": 0.00027256732141374873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 75104
    },
    {
      "epoch": 0.00027268345576458543,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 75136
    },
    {
      "epoch": 0.00027279959011542213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 75168
    },
    {
      "epoch": 0.0002729157244662589,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7494,
      "step": 75200
    },
    {
      "epoch": 0.0002730318588170956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 75232
    },
    {
      "epoch": 0.0002731479931679323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 75264
    },
    {
      "epoch": 0.000273264127518769,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 75296
    },
    {
      "epoch": 0.0002733802618696057,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6844,
      "step": 75328
    },
    {
      "epoch": 0.0002734963962204424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 75360
    },
    {
      "epoch": 0.0002736125305712791,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 75392
    },
    {
      "epoch": 0.0002737286649221158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 75424
    },
    {
      "epoch": 0.0002738447992729525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 75456
    },
    {
      "epoch": 0.00027396093362378924,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 75488
    },
    {
      "epoch": 0.00027407706797462594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6912,
      "step": 75520
    },
    {
      "epoch": 0.00027419320232546264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6848,
      "step": 75552
    },
    {
      "epoch": 0.00027430933667629934,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 75584
    },
    {
      "epoch": 0.00027442547102713604,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6924,
      "step": 75616
    },
    {
      "epoch": 0.00027454160537797274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 75648
    },
    {
      "epoch": 0.00027465773972880944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 75680
    },
    {
      "epoch": 0.00027477387407964614,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7428,
      "step": 75712
    },
    {
      "epoch": 0.00027489000843048284,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 75744
    },
    {
      "epoch": 0.0002750061427813196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 75776
    },
    {
      "epoch": 0.0002751222771321563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.736,
      "step": 75808
    },
    {
      "epoch": 0.000275238411482993,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 75840
    },
    {
      "epoch": 0.0002753545458338297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.749,
      "step": 75872
    },
    {
      "epoch": 0.0002754706801846664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 75904
    },
    {
      "epoch": 0.0002755868145355031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6891,
      "step": 75936
    },
    {
      "epoch": 0.0002757029488863398,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 75968
    },
    {
      "epoch": 0.0002758190832371765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 76000
    },
    {
      "epoch": 0.0002759352175880132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 76032
    },
    {
      "epoch": 0.00027605135193884995,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 76064
    },
    {
      "epoch": 0.00027616748628968665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 76096
    },
    {
      "epoch": 0.00027628362064052335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 76128
    },
    {
      "epoch": 0.00027639975499136005,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 76160
    },
    {
      "epoch": 0.00027651588934219675,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 76192
    },
    {
      "epoch": 0.00027663202369303345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6983,
      "step": 76224
    },
    {
      "epoch": 0.00027674815804387015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6912,
      "step": 76256
    },
    {
      "epoch": 0.00027686429239470685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6923,
      "step": 76288
    },
    {
      "epoch": 0.00027698042674554355,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6886,
      "step": 76320
    },
    {
      "epoch": 0.0002770965610963803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 76352
    },
    {
      "epoch": 0.000277212695447217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 76384
    },
    {
      "epoch": 0.0002773288297980537,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6853,
      "step": 76416
    },
    {
      "epoch": 0.0002774449641488904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 76448
    },
    {
      "epoch": 0.0002775610984997271,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 76480
    },
    {
      "epoch": 0.0002776772328505638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 76512
    },
    {
      "epoch": 0.0002777933672014005,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 76544
    },
    {
      "epoch": 0.0002779095015522372,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 76576
    },
    {
      "epoch": 0.0002780256359030739,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7396,
      "step": 76608
    },
    {
      "epoch": 0.00027814177025391065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7511,
      "step": 76640
    },
    {
      "epoch": 0.00027825790460474735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 76672
    },
    {
      "epoch": 0.00027837403895558405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 76704
    },
    {
      "epoch": 0.00027849017330642075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7512,
      "step": 76736
    },
    {
      "epoch": 0.00027860630765725745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 76768
    },
    {
      "epoch": 0.00027872244200809415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 76800
    },
    {
      "epoch": 0.00027883857635893085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 76832
    },
    {
      "epoch": 0.00027895471070976755,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7013,
      "step": 76864
    },
    {
      "epoch": 0.00027907084506060425,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7013,
      "step": 76896
    },
    {
      "epoch": 0.000279186979411441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 76928
    },
    {
      "epoch": 0.0002793031137622777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 76960
    },
    {
      "epoch": 0.0002794192481131144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 76992
    },
    {
      "epoch": 0.0002795353824639511,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6879,
      "step": 77024
    },
    {
      "epoch": 0.0002796515168147878,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 77056
    },
    {
      "epoch": 0.0002797676511656245,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6792,
      "step": 77088
    },
    {
      "epoch": 0.0002798837855164612,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 77120
    },
    {
      "epoch": 0.0002799999198672979,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6858,
      "step": 77152
    },
    {
      "epoch": 0.0002801160542181346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6955,
      "step": 77184
    },
    {
      "epoch": 0.00028023218856897136,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 77216
    },
    {
      "epoch": 0.00028034832291980806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 77248
    },
    {
      "epoch": 0.00028046445727064476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6916,
      "step": 77280
    },
    {
      "epoch": 0.00028058059162148146,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 77312
    },
    {
      "epoch": 0.00028069672597231816,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 77344
    },
    {
      "epoch": 0.00028081286032315486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 77376
    },
    {
      "epoch": 0.00028092899467399156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 77408
    },
    {
      "epoch": 0.00028104512902482826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 77440
    },
    {
      "epoch": 0.00028116126337566496,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7308,
      "step": 77472
    },
    {
      "epoch": 0.0002812773977265017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7268,
      "step": 77504
    },
    {
      "epoch": 0.0002813935320773384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7369,
      "step": 77536
    },
    {
      "epoch": 0.0002815096664281751,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7397,
      "step": 77568
    },
    {
      "epoch": 0.0002816258007790118,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 77600
    },
    {
      "epoch": 0.0002817419351298485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 77632
    },
    {
      "epoch": 0.0002818580694806852,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 77664
    },
    {
      "epoch": 0.0002819742038315219,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 77696
    },
    {
      "epoch": 0.0002820903381823586,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 77728
    },
    {
      "epoch": 0.0002822064725331953,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.691,
      "step": 77760
    },
    {
      "epoch": 0.00028232260688403207,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6859,
      "step": 77792
    },
    {
      "epoch": 0.00028243874123486877,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 77824
    },
    {
      "epoch": 0.00028255487558570547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 77856
    },
    {
      "epoch": 0.00028267100993654217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6922,
      "step": 77888
    },
    {
      "epoch": 0.00028278714428737887,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6896,
      "step": 77920
    },
    {
      "epoch": 0.00028290327863821557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 77952
    },
    {
      "epoch": 0.00028301941298905227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 77984
    },
    {
      "epoch": 0.00028313554733988897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 78016
    },
    {
      "epoch": 0.00028325168169072567,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 78048
    },
    {
      "epoch": 0.0002833678160415624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 78080
    },
    {
      "epoch": 0.0002834839503923991,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 78112
    },
    {
      "epoch": 0.0002836000847432358,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 78144
    },
    {
      "epoch": 0.0002837162190940725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 78176
    },
    {
      "epoch": 0.0002838323534449092,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 78208
    },
    {
      "epoch": 0.0002839484877957459,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.736,
      "step": 78240
    },
    {
      "epoch": 0.0002840646221465826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 78272
    },
    {
      "epoch": 0.0002841807564974193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 78304
    },
    {
      "epoch": 0.000284296890848256,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 78336
    },
    {
      "epoch": 0.0002844130251990927,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 78368
    },
    {
      "epoch": 0.0002845291595499295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 78400
    },
    {
      "epoch": 0.0002846452939007662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7429,
      "step": 78432
    },
    {
      "epoch": 0.0002847614282516029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 78464
    },
    {
      "epoch": 0.0002848775626024396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 78496
    },
    {
      "epoch": 0.0002849936969532763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6813,
      "step": 78528
    },
    {
      "epoch": 0.000285109831304113,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6855,
      "step": 78560
    },
    {
      "epoch": 0.0002852259656549497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 78592
    },
    {
      "epoch": 0.0002853421000057864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 78624
    },
    {
      "epoch": 0.0002854582343566231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 78656
    },
    {
      "epoch": 0.00028557436870745983,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6895,
      "step": 78688
    },
    {
      "epoch": 0.00028569050305829653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 78720
    },
    {
      "epoch": 0.00028580663740913323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.737,
      "step": 78752
    },
    {
      "epoch": 0.00028592277175996993,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 78784
    },
    {
      "epoch": 0.00028603890611080663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 78816
    },
    {
      "epoch": 0.00028615504046164333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6909,
      "step": 78848
    },
    {
      "epoch": 0.00028627117481248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 78880
    },
    {
      "epoch": 0.0002863873091633167,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 78912
    },
    {
      "epoch": 0.0002865034435141534,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7284,
      "step": 78944
    },
    {
      "epoch": 0.0002866195778649902,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 78976
    },
    {
      "epoch": 0.0002867357122158269,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 79008
    },
    {
      "epoch": 0.0002868518465666636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 79040
    },
    {
      "epoch": 0.0002869679809175003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 79072
    },
    {
      "epoch": 0.000287084115268337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 79104
    },
    {
      "epoch": 0.0002872002496191737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 79136
    },
    {
      "epoch": 0.0002873163839700104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 79168
    },
    {
      "epoch": 0.0002874325183208471,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7301,
      "step": 79200
    },
    {
      "epoch": 0.0002875486526716838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 79232
    },
    {
      "epoch": 0.00028766478702252053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 79264
    },
    {
      "epoch": 0.00028778092137335723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 79296
    },
    {
      "epoch": 0.00028789705572419393,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 79328
    },
    {
      "epoch": 0.00028801319007503063,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6842,
      "step": 79360
    },
    {
      "epoch": 0.00028812932442586733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 79392
    },
    {
      "epoch": 0.00028824545877670403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6878,
      "step": 79424
    },
    {
      "epoch": 0.00028836159312754073,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6707,
      "step": 79456
    },
    {
      "epoch": 0.00028847772747837743,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 79488
    },
    {
      "epoch": 0.00028859386182921413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 79520
    },
    {
      "epoch": 0.0002887099961800509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 79552
    },
    {
      "epoch": 0.0002888261305308876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 79584
    },
    {
      "epoch": 0.0002889422648817243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 79616
    },
    {
      "epoch": 0.000289058399232561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 79648
    },
    {
      "epoch": 0.0002891745335833977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 79680
    },
    {
      "epoch": 0.0002892906679342344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 79712
    },
    {
      "epoch": 0.0002894068022850711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 79744
    },
    {
      "epoch": 0.0002895229366359078,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7237,
      "step": 79776
    },
    {
      "epoch": 0.0002896390709867445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 79808
    },
    {
      "epoch": 0.00028975520533758124,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6952,
      "step": 79840
    },
    {
      "epoch": 0.00028987133968841794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7008,
      "step": 79872
    },
    {
      "epoch": 0.00028998747403925464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 79904
    },
    {
      "epoch": 0.00029010360839009134,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 79936
    },
    {
      "epoch": 0.00029021974274092804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 79968
    },
    {
      "epoch": 0.00029033587709176474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 80000
    },
    {
      "epoch": 0.00029045201144260144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 80032
    },
    {
      "epoch": 0.00029056814579343814,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 80064
    },
    {
      "epoch": 0.00029068428014427484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 80096
    },
    {
      "epoch": 0.0002908004144951116,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 80128
    },
    {
      "epoch": 0.0002909165488459483,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 80160
    },
    {
      "epoch": 0.000291032683196785,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 80192
    },
    {
      "epoch": 0.0002911488175476217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6792,
      "step": 80224
    },
    {
      "epoch": 0.0002912649518984584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 80256
    },
    {
      "epoch": 0.0002913810862492951,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 80288
    },
    {
      "epoch": 0.0002914972206001318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 80320
    },
    {
      "epoch": 0.0002916133549509685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 80352
    },
    {
      "epoch": 0.0002917294893018052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 80384
    },
    {
      "epoch": 0.00029184562365264195,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 80416
    },
    {
      "epoch": 0.00029196175800347865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 80448
    },
    {
      "epoch": 0.00029207789235431535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 80480
    },
    {
      "epoch": 0.00029219402670515205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7429,
      "step": 80512
    },
    {
      "epoch": 0.00029231016105598875,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 80544
    },
    {
      "epoch": 0.00029242629540682545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 80576
    },
    {
      "epoch": 0.00029254242975766215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6937,
      "step": 80608
    },
    {
      "epoch": 0.00029265856410849885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 80640
    },
    {
      "epoch": 0.00029277469845933555,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 80672
    },
    {
      "epoch": 0.0002928908328101723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 80704
    },
    {
      "epoch": 0.000293006967161009,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 80736
    },
    {
      "epoch": 0.0002931231015118457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 80768
    },
    {
      "epoch": 0.0002932392358626824,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 80800
    },
    {
      "epoch": 0.0002933553702135191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7013,
      "step": 80832
    },
    {
      "epoch": 0.0002934715045643558,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 80864
    },
    {
      "epoch": 0.0002935876389151925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 80896
    },
    {
      "epoch": 0.0002937037732660292,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 80928
    },
    {
      "epoch": 0.0002938199076168659,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 80960
    },
    {
      "epoch": 0.00029393604196770265,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 80992
    },
    {
      "epoch": 0.00029405217631853935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7402,
      "step": 81024
    },
    {
      "epoch": 0.00029416831066937605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 81056
    },
    {
      "epoch": 0.00029428444502021275,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 81088
    },
    {
      "epoch": 0.00029440057937104945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 81120
    },
    {
      "epoch": 0.00029451671372188615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 81152
    },
    {
      "epoch": 0.00029463284807272285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 81184
    },
    {
      "epoch": 0.00029474898242355955,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 81216
    },
    {
      "epoch": 0.00029486511677439625,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 81248
    },
    {
      "epoch": 0.000294981251125233,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7322,
      "step": 81280
    },
    {
      "epoch": 0.0002950973854760697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 81312
    },
    {
      "epoch": 0.0002952135198269064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 81344
    },
    {
      "epoch": 0.0002953296541777431,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 81376
    },
    {
      "epoch": 0.0002954457885285798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 81408
    },
    {
      "epoch": 0.0002955619228794165,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 81440
    },
    {
      "epoch": 0.0002956780572302532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 81472
    },
    {
      "epoch": 0.0002957941915810899,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 81504
    },
    {
      "epoch": 0.0002959103259319266,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 81536
    },
    {
      "epoch": 0.00029602646028276336,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 81568
    },
    {
      "epoch": 0.00029614259463360006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6759,
      "step": 81600
    },
    {
      "epoch": 0.00029625872898443676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6973,
      "step": 81632
    },
    {
      "epoch": 0.00029637486333527346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 81664
    },
    {
      "epoch": 0.00029649099768611016,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 81696
    },
    {
      "epoch": 0.00029660713203694686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 81728
    },
    {
      "epoch": 0.00029672326638778356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 81760
    },
    {
      "epoch": 0.00029683940073862026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 81792
    },
    {
      "epoch": 0.00029695553508945696,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 81824
    },
    {
      "epoch": 0.0002970716694402937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 81856
    },
    {
      "epoch": 0.0002971878037911304,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7396,
      "step": 81888
    },
    {
      "epoch": 0.0002973039381419671,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 81920
    },
    {
      "epoch": 0.0002974200724928038,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.729,
      "step": 81952
    },
    {
      "epoch": 0.0002975362068436405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 81984
    },
    {
      "epoch": 0.0002976523411944772,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 82016
    },
    {
      "epoch": 0.0002977684755453139,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 82048
    },
    {
      "epoch": 0.0002978846098961506,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 82080
    },
    {
      "epoch": 0.0002980007442469873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 82112
    },
    {
      "epoch": 0.00029811687859782407,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 82144
    },
    {
      "epoch": 0.00029823301294866077,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 82176
    },
    {
      "epoch": 0.00029834914729949747,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 82208
    },
    {
      "epoch": 0.00029846528165033417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 82240
    },
    {
      "epoch": 0.00029858141600117087,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 82272
    },
    {
      "epoch": 0.00029869755035200757,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6895,
      "step": 82304
    },
    {
      "epoch": 0.00029881368470284427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6983,
      "step": 82336
    },
    {
      "epoch": 0.00029892981905368097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6822,
      "step": 82368
    },
    {
      "epoch": 0.00029904595340451767,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6839,
      "step": 82400
    },
    {
      "epoch": 0.0002991620877553544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6902,
      "step": 82432
    },
    {
      "epoch": 0.0002992782221061911,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6985,
      "step": 82464
    },
    {
      "epoch": 0.0002993943564570278,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 82496
    },
    {
      "epoch": 0.0002995104908078645,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 82528
    },
    {
      "epoch": 0.0002996266251587012,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7288,
      "step": 82560
    },
    {
      "epoch": 0.0002997427595095379,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 82592
    },
    {
      "epoch": 0.0002998588938603746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 82624
    },
    {
      "epoch": 0.0002999750282112113,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 82656
    },
    {
      "epoch": 0.000300091162562048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 82688
    },
    {
      "epoch": 0.0003002072969128848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7437,
      "step": 82720
    },
    {
      "epoch": 0.0003003234312637215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7403,
      "step": 82752
    },
    {
      "epoch": 0.0003004395656145582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 82784
    },
    {
      "epoch": 0.0003005556999653949,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 82816
    },
    {
      "epoch": 0.0003006718343162316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 82848
    },
    {
      "epoch": 0.0003007879686670683,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 82880
    },
    {
      "epoch": 0.000300904103017905,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 82912
    },
    {
      "epoch": 0.0003010202373687417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 82944
    },
    {
      "epoch": 0.0003011363717195784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 82976
    },
    {
      "epoch": 0.00030125250607041513,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 83008
    },
    {
      "epoch": 0.00030136864042125183,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 83040
    },
    {
      "epoch": 0.00030148477477208853,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6994,
      "step": 83072
    },
    {
      "epoch": 0.00030160090912292523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 83104
    },
    {
      "epoch": 0.00030171704347376193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 83136
    },
    {
      "epoch": 0.00030183317782459863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6895,
      "step": 83168
    },
    {
      "epoch": 0.00030194931217543533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6948,
      "step": 83200
    },
    {
      "epoch": 0.00030206544652627203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 83232
    },
    {
      "epoch": 0.00030218158087710873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 83264
    },
    {
      "epoch": 0.0003022977152279455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 83296
    },
    {
      "epoch": 0.0003024138495787822,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 83328
    },
    {
      "epoch": 0.0003025299839296189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 83360
    },
    {
      "epoch": 0.0003026461182804556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 83392
    },
    {
      "epoch": 0.0003027622526312923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 83424
    },
    {
      "epoch": 0.000302878386982129,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7526,
      "step": 83456
    },
    {
      "epoch": 0.0003029945213329657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 83488
    },
    {
      "epoch": 0.0003031106556838024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7248,
      "step": 83520
    },
    {
      "epoch": 0.0003032267900346391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7499,
      "step": 83552
    },
    {
      "epoch": 0.0003033429243854758,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 83584
    },
    {
      "epoch": 0.00030345905873631254,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 83616
    },
    {
      "epoch": 0.00030357519308714924,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 83648
    },
    {
      "epoch": 0.00030369132743798594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 83680
    },
    {
      "epoch": 0.00030380746178882264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 83712
    },
    {
      "epoch": 0.00030392359613965934,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 83744
    },
    {
      "epoch": 0.00030403973049049604,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6963,
      "step": 83776
    },
    {
      "epoch": 0.00030415586484133273,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 83808
    },
    {
      "epoch": 0.00030427199919216943,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6902,
      "step": 83840
    },
    {
      "epoch": 0.00030438813354300613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 83872
    },
    {
      "epoch": 0.0003045042678938429,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6923,
      "step": 83904
    },
    {
      "epoch": 0.0003046204022446796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6894,
      "step": 83936
    },
    {
      "epoch": 0.0003047365365955163,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6923,
      "step": 83968
    },
    {
      "epoch": 0.000304852670946353,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 84000
    },
    {
      "epoch": 0.0003049688052971897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 84032
    },
    {
      "epoch": 0.0003050849396480264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 84064
    },
    {
      "epoch": 0.0003052010739988631,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6977,
      "step": 84096
    },
    {
      "epoch": 0.0003053172083496998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6895,
      "step": 84128
    },
    {
      "epoch": 0.0003054333427005365,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 84160
    },
    {
      "epoch": 0.00030554947705137324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 84192
    },
    {
      "epoch": 0.00030566561140220994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 84224
    },
    {
      "epoch": 0.00030578174575304664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 84256
    },
    {
      "epoch": 0.00030589788010388334,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7334,
      "step": 84288
    },
    {
      "epoch": 0.00030601401445472004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7593,
      "step": 84320
    },
    {
      "epoch": 0.00030613014880555674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 84352
    },
    {
      "epoch": 0.00030624628315639344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 84384
    },
    {
      "epoch": 0.00030636241750723014,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 84416
    },
    {
      "epoch": 0.00030647855185806684,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 84448
    },
    {
      "epoch": 0.0003065946862089036,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7439,
      "step": 84480
    },
    {
      "epoch": 0.0003067108205597403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 84512
    },
    {
      "epoch": 0.000306826954910577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 84544
    },
    {
      "epoch": 0.0003069430892614137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6831,
      "step": 84576
    },
    {
      "epoch": 0.0003070592236122504,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 84608
    },
    {
      "epoch": 0.0003071753579630871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 84640
    },
    {
      "epoch": 0.0003072914923139238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6861,
      "step": 84672
    },
    {
      "epoch": 0.0003074076266647605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 84704
    },
    {
      "epoch": 0.0003075237610155972,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6925,
      "step": 84736
    },
    {
      "epoch": 0.00030763989536643395,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6864,
      "step": 84768
    },
    {
      "epoch": 0.00030775602971727065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 84800
    },
    {
      "epoch": 0.00030787216406810735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 84832
    },
    {
      "epoch": 0.00030798829841894405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 84864
    },
    {
      "epoch": 0.00030810443276978075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7293,
      "step": 84896
    },
    {
      "epoch": 0.00030822056712061745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 84928
    },
    {
      "epoch": 0.00030833670147145415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 84960
    },
    {
      "epoch": 0.00030845283582229085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 84992
    },
    {
      "epoch": 0.00030856897017312755,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6929,
      "step": 85024
    },
    {
      "epoch": 0.0003086851045239643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 85056
    },
    {
      "epoch": 0.000308801238874801,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 85088
    },
    {
      "epoch": 0.0003089173732256377,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 85120
    },
    {
      "epoch": 0.0003090335075764744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 85152
    },
    {
      "epoch": 0.0003091496419273111,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 85184
    },
    {
      "epoch": 0.0003092657762781478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7526,
      "step": 85216
    },
    {
      "epoch": 0.0003093819106289845,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7395,
      "step": 85248
    },
    {
      "epoch": 0.0003094980449798212,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 85280
    },
    {
      "epoch": 0.0003096141793306579,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 85312
    },
    {
      "epoch": 0.00030973031368149466,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6955,
      "step": 85344
    },
    {
      "epoch": 0.00030984644803233136,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6875,
      "step": 85376
    },
    {
      "epoch": 0.00030996258238316806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6982,
      "step": 85408
    },
    {
      "epoch": 0.00031007871673400476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6924,
      "step": 85440
    },
    {
      "epoch": 0.00031019485108484146,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 85472
    },
    {
      "epoch": 0.00031031098543567816,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 85504
    },
    {
      "epoch": 0.00031042711978651486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6888,
      "step": 85536
    },
    {
      "epoch": 0.00031054325413735156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 85568
    },
    {
      "epoch": 0.00031065938848818826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 85600
    },
    {
      "epoch": 0.000310775522839025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 85632
    },
    {
      "epoch": 0.0003108916571898617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 85664
    },
    {
      "epoch": 0.0003110077915406984,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 85696
    },
    {
      "epoch": 0.0003111239258915351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 85728
    },
    {
      "epoch": 0.0003112400602423718,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 85760
    },
    {
      "epoch": 0.0003113561945932085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 85792
    },
    {
      "epoch": 0.0003114723289440452,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7439,
      "step": 85824
    },
    {
      "epoch": 0.0003115884632948819,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 85856
    },
    {
      "epoch": 0.0003117045976457186,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 85888
    },
    {
      "epoch": 0.00031182073199655536,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6909,
      "step": 85920
    },
    {
      "epoch": 0.00031193686634739206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 85952
    },
    {
      "epoch": 0.00031205300069822876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 85984
    },
    {
      "epoch": 0.00031216913504906546,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 86016
    },
    {
      "epoch": 0.00031228526939990216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 86048
    },
    {
      "epoch": 0.00031240140375073886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7386,
      "step": 86080
    },
    {
      "epoch": 0.00031251753810157556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 86112
    },
    {
      "epoch": 0.00031263367245241226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 86144
    },
    {
      "epoch": 0.00031274980680324896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 86176
    },
    {
      "epoch": 0.0003128659411540857,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6869,
      "step": 86208
    },
    {
      "epoch": 0.0003129820755049224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 86240
    },
    {
      "epoch": 0.0003130982098557591,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 86272
    },
    {
      "epoch": 0.0003132143442065958,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 86304
    },
    {
      "epoch": 0.0003133304785574325,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 86336
    },
    {
      "epoch": 0.0003134466129082692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 86368
    },
    {
      "epoch": 0.0003135627472591059,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 86400
    },
    {
      "epoch": 0.0003136788816099426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 86432
    },
    {
      "epoch": 0.0003137950159607793,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 86464
    },
    {
      "epoch": 0.00031391115031161607,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 86496
    },
    {
      "epoch": 0.00031402728466245277,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 86528
    },
    {
      "epoch": 0.00031414341901328947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 86560
    },
    {
      "epoch": 0.00031425955336412617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 86592
    },
    {
      "epoch": 0.00031437568771496287,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 86624
    },
    {
      "epoch": 0.00031449182206579957,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 86656
    },
    {
      "epoch": 0.00031460795641663627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 86688
    },
    {
      "epoch": 0.00031472409076747297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 86720
    },
    {
      "epoch": 0.00031484022511830967,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 86752
    },
    {
      "epoch": 0.0003149563594691464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 86784
    },
    {
      "epoch": 0.0003150724938199831,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 86816
    },
    {
      "epoch": 0.0003151886281708198,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 86848
    },
    {
      "epoch": 0.0003153047625216565,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 86880
    },
    {
      "epoch": 0.0003154208968724932,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 86912
    },
    {
      "epoch": 0.0003155370312233299,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 86944
    },
    {
      "epoch": 0.0003156531655741666,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 86976
    },
    {
      "epoch": 0.0003157692999250033,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 87008
    },
    {
      "epoch": 0.00031588543427584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 87040
    },
    {
      "epoch": 0.0003160015686266768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 87072
    },
    {
      "epoch": 0.0003161177029775135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6929,
      "step": 87104
    },
    {
      "epoch": 0.0003162338373283502,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 87136
    },
    {
      "epoch": 0.0003163499716791869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 87168
    },
    {
      "epoch": 0.0003164661060300236,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 87200
    },
    {
      "epoch": 0.0003165822403808603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 87232
    },
    {
      "epoch": 0.000316698374731697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7273,
      "step": 87264
    },
    {
      "epoch": 0.0003168145090825337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 87296
    },
    {
      "epoch": 0.0003169306434333704,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 87328
    },
    {
      "epoch": 0.00031704677778420713,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 87360
    },
    {
      "epoch": 0.00031716291213504383,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 87392
    },
    {
      "epoch": 0.00031727904648588053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 87424
    },
    {
      "epoch": 0.00031739518083671723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6943,
      "step": 87456
    },
    {
      "epoch": 0.00031751131518755393,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 87488
    },
    {
      "epoch": 0.00031762744953839063,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 87520
    },
    {
      "epoch": 0.00031774358388922733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 87552
    },
    {
      "epoch": 0.00031785971824006403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 87584
    },
    {
      "epoch": 0.00031797585259090073,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6834,
      "step": 87616
    },
    {
      "epoch": 0.0003180919869417375,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 87648
    },
    {
      "epoch": 0.0003182081212925742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 87680
    },
    {
      "epoch": 0.0003183242556434109,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 87712
    },
    {
      "epoch": 0.0003184403899942476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 87744
    },
    {
      "epoch": 0.0003185565243450843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 87776
    },
    {
      "epoch": 0.000318672658695921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 87808
    },
    {
      "epoch": 0.0003187887930467577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7516,
      "step": 87840
    },
    {
      "epoch": 0.0003189049273975944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 87872
    },
    {
      "epoch": 0.0003190210617484311,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 87904
    },
    {
      "epoch": 0.00031913719609926784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 87936
    },
    {
      "epoch": 0.00031925333045010454,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 87968
    },
    {
      "epoch": 0.00031936946480094124,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 88000
    },
    {
      "epoch": 0.00031948559915177794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 88032
    },
    {
      "epoch": 0.00031960173350261464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 88064
    },
    {
      "epoch": 0.00031971786785345134,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7345,
      "step": 88096
    },
    {
      "epoch": 0.00031983400220428804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 88128
    },
    {
      "epoch": 0.00031995013655512474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7395,
      "step": 88160
    },
    {
      "epoch": 0.00032006627090596144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6917,
      "step": 88192
    },
    {
      "epoch": 0.0003201824052567982,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 88224
    },
    {
      "epoch": 0.0003202985396076349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 88256
    },
    {
      "epoch": 0.0003204146739584716,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 88288
    },
    {
      "epoch": 0.0003205308083093083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 88320
    },
    {
      "epoch": 0.000320646942660145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 88352
    },
    {
      "epoch": 0.0003207630770109817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6936,
      "step": 88384
    },
    {
      "epoch": 0.0003208792113618184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 88416
    },
    {
      "epoch": 0.0003209953457126551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 88448
    },
    {
      "epoch": 0.0003211114800634918,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6842,
      "step": 88480
    },
    {
      "epoch": 0.00032122761441432854,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6963,
      "step": 88512
    },
    {
      "epoch": 0.00032134374876516524,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 88544
    },
    {
      "epoch": 0.00032145988311600194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 88576
    },
    {
      "epoch": 0.00032157601746683864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.745,
      "step": 88608
    },
    {
      "epoch": 0.00032169215181767534,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 88640
    },
    {
      "epoch": 0.00032180828616851204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 88672
    },
    {
      "epoch": 0.00032192442051934874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 88704
    },
    {
      "epoch": 0.00032204055487018544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7472,
      "step": 88736
    },
    {
      "epoch": 0.00032215668922102214,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7595,
      "step": 88768
    },
    {
      "epoch": 0.0003222728235718589,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 88800
    },
    {
      "epoch": 0.0003223889579226956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 88832
    },
    {
      "epoch": 0.0003225050922735323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 88864
    },
    {
      "epoch": 0.000322621226624369,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 88896
    },
    {
      "epoch": 0.0003227373609752057,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 88928
    },
    {
      "epoch": 0.0003228534953260424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 88960
    },
    {
      "epoch": 0.0003229696296768791,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 88992
    },
    {
      "epoch": 0.0003230857640277158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 89024
    },
    {
      "epoch": 0.0003232018983785525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 89056
    },
    {
      "epoch": 0.0003233180327293892,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 89088
    },
    {
      "epoch": 0.00032343416708022595,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6898,
      "step": 89120
    },
    {
      "epoch": 0.00032355030143106265,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6818,
      "step": 89152
    },
    {
      "epoch": 0.00032366643578189935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 89184
    },
    {
      "epoch": 0.00032378257013273605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 89216
    },
    {
      "epoch": 0.00032389870448357275,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6843,
      "step": 89248
    },
    {
      "epoch": 0.00032401483883440945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6893,
      "step": 89280
    },
    {
      "epoch": 0.00032413097318524615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6951,
      "step": 89312
    },
    {
      "epoch": 0.00032424710753608285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 89344
    },
    {
      "epoch": 0.00032436324188691955,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7275,
      "step": 89376
    },
    {
      "epoch": 0.0003244793762377563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 89408
    },
    {
      "epoch": 0.000324595510588593,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 89440
    },
    {
      "epoch": 0.0003247116449394297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 89472
    },
    {
      "epoch": 0.0003248277792902664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7304,
      "step": 89504
    },
    {
      "epoch": 0.0003249439136411031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7494,
      "step": 89536
    },
    {
      "epoch": 0.0003250600479919398,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 89568
    },
    {
      "epoch": 0.0003251761823427765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.755,
      "step": 89600
    },
    {
      "epoch": 0.0003252923166936132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7415,
      "step": 89632
    },
    {
      "epoch": 0.0003254084510444499,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6919,
      "step": 89664
    },
    {
      "epoch": 0.00032552458539528666,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 89696
    },
    {
      "epoch": 0.00032564071974612336,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 89728
    },
    {
      "epoch": 0.00032575685409696006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 89760
    },
    {
      "epoch": 0.00032587298844779676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7205,
      "step": 89792
    },
    {
      "epoch": 0.00032598912279863346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 89824
    },
    {
      "epoch": 0.00032610525714947016,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 89856
    },
    {
      "epoch": 0.00032622139150030686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 89888
    },
    {
      "epoch": 0.00032633752585114356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 89920
    },
    {
      "epoch": 0.00032645366020198026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 89952
    },
    {
      "epoch": 0.000326569794552817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6946,
      "step": 89984
    },
    {
      "epoch": 0.0003266859289036537,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.693,
      "step": 90016
    },
    {
      "epoch": 0.0003268020632544904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6793,
      "step": 90048
    },
    {
      "epoch": 0.0003269181976053271,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6886,
      "step": 90080
    },
    {
      "epoch": 0.0003270343319561638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 90112
    },
    {
      "epoch": 0.0003271504663070005,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 90144
    },
    {
      "epoch": 0.0003272666006578372,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6923,
      "step": 90176
    },
    {
      "epoch": 0.0003273827350086739,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 90208
    },
    {
      "epoch": 0.0003274988693595106,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 90240
    },
    {
      "epoch": 0.00032761500371034736,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7277,
      "step": 90272
    },
    {
      "epoch": 0.00032773113806118406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7369,
      "step": 90304
    },
    {
      "epoch": 0.00032784727241202076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 90336
    },
    {
      "epoch": 0.00032796340676285746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7493,
      "step": 90368
    },
    {
      "epoch": 0.00032807954111369416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 90400
    },
    {
      "epoch": 0.00032819567546453086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 90432
    },
    {
      "epoch": 0.00032831180981536756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 90464
    },
    {
      "epoch": 0.00032842794416620426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 90496
    },
    {
      "epoch": 0.00032854407851704096,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 90528
    },
    {
      "epoch": 0.0003286602128678777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 90560
    },
    {
      "epoch": 0.0003287763472187144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 90592
    },
    {
      "epoch": 0.0003288924815695511,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 90624
    },
    {
      "epoch": 0.0003290086159203878,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6836,
      "step": 90656
    },
    {
      "epoch": 0.0003291247502712245,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6874,
      "step": 90688
    },
    {
      "epoch": 0.0003292408846220612,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 90720
    },
    {
      "epoch": 0.0003293570189728979,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 90752
    },
    {
      "epoch": 0.0003294731533237346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7004,
      "step": 90784
    },
    {
      "epoch": 0.0003295892876745713,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.686,
      "step": 90816
    },
    {
      "epoch": 0.00032970542202540807,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6931,
      "step": 90848
    },
    {
      "epoch": 0.00032982155637624477,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 90880
    },
    {
      "epoch": 0.00032993769072708147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 90912
    },
    {
      "epoch": 0.00033005382507791817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 90944
    },
    {
      "epoch": 0.00033016995942875487,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 90976
    },
    {
      "epoch": 0.00033028609377959157,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 91008
    },
    {
      "epoch": 0.00033040222813042827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 91040
    },
    {
      "epoch": 0.00033051836248126497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7301,
      "step": 91072
    },
    {
      "epoch": 0.00033063449683210167,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 91104
    },
    {
      "epoch": 0.0003307506311829384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7384,
      "step": 91136
    },
    {
      "epoch": 0.0003308667655337751,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 91168
    },
    {
      "epoch": 0.0003309828998846118,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 91200
    },
    {
      "epoch": 0.0003310990342354485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 91232
    },
    {
      "epoch": 0.0003312151685862852,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 91264
    },
    {
      "epoch": 0.0003313313029371219,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7262,
      "step": 91296
    },
    {
      "epoch": 0.0003314474372879586,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7519,
      "step": 91328
    },
    {
      "epoch": 0.0003315635716387953,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 91360
    },
    {
      "epoch": 0.000331679705989632,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 91392
    },
    {
      "epoch": 0.0003317958403404688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6816,
      "step": 91424
    },
    {
      "epoch": 0.0003319119746913055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6889,
      "step": 91456
    },
    {
      "epoch": 0.0003320281090421422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 91488
    },
    {
      "epoch": 0.0003321442433929789,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6959,
      "step": 91520
    },
    {
      "epoch": 0.0003322603777438156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 91552
    },
    {
      "epoch": 0.0003323765120946523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 91584
    },
    {
      "epoch": 0.000332492646445489,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7004,
      "step": 91616
    },
    {
      "epoch": 0.0003326087807963257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 91648
    },
    {
      "epoch": 0.0003327249151471624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 91680
    },
    {
      "epoch": 0.00033284104949799913,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 91712
    },
    {
      "epoch": 0.00033295718384883583,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 91744
    },
    {
      "epoch": 0.00033307331819967253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7205,
      "step": 91776
    },
    {
      "epoch": 0.00033318945255050923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 91808
    },
    {
      "epoch": 0.00033330558690134593,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 91840
    },
    {
      "epoch": 0.00033342172125218263,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 91872
    },
    {
      "epoch": 0.00033353785560301933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 91904
    },
    {
      "epoch": 0.00033365398995385603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 91936
    },
    {
      "epoch": 0.00033377012430469273,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 91968
    },
    {
      "epoch": 0.0003338862586555295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 92000
    },
    {
      "epoch": 0.0003340023930063662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 92032
    },
    {
      "epoch": 0.0003341185273572029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 92064
    },
    {
      "epoch": 0.0003342346617080396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 92096
    },
    {
      "epoch": 0.0003343507960588763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7346,
      "step": 92128
    },
    {
      "epoch": 0.000334466930409713,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 92160
    },
    {
      "epoch": 0.0003345830647605497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 92192
    },
    {
      "epoch": 0.0003346991991113864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6836,
      "step": 92224
    },
    {
      "epoch": 0.0003348153334622231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6985,
      "step": 92256
    },
    {
      "epoch": 0.00033493146781305984,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 92288
    },
    {
      "epoch": 0.00033504760216389654,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6839,
      "step": 92320
    },
    {
      "epoch": 0.00033516373651473324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6886,
      "step": 92352
    },
    {
      "epoch": 0.00033527987086556994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 92384
    },
    {
      "epoch": 0.00033539600521640664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 92416
    },
    {
      "epoch": 0.00033551213956724334,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 92448
    },
    {
      "epoch": 0.00033562827391808004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 92480
    },
    {
      "epoch": 0.00033574440826891674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6994,
      "step": 92512
    },
    {
      "epoch": 0.00033586054261975344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 92544
    },
    {
      "epoch": 0.0003359766769705902,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 92576
    },
    {
      "epoch": 0.0003360928113214269,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 92608
    },
    {
      "epoch": 0.0003362089456722636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 92640
    },
    {
      "epoch": 0.0003363250800231003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 92672
    },
    {
      "epoch": 0.000336441214373937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 92704
    },
    {
      "epoch": 0.0003365573487247737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7004,
      "step": 92736
    },
    {
      "epoch": 0.0003366734830756104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 92768
    },
    {
      "epoch": 0.0003367896174264471,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 92800
    },
    {
      "epoch": 0.0003369057517772838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 92832
    },
    {
      "epoch": 0.00033702188612812054,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 92864
    },
    {
      "epoch": 0.00033713802047895724,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 92896
    },
    {
      "epoch": 0.00033725415482979394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 92928
    },
    {
      "epoch": 0.00033737028918063064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 92960
    },
    {
      "epoch": 0.00033748642353146734,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 92992
    },
    {
      "epoch": 0.00033760255788230404,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 93024
    },
    {
      "epoch": 0.00033771869223314074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7309,
      "step": 93056
    },
    {
      "epoch": 0.00033783482658397744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6899,
      "step": 93088
    },
    {
      "epoch": 0.00033795096093481414,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.686,
      "step": 93120
    },
    {
      "epoch": 0.0003380670952856509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 93152
    },
    {
      "epoch": 0.0003381832296364876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 93184
    },
    {
      "epoch": 0.0003382993639873243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 93216
    },
    {
      "epoch": 0.000338415498338161,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 93248
    },
    {
      "epoch": 0.0003385316326889977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 93280
    },
    {
      "epoch": 0.0003386477670398344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7378,
      "step": 93312
    },
    {
      "epoch": 0.0003387639013906711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 93344
    },
    {
      "epoch": 0.0003388800357415078,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 93376
    },
    {
      "epoch": 0.0003389961700923445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 93408
    },
    {
      "epoch": 0.00033911230444318125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 93440
    },
    {
      "epoch": 0.00033922843879401795,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 93472
    },
    {
      "epoch": 0.00033934457314485465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 93504
    },
    {
      "epoch": 0.00033946070749569135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6983,
      "step": 93536
    },
    {
      "epoch": 0.00033957684184652805,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 93568
    },
    {
      "epoch": 0.00033969297619736475,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 93600
    },
    {
      "epoch": 0.00033980911054820145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 93632
    },
    {
      "epoch": 0.00033992524489903815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 93664
    },
    {
      "epoch": 0.00034004137924987485,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 93696
    },
    {
      "epoch": 0.0003401575136007116,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 93728
    },
    {
      "epoch": 0.0003402736479515483,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 93760
    },
    {
      "epoch": 0.000340389782302385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 93792
    },
    {
      "epoch": 0.0003405059166532217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 93824
    },
    {
      "epoch": 0.0003406220510040584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6948,
      "step": 93856
    },
    {
      "epoch": 0.0003407381853548951,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7337,
      "step": 93888
    },
    {
      "epoch": 0.0003408543197057318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7354,
      "step": 93920
    },
    {
      "epoch": 0.0003409704540565685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 93952
    },
    {
      "epoch": 0.0003410865884074052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 93984
    },
    {
      "epoch": 0.00034120272275824196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 94016
    },
    {
      "epoch": 0.00034131885710907866,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 94048
    },
    {
      "epoch": 0.00034143499145991536,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 94080
    },
    {
      "epoch": 0.00034155112581075206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 94112
    },
    {
      "epoch": 0.00034166726016158876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 94144
    },
    {
      "epoch": 0.00034178339451242546,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 94176
    },
    {
      "epoch": 0.00034189952886326216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 94208
    },
    {
      "epoch": 0.00034201566321409886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 94240
    },
    {
      "epoch": 0.00034213179756493556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 94272
    },
    {
      "epoch": 0.00034224793191577226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 94304
    },
    {
      "epoch": 0.000342364066266609,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 94336
    },
    {
      "epoch": 0.0003424802006174457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6917,
      "step": 94368
    },
    {
      "epoch": 0.0003425963349682824,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 94400
    },
    {
      "epoch": 0.0003427124693191191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 94432
    },
    {
      "epoch": 0.0003428286036699558,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6837,
      "step": 94464
    },
    {
      "epoch": 0.0003429447380207925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 94496
    },
    {
      "epoch": 0.0003430608723716292,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 94528
    },
    {
      "epoch": 0.0003431770067224659,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6961,
      "step": 94560
    },
    {
      "epoch": 0.0003432931410733026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 94592
    },
    {
      "epoch": 0.00034340927542413937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 94624
    },
    {
      "epoch": 0.00034352540977497606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 94656
    },
    {
      "epoch": 0.00034364154412581276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7358,
      "step": 94688
    },
    {
      "epoch": 0.00034375767847664946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 94720
    },
    {
      "epoch": 0.00034387381282748616,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 94752
    },
    {
      "epoch": 0.00034398994717832286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 94784
    },
    {
      "epoch": 0.00034410608152915956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 94816
    },
    {
      "epoch": 0.00034422221587999626,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 94848
    },
    {
      "epoch": 0.00034433835023083296,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 94880
    },
    {
      "epoch": 0.0003444544845816697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7415,
      "step": 94912
    },
    {
      "epoch": 0.0003445706189325064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 94944
    },
    {
      "epoch": 0.0003446867532833431,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 94976
    },
    {
      "epoch": 0.0003448028876341798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 95008
    },
    {
      "epoch": 0.0003449190219850165,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 95040
    },
    {
      "epoch": 0.0003450351563358532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 95072
    },
    {
      "epoch": 0.0003451512906866899,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 95104
    },
    {
      "epoch": 0.0003452674250375266,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 95136
    },
    {
      "epoch": 0.0003453835593883633,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 95168
    },
    {
      "epoch": 0.00034549969373920007,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 95200
    },
    {
      "epoch": 0.00034561582809003677,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 95232
    },
    {
      "epoch": 0.00034573196244087347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6795,
      "step": 95264
    },
    {
      "epoch": 0.00034584809679171017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6912,
      "step": 95296
    },
    {
      "epoch": 0.00034596423114254687,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6799,
      "step": 95328
    },
    {
      "epoch": 0.00034608036549338357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 95360
    },
    {
      "epoch": 0.00034619649984422027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 95392
    },
    {
      "epoch": 0.00034631263419505697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.73,
      "step": 95424
    },
    {
      "epoch": 0.00034642876854589367,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 95456
    },
    {
      "epoch": 0.0003465449028967304,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 95488
    },
    {
      "epoch": 0.0003466610372475671,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7388,
      "step": 95520
    },
    {
      "epoch": 0.0003467771715984038,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 95552
    },
    {
      "epoch": 0.0003468933059492405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 95584
    },
    {
      "epoch": 0.0003470094403000772,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.745,
      "step": 95616
    },
    {
      "epoch": 0.0003471255746509139,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 95648
    },
    {
      "epoch": 0.0003472417090017506,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7275,
      "step": 95680
    },
    {
      "epoch": 0.0003473578433525873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 95712
    },
    {
      "epoch": 0.000347473977703424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 95744
    },
    {
      "epoch": 0.0003475901120542608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 95776
    },
    {
      "epoch": 0.0003477062464050975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7336,
      "step": 95808
    },
    {
      "epoch": 0.0003478223807559342,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 95840
    },
    {
      "epoch": 0.0003479385151067709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 95872
    },
    {
      "epoch": 0.0003480546494576076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 95904
    },
    {
      "epoch": 0.0003481707838084443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 95936
    },
    {
      "epoch": 0.000348286918159281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6983,
      "step": 95968
    },
    {
      "epoch": 0.0003484030525101177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6904,
      "step": 96000
    },
    {
      "epoch": 0.0003485191868609544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6887,
      "step": 96032
    },
    {
      "epoch": 0.00034863532121179113,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 96064
    },
    {
      "epoch": 0.00034875145556262783,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 96096
    },
    {
      "epoch": 0.00034886758991346453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 96128
    },
    {
      "epoch": 0.00034898372426430123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6962,
      "step": 96160
    },
    {
      "epoch": 0.00034909985861513793,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 96192
    },
    {
      "epoch": 0.00034921599296597463,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6997,
      "step": 96224
    },
    {
      "epoch": 0.00034933212731681133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 96256
    },
    {
      "epoch": 0.00034944826166764803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 96288
    },
    {
      "epoch": 0.00034956439601848473,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 96320
    },
    {
      "epoch": 0.0003496805303693215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 96352
    },
    {
      "epoch": 0.0003497966647201582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.742,
      "step": 96384
    },
    {
      "epoch": 0.0003499127990709949,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7409,
      "step": 96416
    },
    {
      "epoch": 0.0003500289334218316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7445,
      "step": 96448
    },
    {
      "epoch": 0.0003501450677726683,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 96480
    },
    {
      "epoch": 0.000350261202123505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 96512
    },
    {
      "epoch": 0.0003503773364743417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6951,
      "step": 96544
    },
    {
      "epoch": 0.0003504934708251784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 96576
    },
    {
      "epoch": 0.0003506096051760151,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 96608
    },
    {
      "epoch": 0.00035072573952685184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 96640
    },
    {
      "epoch": 0.00035084187387768854,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7205,
      "step": 96672
    },
    {
      "epoch": 0.00035095800822852524,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6897,
      "step": 96704
    },
    {
      "epoch": 0.00035107414257936194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 96736
    },
    {
      "epoch": 0.00035119027693019864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6897,
      "step": 96768
    },
    {
      "epoch": 0.00035130641128103534,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.68,
      "step": 96800
    },
    {
      "epoch": 0.00035142254563187204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 96832
    },
    {
      "epoch": 0.00035153867998270874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 96864
    },
    {
      "epoch": 0.00035165481433354544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 96896
    },
    {
      "epoch": 0.0003517709486843822,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 96928
    },
    {
      "epoch": 0.0003518870830352189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 96960
    },
    {
      "epoch": 0.0003520032173860556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 96992
    },
    {
      "epoch": 0.0003521193517368923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 97024
    },
    {
      "epoch": 0.000352235486087729,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 97056
    },
    {
      "epoch": 0.0003523516204385657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 97088
    },
    {
      "epoch": 0.0003524677547894024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 97120
    },
    {
      "epoch": 0.0003525838891402391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 97152
    },
    {
      "epoch": 0.0003527000234910758,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7452,
      "step": 97184
    },
    {
      "epoch": 0.00035281615784191255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 97216
    },
    {
      "epoch": 0.00035293229219274925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7366,
      "step": 97248
    },
    {
      "epoch": 0.00035304842654358595,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 97280
    },
    {
      "epoch": 0.00035316456089442265,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 97312
    },
    {
      "epoch": 0.00035328069524525935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7395,
      "step": 97344
    },
    {
      "epoch": 0.00035339682959609605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 97376
    },
    {
      "epoch": 0.00035351296394693275,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6907,
      "step": 97408
    },
    {
      "epoch": 0.00035362909829776945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 97440
    },
    {
      "epoch": 0.00035374523264860615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.693,
      "step": 97472
    },
    {
      "epoch": 0.0003538613669994429,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6915,
      "step": 97504
    },
    {
      "epoch": 0.0003539775013502796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6861,
      "step": 97536
    },
    {
      "epoch": 0.0003540936357011163,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7026,
      "step": 97568
    },
    {
      "epoch": 0.000354209770051953,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 97600
    },
    {
      "epoch": 0.0003543259044027897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6842,
      "step": 97632
    },
    {
      "epoch": 0.0003544420387536264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 97664
    },
    {
      "epoch": 0.0003545581731044631,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 97696
    },
    {
      "epoch": 0.0003546743074552998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 97728
    },
    {
      "epoch": 0.0003547904418061365,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 97760
    },
    {
      "epoch": 0.00035490657615697325,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 97792
    },
    {
      "epoch": 0.00035502271050780995,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 97824
    },
    {
      "epoch": 0.00035513884485864665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 97856
    },
    {
      "epoch": 0.00035525497920948335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 97888
    },
    {
      "epoch": 0.00035537111356032005,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 97920
    },
    {
      "epoch": 0.00035548724791115675,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7369,
      "step": 97952
    },
    {
      "epoch": 0.00035560338226199345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 97984
    },
    {
      "epoch": 0.00035571951661283015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 98016
    },
    {
      "epoch": 0.00035583565096366685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 98048
    },
    {
      "epoch": 0.0003559517853145036,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 98080
    },
    {
      "epoch": 0.0003560679196653403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7385,
      "step": 98112
    },
    {
      "epoch": 0.000356184054016177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 98144
    },
    {
      "epoch": 0.0003563001883670137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7414,
      "step": 98176
    },
    {
      "epoch": 0.0003564163227178504,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 98208
    },
    {
      "epoch": 0.0003565324570686871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.679,
      "step": 98240
    },
    {
      "epoch": 0.0003566485914195238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6926,
      "step": 98272
    },
    {
      "epoch": 0.0003567647257703605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6861,
      "step": 98304
    },
    {
      "epoch": 0.0003568808601211972,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6783,
      "step": 98336
    },
    {
      "epoch": 0.00035699699447203396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6972,
      "step": 98368
    },
    {
      "epoch": 0.00035711312882287066,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6994,
      "step": 98400
    },
    {
      "epoch": 0.00035722926317370736,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 98432
    },
    {
      "epoch": 0.00035734539752454406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 98464
    },
    {
      "epoch": 0.00035746153187538076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6955,
      "step": 98496
    },
    {
      "epoch": 0.00035757766622621746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 98528
    },
    {
      "epoch": 0.00035769380057705416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 98560
    },
    {
      "epoch": 0.00035780993492789086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 98592
    },
    {
      "epoch": 0.00035792606927872756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 98624
    },
    {
      "epoch": 0.0003580422036295643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 98656
    },
    {
      "epoch": 0.000358158337980401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 98688
    },
    {
      "epoch": 0.0003582744723312377,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7327,
      "step": 98720
    },
    {
      "epoch": 0.0003583906066820744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 98752
    },
    {
      "epoch": 0.0003585067410329111,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 98784
    },
    {
      "epoch": 0.0003586228753837478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 98816
    },
    {
      "epoch": 0.0003587390097345845,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 98848
    },
    {
      "epoch": 0.0003588551440854212,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 98880
    },
    {
      "epoch": 0.0003589712784362579,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 98912
    },
    {
      "epoch": 0.00035908741278709467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 98944
    },
    {
      "epoch": 0.00035920354713793137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 98976
    },
    {
      "epoch": 0.00035931968148876807,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 99008
    },
    {
      "epoch": 0.00035943581583960477,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7388,
      "step": 99040
    },
    {
      "epoch": 0.00035955195019044147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 99072
    },
    {
      "epoch": 0.00035966808454127817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6811,
      "step": 99104
    },
    {
      "epoch": 0.00035978421889211487,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 99136
    },
    {
      "epoch": 0.00035990035324295157,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6882,
      "step": 99168
    },
    {
      "epoch": 0.00036001648759378827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 99200
    },
    {
      "epoch": 0.000360132621944625,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 99232
    },
    {
      "epoch": 0.0003602487562954617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6907,
      "step": 99264
    },
    {
      "epoch": 0.0003603648906462984,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 99296
    },
    {
      "epoch": 0.0003604810249971351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 99328
    },
    {
      "epoch": 0.0003605971593479718,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 99360
    },
    {
      "epoch": 0.0003607132936988085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 99392
    },
    {
      "epoch": 0.0003608294280496452,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 99424
    },
    {
      "epoch": 0.0003609455624004819,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 99456
    },
    {
      "epoch": 0.0003610616967513186,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 99488
    },
    {
      "epoch": 0.0003611778311021554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 99520
    },
    {
      "epoch": 0.0003612939654529921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 99552
    },
    {
      "epoch": 0.0003614100998038288,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6914,
      "step": 99584
    },
    {
      "epoch": 0.00036152623415466547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 99616
    },
    {
      "epoch": 0.00036164236850550217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 99648
    },
    {
      "epoch": 0.00036175850285633887,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 99680
    },
    {
      "epoch": 0.00036187463720717557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 99712
    },
    {
      "epoch": 0.00036199077155801227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 99744
    },
    {
      "epoch": 0.00036210690590884897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 99776
    },
    {
      "epoch": 0.00036222304025968567,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 99808
    },
    {
      "epoch": 0.0003623391746105224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 99840
    },
    {
      "epoch": 0.0003624553089613591,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 99872
    },
    {
      "epoch": 0.0003625714433121958,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 99904
    },
    {
      "epoch": 0.0003626875776630325,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 99936
    },
    {
      "epoch": 0.0003628037120138692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 99968
    },
    {
      "epoch": 0.0003629198463647059,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7004,
      "step": 100000
    },
    {
      "epoch": 0.0003630359807155426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6898,
      "step": 100032
    },
    {
      "epoch": 0.0003631521150663793,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 100064
    },
    {
      "epoch": 0.000363268249417216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 100096
    },
    {
      "epoch": 0.0003633843837680528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 100128
    },
    {
      "epoch": 0.0003635005181188895,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 100160
    },
    {
      "epoch": 0.0003636166524697262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 100192
    },
    {
      "epoch": 0.0003637327868205629,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7379,
      "step": 100224
    },
    {
      "epoch": 0.0003638489211713996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 100256
    },
    {
      "epoch": 0.0003639650555222363,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 100288
    },
    {
      "epoch": 0.000364081189873073,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 100320
    },
    {
      "epoch": 0.0003641973242239097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6996,
      "step": 100352
    },
    {
      "epoch": 0.0003643134585747464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 100384
    },
    {
      "epoch": 0.00036442959292558313,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 100416
    },
    {
      "epoch": 0.00036454572727641983,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 100448
    },
    {
      "epoch": 0.00036466186162725653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.694,
      "step": 100480
    },
    {
      "epoch": 0.00036477799597809323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 100512
    },
    {
      "epoch": 0.00036489413032892993,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 100544
    },
    {
      "epoch": 0.00036501026467976663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 100576
    },
    {
      "epoch": 0.00036512639903060333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 100608
    },
    {
      "epoch": 0.00036524253338144003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6961,
      "step": 100640
    },
    {
      "epoch": 0.00036535866773227673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 100672
    },
    {
      "epoch": 0.0003654748020831135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 100704
    },
    {
      "epoch": 0.0003655909364339502,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7437,
      "step": 100736
    },
    {
      "epoch": 0.0003657070707847869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7402,
      "step": 100768
    },
    {
      "epoch": 0.0003658232051356236,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 100800
    },
    {
      "epoch": 0.0003659393394864603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6936,
      "step": 100832
    },
    {
      "epoch": 0.000366055473837297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 100864
    },
    {
      "epoch": 0.0003661716081881337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 100896
    },
    {
      "epoch": 0.0003662877425389704,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7023,
      "step": 100928
    },
    {
      "epoch": 0.0003664038768898071,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 100960
    },
    {
      "epoch": 0.00036652001124064384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7293,
      "step": 100992
    },
    {
      "epoch": 0.00036663614559148054,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 101024
    },
    {
      "epoch": 0.00036675227994231724,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 101056
    },
    {
      "epoch": 0.00036686841429315394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 101088
    },
    {
      "epoch": 0.00036698454864399064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 101120
    },
    {
      "epoch": 0.00036710068299482734,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 101152
    },
    {
      "epoch": 0.00036721681734566404,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 101184
    },
    {
      "epoch": 0.00036733295169650074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 101216
    },
    {
      "epoch": 0.00036744908604733744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6899,
      "step": 101248
    },
    {
      "epoch": 0.0003675652203981742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 101280
    },
    {
      "epoch": 0.0003676813547490109,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6954,
      "step": 101312
    },
    {
      "epoch": 0.0003677974890998476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6955,
      "step": 101344
    },
    {
      "epoch": 0.0003679136234506843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 101376
    },
    {
      "epoch": 0.000368029757801521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 101408
    },
    {
      "epoch": 0.0003681458921523577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 101440
    },
    {
      "epoch": 0.0003682620265031944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7205,
      "step": 101472
    },
    {
      "epoch": 0.0003683781608540311,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7327,
      "step": 101504
    },
    {
      "epoch": 0.0003684942952048678,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 101536
    },
    {
      "epoch": 0.00036861042955570455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 101568
    },
    {
      "epoch": 0.00036872656390654125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 101600
    },
    {
      "epoch": 0.00036884269825737795,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7383,
      "step": 101632
    },
    {
      "epoch": 0.00036895883260821465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 101664
    },
    {
      "epoch": 0.00036907496695905135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 101696
    },
    {
      "epoch": 0.00036919110130988805,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 101728
    },
    {
      "epoch": 0.00036930723566072475,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 101760
    },
    {
      "epoch": 0.00036942337001156145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 101792
    },
    {
      "epoch": 0.00036953950436239815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 101824
    },
    {
      "epoch": 0.0003696556387132349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 101856
    },
    {
      "epoch": 0.0003697717730640716,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 101888
    },
    {
      "epoch": 0.0003698879074149083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 101920
    },
    {
      "epoch": 0.000370004041765745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 101952
    },
    {
      "epoch": 0.0003701201761165817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 101984
    },
    {
      "epoch": 0.0003702363104674184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6728,
      "step": 102016
    },
    {
      "epoch": 0.0003703524448182551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6871,
      "step": 102048
    },
    {
      "epoch": 0.0003704685791690918,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 102080
    },
    {
      "epoch": 0.0003705847135199285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 102112
    },
    {
      "epoch": 0.00037070084787076525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6956,
      "step": 102144
    },
    {
      "epoch": 0.00037081698222160195,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6913,
      "step": 102176
    },
    {
      "epoch": 0.00037093311657243865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6846,
      "step": 102208
    },
    {
      "epoch": 0.00037104925092327535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 102240
    },
    {
      "epoch": 0.00037116538527411205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7471,
      "step": 102272
    },
    {
      "epoch": 0.00037128151962494875,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 102304
    },
    {
      "epoch": 0.00037139765397578545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 102336
    },
    {
      "epoch": 0.00037151378832662215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 102368
    },
    {
      "epoch": 0.00037162992267745885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.738,
      "step": 102400
    },
    {
      "epoch": 0.0003717460570282956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7327,
      "step": 102432
    },
    {
      "epoch": 0.0003718621913791323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 102464
    },
    {
      "epoch": 0.000371978325729969,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7512,
      "step": 102496
    },
    {
      "epoch": 0.0003720944600808057,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 102528
    },
    {
      "epoch": 0.0003722105944316424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 102560
    },
    {
      "epoch": 0.0003723267287824791,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 102592
    },
    {
      "epoch": 0.0003724428631333158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6907,
      "step": 102624
    },
    {
      "epoch": 0.0003725589974841525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 102656
    },
    {
      "epoch": 0.0003726751318349892,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 102688
    },
    {
      "epoch": 0.00037279126618582596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7205,
      "step": 102720
    },
    {
      "epoch": 0.00037290740053666266,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 102752
    },
    {
      "epoch": 0.00037302353488749936,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6912,
      "step": 102784
    },
    {
      "epoch": 0.00037313966923833606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6885,
      "step": 102816
    },
    {
      "epoch": 0.00037325580358917276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 102848
    },
    {
      "epoch": 0.00037337193794000946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 102880
    },
    {
      "epoch": 0.00037348807229084616,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.687,
      "step": 102912
    },
    {
      "epoch": 0.00037360420664168286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6826,
      "step": 102944
    },
    {
      "epoch": 0.00037372034099251956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.688,
      "step": 102976
    },
    {
      "epoch": 0.0003738364753433563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 103008
    },
    {
      "epoch": 0.000373952609694193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 103040
    },
    {
      "epoch": 0.0003740687440450297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 103072
    },
    {
      "epoch": 0.0003741848783958664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 103104
    },
    {
      "epoch": 0.0003743010127467031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 103136
    },
    {
      "epoch": 0.0003744171470975398,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7401,
      "step": 103168
    },
    {
      "epoch": 0.0003745332814483765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 103200
    },
    {
      "epoch": 0.0003746494157992132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 103232
    },
    {
      "epoch": 0.0003747655501500499,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7501,
      "step": 103264
    },
    {
      "epoch": 0.00037488168450088667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 103296
    },
    {
      "epoch": 0.00037499781885172337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7458,
      "step": 103328
    },
    {
      "epoch": 0.00037511395320256007,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 103360
    },
    {
      "epoch": 0.00037523008755339677,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 103392
    },
    {
      "epoch": 0.00037534622190423347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 103424
    },
    {
      "epoch": 0.00037546235625507017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 103456
    },
    {
      "epoch": 0.00037557849060590687,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 103488
    },
    {
      "epoch": 0.00037569462495674357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 103520
    },
    {
      "epoch": 0.00037581075930758027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6731,
      "step": 103552
    },
    {
      "epoch": 0.000375926893658417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 103584
    },
    {
      "epoch": 0.0003760430280092537,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6997,
      "step": 103616
    },
    {
      "epoch": 0.0003761591623600904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 103648
    },
    {
      "epoch": 0.0003762752967109271,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6895,
      "step": 103680
    },
    {
      "epoch": 0.0003763914310617638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6932,
      "step": 103712
    },
    {
      "epoch": 0.0003765075654126005,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 103744
    },
    {
      "epoch": 0.0003766236997634372,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 103776
    },
    {
      "epoch": 0.0003767398341142739,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 103808
    },
    {
      "epoch": 0.0003768559684651106,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6973,
      "step": 103840
    },
    {
      "epoch": 0.0003769721028159474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 103872
    },
    {
      "epoch": 0.0003770882371667841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 103904
    },
    {
      "epoch": 0.0003772043715176208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7262,
      "step": 103936
    },
    {
      "epoch": 0.0003773205058684575,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 103968
    },
    {
      "epoch": 0.0003774366402192942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 104000
    },
    {
      "epoch": 0.0003775527745701309,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7505,
      "step": 104032
    },
    {
      "epoch": 0.0003776689089209676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 104064
    },
    {
      "epoch": 0.0003777850432718043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 104096
    },
    {
      "epoch": 0.000377901177622641,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 104128
    },
    {
      "epoch": 0.00037801731197347773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 104160
    },
    {
      "epoch": 0.00037813344632431443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 104192
    },
    {
      "epoch": 0.00037824958067515113,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 104224
    },
    {
      "epoch": 0.00037836571502598783,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 104256
    },
    {
      "epoch": 0.00037848184937682453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6836,
      "step": 104288
    },
    {
      "epoch": 0.00037859798372766123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 104320
    },
    {
      "epoch": 0.0003787141180784979,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6919,
      "step": 104352
    },
    {
      "epoch": 0.0003788302524293346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.687,
      "step": 104384
    },
    {
      "epoch": 0.0003789463867801713,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 104416
    },
    {
      "epoch": 0.0003790625211310081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6878,
      "step": 104448
    },
    {
      "epoch": 0.0003791786554818448,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 104480
    },
    {
      "epoch": 0.0003792947898326815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 104512
    },
    {
      "epoch": 0.0003794109241835182,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 104544
    },
    {
      "epoch": 0.0003795270585343549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 104576
    },
    {
      "epoch": 0.0003796431928851916,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 104608
    },
    {
      "epoch": 0.0003797593272360283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 104640
    },
    {
      "epoch": 0.000379875461586865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 104672
    },
    {
      "epoch": 0.0003799915959377017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 104704
    },
    {
      "epoch": 0.00038010773028853843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 104736
    },
    {
      "epoch": 0.00038022386463937513,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 104768
    },
    {
      "epoch": 0.00038033999899021183,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 104800
    },
    {
      "epoch": 0.00038045613334104853,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 104832
    },
    {
      "epoch": 0.00038057226769188523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 104864
    },
    {
      "epoch": 0.00038068840204272193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 104896
    },
    {
      "epoch": 0.00038080453639355863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 104928
    },
    {
      "epoch": 0.00038092067074439533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7177,
      "step": 104960
    },
    {
      "epoch": 0.00038103680509523203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7275,
      "step": 104992
    },
    {
      "epoch": 0.00038115293944606873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 105024
    },
    {
      "epoch": 0.0003812690737969055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 105056
    },
    {
      "epoch": 0.0003813852081477422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 105088
    },
    {
      "epoch": 0.0003815013424985789,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6907,
      "step": 105120
    },
    {
      "epoch": 0.0003816174768494156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.692,
      "step": 105152
    },
    {
      "epoch": 0.0003817336112002523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 105184
    },
    {
      "epoch": 0.000381849745551089,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 105216
    },
    {
      "epoch": 0.0003819658799019257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 105248
    },
    {
      "epoch": 0.0003820820142527624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 105280
    },
    {
      "epoch": 0.0003821981486035991,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 105312
    },
    {
      "epoch": 0.00038231428295443584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6929,
      "step": 105344
    },
    {
      "epoch": 0.00038243041730527254,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 105376
    },
    {
      "epoch": 0.00038254655165610924,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 105408
    },
    {
      "epoch": 0.00038266268600694594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 105440
    },
    {
      "epoch": 0.00038277882035778264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 105472
    },
    {
      "epoch": 0.00038289495470861934,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 105504
    },
    {
      "epoch": 0.00038301108905945604,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 105536
    },
    {
      "epoch": 0.00038312722341029274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 105568
    },
    {
      "epoch": 0.00038324335776112944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 105600
    },
    {
      "epoch": 0.0003833594921119662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 105632
    },
    {
      "epoch": 0.0003834756264628029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 105664
    },
    {
      "epoch": 0.0003835917608136396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 105696
    },
    {
      "epoch": 0.0003837078951644763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 105728
    },
    {
      "epoch": 0.000383824029515313,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7237,
      "step": 105760
    },
    {
      "epoch": 0.0003839401638661497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7353,
      "step": 105792
    },
    {
      "epoch": 0.0003840562982169864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 105824
    },
    {
      "epoch": 0.0003841724325678231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 105856
    },
    {
      "epoch": 0.0003842885669186598,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7102,
      "step": 105888
    },
    {
      "epoch": 0.00038440470126949655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 105920
    },
    {
      "epoch": 0.00038452083562033325,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.693,
      "step": 105952
    },
    {
      "epoch": 0.00038463696997116995,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.683,
      "step": 105984
    },
    {
      "epoch": 0.00038475310432200665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.69,
      "step": 106016
    },
    {
      "epoch": 0.00038486923867284335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 106048
    },
    {
      "epoch": 0.00038498537302368005,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 106080
    },
    {
      "epoch": 0.00038510150737451675,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 106112
    },
    {
      "epoch": 0.00038521764172535345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 106144
    },
    {
      "epoch": 0.00038533377607619015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 106176
    },
    {
      "epoch": 0.0003854499104270269,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 106208
    },
    {
      "epoch": 0.0003855660447778636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 106240
    },
    {
      "epoch": 0.0003856821791287003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 106272
    },
    {
      "epoch": 0.000385798313479537,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 106304
    },
    {
      "epoch": 0.0003859144478303737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 106336
    },
    {
      "epoch": 0.0003860305821812104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 106368
    },
    {
      "epoch": 0.0003861467165320471,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 106400
    },
    {
      "epoch": 0.0003862628508828838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 106432
    },
    {
      "epoch": 0.0003863789852337205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 106464
    },
    {
      "epoch": 0.00038649511958455725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 106496
    },
    {
      "epoch": 0.00038661125393539395,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 106528
    },
    {
      "epoch": 0.00038672738828623065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 106560
    },
    {
      "epoch": 0.00038684352263706735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 106592
    },
    {
      "epoch": 0.00038695965698790405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 106624
    },
    {
      "epoch": 0.00038707579133874075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 106656
    },
    {
      "epoch": 0.00038719192568957745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7343,
      "step": 106688
    },
    {
      "epoch": 0.00038730806004041415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 106720
    },
    {
      "epoch": 0.00038742419439125085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 106752
    },
    {
      "epoch": 0.0003875403287420876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 106784
    },
    {
      "epoch": 0.0003876564630929243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 106816
    },
    {
      "epoch": 0.000387772597443761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 106848
    },
    {
      "epoch": 0.0003878887317945977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 106880
    },
    {
      "epoch": 0.0003880048661454344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6896,
      "step": 106912
    },
    {
      "epoch": 0.0003881210004962711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 106944
    },
    {
      "epoch": 0.0003882371348471078,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7342,
      "step": 106976
    },
    {
      "epoch": 0.0003883532691979445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 107008
    },
    {
      "epoch": 0.0003884694035487812,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 107040
    },
    {
      "epoch": 0.00038858553789961796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 107072
    },
    {
      "epoch": 0.00038870167225045466,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 107104
    },
    {
      "epoch": 0.00038881780660129136,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 107136
    },
    {
      "epoch": 0.00038893394095212806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 107168
    },
    {
      "epoch": 0.00038905007530296476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 107200
    },
    {
      "epoch": 0.00038916620965380146,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 107232
    },
    {
      "epoch": 0.00038928234400463816,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7262,
      "step": 107264
    },
    {
      "epoch": 0.00038939847835547486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7056,
      "step": 107296
    },
    {
      "epoch": 0.00038951461270631156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6926,
      "step": 107328
    },
    {
      "epoch": 0.0003896307470571483,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.687,
      "step": 107360
    },
    {
      "epoch": 0.000389746881407985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 107392
    },
    {
      "epoch": 0.0003898630157588217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 107424
    },
    {
      "epoch": 0.0003899791501096584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 107456
    },
    {
      "epoch": 0.0003900952844604951,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 107488
    },
    {
      "epoch": 0.0003902114188113318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 107520
    },
    {
      "epoch": 0.0003903275531621685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7388,
      "step": 107552
    },
    {
      "epoch": 0.0003904436875130052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7439,
      "step": 107584
    },
    {
      "epoch": 0.0003905598218638419,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7288,
      "step": 107616
    },
    {
      "epoch": 0.00039067595621467867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 107648
    },
    {
      "epoch": 0.00039079209056551537,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6934,
      "step": 107680
    },
    {
      "epoch": 0.00039090822491635207,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 107712
    },
    {
      "epoch": 0.00039102435926718877,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 107744
    },
    {
      "epoch": 0.00039114049361802547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 107776
    },
    {
      "epoch": 0.00039125662796886217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 107808
    },
    {
      "epoch": 0.00039137276231969887,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 107840
    },
    {
      "epoch": 0.00039148889667053557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 107872
    },
    {
      "epoch": 0.00039160503102137227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 107904
    },
    {
      "epoch": 0.000391721165372209,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7023,
      "step": 107936
    },
    {
      "epoch": 0.0003918372997230457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 107968
    },
    {
      "epoch": 0.0003919534340738824,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 108000
    },
    {
      "epoch": 0.0003920695684247191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 108032
    },
    {
      "epoch": 0.0003921857027755558,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 108064
    },
    {
      "epoch": 0.0003923018371263925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6889,
      "step": 108096
    },
    {
      "epoch": 0.0003924179714772292,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6833,
      "step": 108128
    },
    {
      "epoch": 0.0003925341058280659,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 108160
    },
    {
      "epoch": 0.0003926502401789026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6996,
      "step": 108192
    },
    {
      "epoch": 0.0003927663745297394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6959,
      "step": 108224
    },
    {
      "epoch": 0.0003928825088805761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6913,
      "step": 108256
    },
    {
      "epoch": 0.0003929986432314128,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6977,
      "step": 108288
    },
    {
      "epoch": 0.0003931147775822495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7334,
      "step": 108320
    },
    {
      "epoch": 0.0003932309119330862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 108352
    },
    {
      "epoch": 0.0003933470462839229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 108384
    },
    {
      "epoch": 0.0003934631806347596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 108416
    },
    {
      "epoch": 0.0003935793149855963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 108448
    },
    {
      "epoch": 0.000393695449336433,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.738,
      "step": 108480
    },
    {
      "epoch": 0.00039381158368726973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 108512
    },
    {
      "epoch": 0.00039392771803810643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 108544
    },
    {
      "epoch": 0.00039404385238894313,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 108576
    },
    {
      "epoch": 0.00039415998673977983,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 108608
    },
    {
      "epoch": 0.00039427612109061653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 108640
    },
    {
      "epoch": 0.00039439225544145323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 108672
    },
    {
      "epoch": 0.00039450838979228993,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 108704
    },
    {
      "epoch": 0.00039462452414312663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 108736
    },
    {
      "epoch": 0.00039474065849396333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 108768
    },
    {
      "epoch": 0.0003948567928448001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 108800
    },
    {
      "epoch": 0.0003949729271956368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 108832
    },
    {
      "epoch": 0.0003950890615464735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6842,
      "step": 108864
    },
    {
      "epoch": 0.0003952051958973102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6869,
      "step": 108896
    },
    {
      "epoch": 0.0003953213302481469,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6922,
      "step": 108928
    },
    {
      "epoch": 0.0003954374645989836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.695,
      "step": 108960
    },
    {
      "epoch": 0.0003955535989498203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6972,
      "step": 108992
    },
    {
      "epoch": 0.000395669733300657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 109024
    },
    {
      "epoch": 0.0003957858676514937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.682,
      "step": 109056
    },
    {
      "epoch": 0.00039590200200233044,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 109088
    },
    {
      "epoch": 0.00039601813635316714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 109120
    },
    {
      "epoch": 0.00039613427070400384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 109152
    },
    {
      "epoch": 0.00039625040505484054,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 109184
    },
    {
      "epoch": 0.00039636653940567724,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 109216
    },
    {
      "epoch": 0.00039648267375651394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7357,
      "step": 109248
    },
    {
      "epoch": 0.00039659880810735064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 109280
    },
    {
      "epoch": 0.00039671494245818733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7424,
      "step": 109312
    },
    {
      "epoch": 0.00039683107680902403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7671,
      "step": 109344
    },
    {
      "epoch": 0.0003969472111598608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 109376
    },
    {
      "epoch": 0.0003970633455106975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 109408
    },
    {
      "epoch": 0.0003971794798615342,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 109440
    },
    {
      "epoch": 0.0003972956142123709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 109472
    },
    {
      "epoch": 0.0003974117485632076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 109504
    },
    {
      "epoch": 0.0003975278829140443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 109536
    },
    {
      "epoch": 0.000397644017264881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 109568
    },
    {
      "epoch": 0.0003977601516157177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 109600
    },
    {
      "epoch": 0.0003978762859665544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 109632
    },
    {
      "epoch": 0.00039799242031739114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6765,
      "step": 109664
    },
    {
      "epoch": 0.00039810855466822784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6893,
      "step": 109696
    },
    {
      "epoch": 0.00039822468901906454,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 109728
    },
    {
      "epoch": 0.00039834082336990124,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 109760
    },
    {
      "epoch": 0.00039845695772073794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.694,
      "step": 109792
    },
    {
      "epoch": 0.00039857309207157464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 109824
    },
    {
      "epoch": 0.00039868922642241134,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 109856
    },
    {
      "epoch": 0.00039880536077324804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 109888
    },
    {
      "epoch": 0.00039892149512408474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 109920
    },
    {
      "epoch": 0.0003990376294749215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 109952
    },
    {
      "epoch": 0.0003991537638257582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 109984
    },
    {
      "epoch": 0.0003992698981765949,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 110016
    },
    {
      "epoch": 0.0003993860325274316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 110048
    },
    {
      "epoch": 0.0003995021668782683,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7329,
      "step": 110080
    },
    {
      "epoch": 0.000399618301229105,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7344,
      "step": 110112
    },
    {
      "epoch": 0.0003997344355799417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7329,
      "step": 110144
    },
    {
      "epoch": 0.0003998505699307784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 110176
    },
    {
      "epoch": 0.0003999667042816151,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7486,
      "step": 110208
    },
    {
      "epoch": 0.00040008283863245185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 110240
    },
    {
      "epoch": 0.00040019897298328855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6902,
      "step": 110272
    },
    {
      "epoch": 0.00040031510733412525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 110304
    },
    {
      "epoch": 0.00040043124168496195,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 110336
    },
    {
      "epoch": 0.00040054737603579865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 110368
    },
    {
      "epoch": 0.00040066351038663535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6905,
      "step": 110400
    },
    {
      "epoch": 0.00040077964473747205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6888,
      "step": 110432
    },
    {
      "epoch": 0.00040089577908830875,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7004,
      "step": 110464
    },
    {
      "epoch": 0.00040101191343914545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.694,
      "step": 110496
    },
    {
      "epoch": 0.00040112804778998215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 110528
    },
    {
      "epoch": 0.0004012441821408189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 110560
    },
    {
      "epoch": 0.0004013603164916556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 110592
    },
    {
      "epoch": 0.0004014764508424923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 110624
    },
    {
      "epoch": 0.000401592585193329,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 110656
    },
    {
      "epoch": 0.0004017087195441657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 110688
    },
    {
      "epoch": 0.0004018248538950024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.694,
      "step": 110720
    },
    {
      "epoch": 0.0004019409882458391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 110752
    },
    {
      "epoch": 0.0004020571225966758,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 110784
    },
    {
      "epoch": 0.0004021732569475125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 110816
    },
    {
      "epoch": 0.00040228939129834926,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7343,
      "step": 110848
    },
    {
      "epoch": 0.00040240552564918596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 110880
    },
    {
      "epoch": 0.00040252166000002266,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 110912
    },
    {
      "epoch": 0.00040263779435085936,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 110944
    },
    {
      "epoch": 0.00040275392870169606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7378,
      "step": 110976
    },
    {
      "epoch": 0.00040287006305253276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7296,
      "step": 111008
    },
    {
      "epoch": 0.00040298619740336946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 111040
    },
    {
      "epoch": 0.00040310233175420616,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7355,
      "step": 111072
    },
    {
      "epoch": 0.00040321846610504286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 111104
    },
    {
      "epoch": 0.0004033346004558796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 111136
    },
    {
      "epoch": 0.0004034507348067163,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6871,
      "step": 111168
    },
    {
      "epoch": 0.000403566869157553,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6776,
      "step": 111200
    },
    {
      "epoch": 0.0004036830035083897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6894,
      "step": 111232
    },
    {
      "epoch": 0.0004037991378592264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6911,
      "step": 111264
    },
    {
      "epoch": 0.0004039152722100631,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 111296
    },
    {
      "epoch": 0.0004040314065608998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 111328
    },
    {
      "epoch": 0.0004041475409117365,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 111360
    },
    {
      "epoch": 0.0004042636752625732,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 111392
    },
    {
      "epoch": 0.00040437980961340996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6913,
      "step": 111424
    },
    {
      "epoch": 0.00040449594396424666,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 111456
    },
    {
      "epoch": 0.00040461207831508336,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 111488
    },
    {
      "epoch": 0.00040472821266592006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 111520
    },
    {
      "epoch": 0.00040484434701675676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 111552
    },
    {
      "epoch": 0.00040496048136759346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 111584
    },
    {
      "epoch": 0.00040507661571843016,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 111616
    },
    {
      "epoch": 0.00040519275006926686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6946,
      "step": 111648
    },
    {
      "epoch": 0.00040530888442010356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 111680
    },
    {
      "epoch": 0.0004054250187709403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 111712
    },
    {
      "epoch": 0.000405541153121777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 111744
    },
    {
      "epoch": 0.0004056572874726137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 111776
    },
    {
      "epoch": 0.0004057734218234504,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 111808
    },
    {
      "epoch": 0.0004058895561742871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 111840
    },
    {
      "epoch": 0.0004060056905251238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 111872
    },
    {
      "epoch": 0.0004061218248759605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 111904
    },
    {
      "epoch": 0.0004062379592267972,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 111936
    },
    {
      "epoch": 0.0004063540935776339,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 111968
    },
    {
      "epoch": 0.00040647022792847067,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6947,
      "step": 112000
    },
    {
      "epoch": 0.00040658636227930737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6823,
      "step": 112032
    },
    {
      "epoch": 0.00040670249663014407,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6951,
      "step": 112064
    },
    {
      "epoch": 0.00040681863098098077,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6961,
      "step": 112096
    },
    {
      "epoch": 0.00040693476533181747,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 112128
    },
    {
      "epoch": 0.00040705089968265417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 112160
    },
    {
      "epoch": 0.00040716703403349087,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 112192
    },
    {
      "epoch": 0.00040728316838432757,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6976,
      "step": 112224
    },
    {
      "epoch": 0.00040739930273516427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 112256
    },
    {
      "epoch": 0.000407515437086001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 112288
    },
    {
      "epoch": 0.0004076315714368377,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 112320
    },
    {
      "epoch": 0.0004077477057876744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 112352
    },
    {
      "epoch": 0.0004078638401385111,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 112384
    },
    {
      "epoch": 0.0004079799744893478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6907,
      "step": 112416
    },
    {
      "epoch": 0.0004080961088401845,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 112448
    },
    {
      "epoch": 0.0004082122431910212,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 112480
    },
    {
      "epoch": 0.0004083283775418579,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 112512
    },
    {
      "epoch": 0.0004084445118926946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 112544
    },
    {
      "epoch": 0.0004085606462435314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 112576
    },
    {
      "epoch": 0.0004086767805943681,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 112608
    },
    {
      "epoch": 0.0004087929149452048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 112640
    },
    {
      "epoch": 0.0004089090492960415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 112672
    },
    {
      "epoch": 0.0004090251836468782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 112704
    },
    {
      "epoch": 0.0004091413179977149,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 112736
    },
    {
      "epoch": 0.0004092574523485516,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 112768
    },
    {
      "epoch": 0.0004093735866993883,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 112800
    },
    {
      "epoch": 0.000409489721050225,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6865,
      "step": 112832
    },
    {
      "epoch": 0.00040960585540106173,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 112864
    },
    {
      "epoch": 0.00040972198975189843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 112896
    },
    {
      "epoch": 0.00040983812410273513,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7026,
      "step": 112928
    },
    {
      "epoch": 0.00040995425845357183,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 112960
    },
    {
      "epoch": 0.00041007039280440853,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 112992
    },
    {
      "epoch": 0.00041018652715524523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 113024
    },
    {
      "epoch": 0.00041030266150608193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 113056
    },
    {
      "epoch": 0.00041041879585691863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 113088
    },
    {
      "epoch": 0.00041053493020775533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 113120
    },
    {
      "epoch": 0.0004106510645585921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7275,
      "step": 113152
    },
    {
      "epoch": 0.0004107671989094288,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 113184
    },
    {
      "epoch": 0.0004108833332602655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6931,
      "step": 113216
    },
    {
      "epoch": 0.0004109994676111022,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6972,
      "step": 113248
    },
    {
      "epoch": 0.0004111156019619389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 113280
    },
    {
      "epoch": 0.0004112317363127756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 113312
    },
    {
      "epoch": 0.0004113478706636123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 113344
    },
    {
      "epoch": 0.000411464005014449,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 113376
    },
    {
      "epoch": 0.0004115801393652857,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 113408
    },
    {
      "epoch": 0.00041169627371612244,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 113440
    },
    {
      "epoch": 0.00041181240806695914,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 113472
    },
    {
      "epoch": 0.00041192854241779584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 113504
    },
    {
      "epoch": 0.00041204467676863254,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 113536
    },
    {
      "epoch": 0.00041216081111946924,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 113568
    },
    {
      "epoch": 0.00041227694547030594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 113600
    },
    {
      "epoch": 0.00041239307982114264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 113632
    },
    {
      "epoch": 0.00041250921417197934,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 113664
    },
    {
      "epoch": 0.00041262534852281604,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 113696
    },
    {
      "epoch": 0.0004127414828736528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 113728
    },
    {
      "epoch": 0.0004128576172244895,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 113760
    },
    {
      "epoch": 0.0004129737515753262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 113792
    },
    {
      "epoch": 0.0004130898859261629,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 113824
    },
    {
      "epoch": 0.0004132060202769996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 113856
    },
    {
      "epoch": 0.0004133221546278363,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7415,
      "step": 113888
    },
    {
      "epoch": 0.000413438288978673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 113920
    },
    {
      "epoch": 0.0004135544233295097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 113952
    },
    {
      "epoch": 0.0004136705576803464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.692,
      "step": 113984
    },
    {
      "epoch": 0.00041378669203118314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 114016
    },
    {
      "epoch": 0.00041390282638201984,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.737,
      "step": 114048
    },
    {
      "epoch": 0.00041401896073285654,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 114080
    },
    {
      "epoch": 0.00041413509508369324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7023,
      "step": 114112
    },
    {
      "epoch": 0.00041425122943452994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6957,
      "step": 114144
    },
    {
      "epoch": 0.00041436736378536664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6879,
      "step": 114176
    },
    {
      "epoch": 0.00041448349813620334,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6959,
      "step": 114208
    },
    {
      "epoch": 0.00041459963248704004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6917,
      "step": 114240
    },
    {
      "epoch": 0.00041471576683787674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6951,
      "step": 114272
    },
    {
      "epoch": 0.0004148319011887135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 114304
    },
    {
      "epoch": 0.0004149480355395502,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 114336
    },
    {
      "epoch": 0.0004150641698903869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 114368
    },
    {
      "epoch": 0.0004151803042412236,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 114400
    },
    {
      "epoch": 0.0004152964385920603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 114432
    },
    {
      "epoch": 0.000415412572942897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 114464
    },
    {
      "epoch": 0.0004155287072937337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7441,
      "step": 114496
    },
    {
      "epoch": 0.0004156448416445704,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 114528
    },
    {
      "epoch": 0.0004157609759954071,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 114560
    },
    {
      "epoch": 0.00041587711034624385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 114592
    },
    {
      "epoch": 0.00041599324469708055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 114624
    },
    {
      "epoch": 0.00041610937904791725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7389,
      "step": 114656
    },
    {
      "epoch": 0.00041622551339875395,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 114688
    },
    {
      "epoch": 0.00041634164774959065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6916,
      "step": 114720
    },
    {
      "epoch": 0.00041645778210042735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 114752
    },
    {
      "epoch": 0.00041657391645126405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 114784
    },
    {
      "epoch": 0.00041669005080210075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 114816
    },
    {
      "epoch": 0.00041680618515293745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 114848
    },
    {
      "epoch": 0.0004169223195037742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 114880
    },
    {
      "epoch": 0.0004170384538546109,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 114912
    },
    {
      "epoch": 0.0004171545882054476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 114944
    },
    {
      "epoch": 0.0004172707225562843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6925,
      "step": 114976
    },
    {
      "epoch": 0.000417386856907121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6824,
      "step": 115008
    },
    {
      "epoch": 0.0004175029912579577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6878,
      "step": 115040
    },
    {
      "epoch": 0.0004176191256087944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6893,
      "step": 115072
    },
    {
      "epoch": 0.0004177352599596311,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 115104
    },
    {
      "epoch": 0.0004178513943104678,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7286,
      "step": 115136
    },
    {
      "epoch": 0.00041796752866130456,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 115168
    },
    {
      "epoch": 0.00041808366301214126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 115200
    },
    {
      "epoch": 0.00041819979736297796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7445,
      "step": 115232
    },
    {
      "epoch": 0.00041831593171381466,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 115264
    },
    {
      "epoch": 0.00041843206606465136,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 115296
    },
    {
      "epoch": 0.00041854820041548806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7248,
      "step": 115328
    },
    {
      "epoch": 0.00041866433476632476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7268,
      "step": 115360
    },
    {
      "epoch": 0.00041878046911716146,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 115392
    },
    {
      "epoch": 0.00041889660346799816,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7161,
      "step": 115424
    },
    {
      "epoch": 0.0004190127378188349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 115456
    },
    {
      "epoch": 0.0004191288721696716,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6931,
      "step": 115488
    },
    {
      "epoch": 0.0004192450065205083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 115520
    },
    {
      "epoch": 0.000419361140871345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 115552
    },
    {
      "epoch": 0.0004194772752221817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 115584
    },
    {
      "epoch": 0.0004195934095730184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 115616
    },
    {
      "epoch": 0.0004197095439238551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 115648
    },
    {
      "epoch": 0.0004198256782746918,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 115680
    },
    {
      "epoch": 0.0004199418126255285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6864,
      "step": 115712
    },
    {
      "epoch": 0.00042005794697636526,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 115744
    },
    {
      "epoch": 0.00042017408132720196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6858,
      "step": 115776
    },
    {
      "epoch": 0.00042029021567803866,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 115808
    },
    {
      "epoch": 0.00042040635002887536,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 115840
    },
    {
      "epoch": 0.00042052248437971206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 115872
    },
    {
      "epoch": 0.00042063861873054876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 115904
    },
    {
      "epoch": 0.00042075475308138546,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6956,
      "step": 115936
    },
    {
      "epoch": 0.00042087088743222216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 115968
    },
    {
      "epoch": 0.00042098702178305886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 116000
    },
    {
      "epoch": 0.00042110315613389556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7309,
      "step": 116032
    },
    {
      "epoch": 0.0004212192904847323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7333,
      "step": 116064
    },
    {
      "epoch": 0.000421335424835569,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 116096
    },
    {
      "epoch": 0.0004214515591864057,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 116128
    },
    {
      "epoch": 0.0004215676935372424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7424,
      "step": 116160
    },
    {
      "epoch": 0.0004216838278880791,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 116192
    },
    {
      "epoch": 0.0004217999622389158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 116224
    },
    {
      "epoch": 0.0004219160965897525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 116256
    },
    {
      "epoch": 0.0004220322309405892,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 116288
    },
    {
      "epoch": 0.0004221483652914259,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 116320
    },
    {
      "epoch": 0.00042226449964226267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 116352
    },
    {
      "epoch": 0.00042238063399309937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 116384
    },
    {
      "epoch": 0.00042249676834393607,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 116416
    },
    {
      "epoch": 0.00042261290269477277,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6959,
      "step": 116448
    },
    {
      "epoch": 0.00042272903704560947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 116480
    },
    {
      "epoch": 0.00042284517139644617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6893,
      "step": 116512
    },
    {
      "epoch": 0.00042296130574728287,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6829,
      "step": 116544
    },
    {
      "epoch": 0.00042307744009811957,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6882,
      "step": 116576
    },
    {
      "epoch": 0.00042319357444895627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6921,
      "step": 116608
    },
    {
      "epoch": 0.000423309708799793,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 116640
    },
    {
      "epoch": 0.0004234258431506297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7291,
      "step": 116672
    },
    {
      "epoch": 0.0004235419775014664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 116704
    },
    {
      "epoch": 0.0004236581118523031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6864,
      "step": 116736
    },
    {
      "epoch": 0.0004237742462031398,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 116768
    },
    {
      "epoch": 0.0004238903805539765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 116800
    },
    {
      "epoch": 0.0004240065149048132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 116832
    },
    {
      "epoch": 0.0004241226492556499,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 116864
    },
    {
      "epoch": 0.0004242387836064866,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 116896
    },
    {
      "epoch": 0.0004243549179573234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 116928
    },
    {
      "epoch": 0.0004244710523081601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 116960
    },
    {
      "epoch": 0.0004245871866589968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7415,
      "step": 116992
    },
    {
      "epoch": 0.0004247033210098335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 117024
    },
    {
      "epoch": 0.0004248194553606702,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 117056
    },
    {
      "epoch": 0.0004249355897115069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7365,
      "step": 117088
    },
    {
      "epoch": 0.0004250517240623436,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 117120
    },
    {
      "epoch": 0.0004251678584131803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 117152
    },
    {
      "epoch": 0.000425283992764017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 117184
    },
    {
      "epoch": 0.00042540012711485373,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6983,
      "step": 117216
    },
    {
      "epoch": 0.00042551626146569043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 117248
    },
    {
      "epoch": 0.00042563239581652713,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 117280
    },
    {
      "epoch": 0.00042574853016736383,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6814,
      "step": 117312
    },
    {
      "epoch": 0.00042586466451820053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 117344
    },
    {
      "epoch": 0.00042598079886903723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.693,
      "step": 117376
    },
    {
      "epoch": 0.00042609693321987393,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 117408
    },
    {
      "epoch": 0.00042621306757071063,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 117440
    },
    {
      "epoch": 0.00042632920192154733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6948,
      "step": 117472
    },
    {
      "epoch": 0.0004264453362723841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 117504
    },
    {
      "epoch": 0.0004265614706232208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6982,
      "step": 117536
    },
    {
      "epoch": 0.0004266776049740575,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7347,
      "step": 117568
    },
    {
      "epoch": 0.0004267937393248942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 117600
    },
    {
      "epoch": 0.0004269098736757309,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6997,
      "step": 117632
    },
    {
      "epoch": 0.0004270260080265676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 117664
    },
    {
      "epoch": 0.0004271421423774043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 117696
    },
    {
      "epoch": 0.000427258276728241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 117728
    },
    {
      "epoch": 0.0004273744110790777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 117760
    },
    {
      "epoch": 0.00042749054542991444,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 117792
    },
    {
      "epoch": 0.00042760667978075114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 117824
    },
    {
      "epoch": 0.00042772281413158784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7443,
      "step": 117856
    },
    {
      "epoch": 0.00042783894848242454,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 117888
    },
    {
      "epoch": 0.00042795508283326124,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 117920
    },
    {
      "epoch": 0.00042807121718409794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 117952
    },
    {
      "epoch": 0.00042818735153493464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6851,
      "step": 117984
    },
    {
      "epoch": 0.00042830348588577134,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 118016
    },
    {
      "epoch": 0.00042841962023660804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6932,
      "step": 118048
    },
    {
      "epoch": 0.0004285357545874448,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6871,
      "step": 118080
    },
    {
      "epoch": 0.0004286518889382815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.692,
      "step": 118112
    },
    {
      "epoch": 0.0004287680232891182,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 118144
    },
    {
      "epoch": 0.0004288841576399549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7394,
      "step": 118176
    },
    {
      "epoch": 0.0004290002919907916,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 118208
    },
    {
      "epoch": 0.0004291164263416283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6878,
      "step": 118240
    },
    {
      "epoch": 0.000429232560692465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 118272
    },
    {
      "epoch": 0.0004293486950433017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 118304
    },
    {
      "epoch": 0.0004294648293941384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 118336
    },
    {
      "epoch": 0.00042958096374497514,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 118368
    },
    {
      "epoch": 0.00042969709809581184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7026,
      "step": 118400
    },
    {
      "epoch": 0.00042981323244664854,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7347,
      "step": 118432
    },
    {
      "epoch": 0.00042992936679748524,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 118464
    },
    {
      "epoch": 0.00043004550114832194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 118496
    },
    {
      "epoch": 0.00043016163549915864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6855,
      "step": 118528
    },
    {
      "epoch": 0.00043027776984999534,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 118560
    },
    {
      "epoch": 0.00043039390420083204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7268,
      "step": 118592
    },
    {
      "epoch": 0.00043051003855166874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 118624
    },
    {
      "epoch": 0.0004306261729025055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7359,
      "step": 118656
    },
    {
      "epoch": 0.0004307423072533422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 118688
    },
    {
      "epoch": 0.0004308584416041789,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 118720
    },
    {
      "epoch": 0.0004309745759550156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7177,
      "step": 118752
    },
    {
      "epoch": 0.0004310907103058523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 118784
    },
    {
      "epoch": 0.000431206844656689,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 118816
    },
    {
      "epoch": 0.0004313229790075257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6747,
      "step": 118848
    },
    {
      "epoch": 0.0004314391133583624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6779,
      "step": 118880
    },
    {
      "epoch": 0.0004315552477091991,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6954,
      "step": 118912
    },
    {
      "epoch": 0.00043167138206003585,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 118944
    },
    {
      "epoch": 0.00043178751641087255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 118976
    },
    {
      "epoch": 0.00043190365076170925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6921,
      "step": 119008
    },
    {
      "epoch": 0.00043201978511254595,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 119040
    },
    {
      "epoch": 0.00043213591946338265,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 119072
    },
    {
      "epoch": 0.00043225205381421935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 119104
    },
    {
      "epoch": 0.00043236818816505605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 119136
    },
    {
      "epoch": 0.00043248432251589275,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6959,
      "step": 119168
    },
    {
      "epoch": 0.00043260045686672945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 119200
    },
    {
      "epoch": 0.0004327165912175662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 119232
    },
    {
      "epoch": 0.0004328327255684029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 119264
    },
    {
      "epoch": 0.0004329488599192396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6857,
      "step": 119296
    },
    {
      "epoch": 0.0004330649942700763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 119328
    },
    {
      "epoch": 0.000433181128620913,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 119360
    },
    {
      "epoch": 0.0004332972629717497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 119392
    },
    {
      "epoch": 0.0004334133973225864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 119424
    },
    {
      "epoch": 0.0004335295316734231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 119456
    },
    {
      "epoch": 0.0004336456660242598,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 119488
    },
    {
      "epoch": 0.00043376180037509656,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7056,
      "step": 119520
    },
    {
      "epoch": 0.00043387793472593326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 119552
    },
    {
      "epoch": 0.00043399406907676996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 119584
    },
    {
      "epoch": 0.00043411020342760666,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 119616
    },
    {
      "epoch": 0.00043422633777844336,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 119648
    },
    {
      "epoch": 0.00043434247212928006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 119680
    },
    {
      "epoch": 0.00043445860648011676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 119712
    },
    {
      "epoch": 0.00043457474083095346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 119744
    },
    {
      "epoch": 0.00043469087518179016,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6925,
      "step": 119776
    },
    {
      "epoch": 0.0004348070095326269,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 119808
    },
    {
      "epoch": 0.0004349231438834636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 119840
    },
    {
      "epoch": 0.0004350392782343003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 119872
    },
    {
      "epoch": 0.000435155412585137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 119904
    },
    {
      "epoch": 0.0004352715469359737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 119936
    },
    {
      "epoch": 0.0004353876812868104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7361,
      "step": 119968
    },
    {
      "epoch": 0.0004355038156376471,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6973,
      "step": 120000
    },
    {
      "epoch": 0.0004356199499884838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 120032
    },
    {
      "epoch": 0.0004357360843393205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6888,
      "step": 120064
    },
    {
      "epoch": 0.00043585221869015727,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 120096
    },
    {
      "epoch": 0.00043596835304099397,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 120128
    },
    {
      "epoch": 0.00043608448739183066,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 120160
    },
    {
      "epoch": 0.00043620062174266736,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 120192
    },
    {
      "epoch": 0.00043631675609350406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 120224
    },
    {
      "epoch": 0.00043643289044434076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6889,
      "step": 120256
    },
    {
      "epoch": 0.00043654902479517746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 120288
    },
    {
      "epoch": 0.00043666515914601416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 120320
    },
    {
      "epoch": 0.00043678129349685086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 120352
    },
    {
      "epoch": 0.0004368974278476876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 120384
    },
    {
      "epoch": 0.0004370135621985243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 120416
    },
    {
      "epoch": 0.000437129696549361,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 120448
    },
    {
      "epoch": 0.0004372458309001977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7286,
      "step": 120480
    },
    {
      "epoch": 0.0004373619652510344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7334,
      "step": 120512
    },
    {
      "epoch": 0.0004374780996018711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 120544
    },
    {
      "epoch": 0.0004375942339527078,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 120576
    },
    {
      "epoch": 0.0004377103683035445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 120608
    },
    {
      "epoch": 0.0004378265026543812,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 120640
    },
    {
      "epoch": 0.00043794263700521797,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 120672
    },
    {
      "epoch": 0.00043805877135605467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 120704
    },
    {
      "epoch": 0.00043817490570689137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 120736
    },
    {
      "epoch": 0.00043829104005772807,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 120768
    },
    {
      "epoch": 0.00043840717440856477,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 120800
    },
    {
      "epoch": 0.00043852330875940147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 120832
    },
    {
      "epoch": 0.00043863944311023817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 120864
    },
    {
      "epoch": 0.00043875557746107487,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 120896
    },
    {
      "epoch": 0.00043887171181191157,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 120928
    },
    {
      "epoch": 0.0004389878461627483,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 120960
    },
    {
      "epoch": 0.000439103980513585,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6882,
      "step": 120992
    },
    {
      "epoch": 0.0004392201148644217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6924,
      "step": 121024
    },
    {
      "epoch": 0.0004393362492152584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6927,
      "step": 121056
    },
    {
      "epoch": 0.0004394523835660951,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 121088
    },
    {
      "epoch": 0.0004395685179169318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 121120
    },
    {
      "epoch": 0.0004396846522677685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 121152
    },
    {
      "epoch": 0.0004398007866186052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 121184
    },
    {
      "epoch": 0.0004399169209694419,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 121216
    },
    {
      "epoch": 0.0004400330553202786,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 121248
    },
    {
      "epoch": 0.0004401491896711154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 121280
    },
    {
      "epoch": 0.0004402653240219521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 121312
    },
    {
      "epoch": 0.0004403814583727888,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 121344
    },
    {
      "epoch": 0.0004404975927236255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7573,
      "step": 121376
    },
    {
      "epoch": 0.0004406137270744622,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7357,
      "step": 121408
    },
    {
      "epoch": 0.0004407298614252989,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6891,
      "step": 121440
    },
    {
      "epoch": 0.0004408459957761356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 121472
    },
    {
      "epoch": 0.0004409621301269723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 121504
    },
    {
      "epoch": 0.000441078264477809,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 121536
    },
    {
      "epoch": 0.00044119439882864573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 121568
    },
    {
      "epoch": 0.00044131053317948243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 121600
    },
    {
      "epoch": 0.00044142666753031913,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 121632
    },
    {
      "epoch": 0.00044154280188115583,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 121664
    },
    {
      "epoch": 0.00044165893623199253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 121696
    },
    {
      "epoch": 0.00044177507058282923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 121728
    },
    {
      "epoch": 0.00044189120493366593,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6867,
      "step": 121760
    },
    {
      "epoch": 0.00044200733928450263,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6899,
      "step": 121792
    },
    {
      "epoch": 0.00044212347363533933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6795,
      "step": 121824
    },
    {
      "epoch": 0.0004422396079861761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 121856
    },
    {
      "epoch": 0.0004423557423370128,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 121888
    },
    {
      "epoch": 0.0004424718766878495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6875,
      "step": 121920
    },
    {
      "epoch": 0.0004425880110386862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6952,
      "step": 121952
    },
    {
      "epoch": 0.0004427041453895229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7362,
      "step": 121984
    },
    {
      "epoch": 0.0004428202797403596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 122016
    },
    {
      "epoch": 0.0004429364140911963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 122048
    },
    {
      "epoch": 0.000443052548442033,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 122080
    },
    {
      "epoch": 0.0004431686827928697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.733,
      "step": 122112
    },
    {
      "epoch": 0.00044328481714370644,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7473,
      "step": 122144
    },
    {
      "epoch": 0.00044340095149454314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 122176
    },
    {
      "epoch": 0.00044351708584537984,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 122208
    },
    {
      "epoch": 0.00044363322019621654,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7384,
      "step": 122240
    },
    {
      "epoch": 0.00044374935454705324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 122272
    },
    {
      "epoch": 0.00044386548889788994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 122304
    },
    {
      "epoch": 0.00044398162324872664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 122336
    },
    {
      "epoch": 0.00044409775759956334,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 122368
    },
    {
      "epoch": 0.00044421389195040004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 122400
    },
    {
      "epoch": 0.0004443300263012368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 122432
    },
    {
      "epoch": 0.0004444461606520735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 122464
    },
    {
      "epoch": 0.0004445622950029102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 122496
    },
    {
      "epoch": 0.0004446784293537469,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6869,
      "step": 122528
    },
    {
      "epoch": 0.0004447945637045836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6985,
      "step": 122560
    },
    {
      "epoch": 0.0004449106980554203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 122592
    },
    {
      "epoch": 0.000445026832406257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6859,
      "step": 122624
    },
    {
      "epoch": 0.0004451429667570937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6817,
      "step": 122656
    },
    {
      "epoch": 0.0004452591011079304,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.682,
      "step": 122688
    },
    {
      "epoch": 0.00044537523545876715,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 122720
    },
    {
      "epoch": 0.00044549136980960385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 122752
    },
    {
      "epoch": 0.00044560750416044055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 122784
    },
    {
      "epoch": 0.00044572363851127725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 122816
    },
    {
      "epoch": 0.00044583977286211395,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 122848
    },
    {
      "epoch": 0.00044595590721295065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7514,
      "step": 122880
    },
    {
      "epoch": 0.00044607204156378735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 122912
    },
    {
      "epoch": 0.00044618817591462405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 122944
    },
    {
      "epoch": 0.00044630431026546075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 122976
    },
    {
      "epoch": 0.0004464204446162975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 123008
    },
    {
      "epoch": 0.0004465365789671342,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 123040
    },
    {
      "epoch": 0.0004466527133179709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 123072
    },
    {
      "epoch": 0.0004467688476688076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7353,
      "step": 123104
    },
    {
      "epoch": 0.0004468849820196443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 123136
    },
    {
      "epoch": 0.000447001116370481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 123168
    },
    {
      "epoch": 0.0004471172507213177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 123200
    },
    {
      "epoch": 0.0004472333850721544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 123232
    },
    {
      "epoch": 0.0004473495194229911,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6954,
      "step": 123264
    },
    {
      "epoch": 0.00044746565377382785,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6861,
      "step": 123296
    },
    {
      "epoch": 0.00044758178812466455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7037,
      "step": 123328
    },
    {
      "epoch": 0.00044769792247550125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 123360
    },
    {
      "epoch": 0.00044781405682633795,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6885,
      "step": 123392
    },
    {
      "epoch": 0.00044793019117717465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6887,
      "step": 123424
    },
    {
      "epoch": 0.00044804632552801135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 123456
    },
    {
      "epoch": 0.00044816245987884805,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 123488
    },
    {
      "epoch": 0.00044827859422968475,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 123520
    },
    {
      "epoch": 0.00044839472858052145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 123552
    },
    {
      "epoch": 0.0004485108629313582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6893,
      "step": 123584
    },
    {
      "epoch": 0.0004486269972821949,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 123616
    },
    {
      "epoch": 0.0004487431316330316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 123648
    },
    {
      "epoch": 0.0004488592659838683,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 123680
    },
    {
      "epoch": 0.000448975400334705,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 123712
    },
    {
      "epoch": 0.0004490915346855417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7605,
      "step": 123744
    },
    {
      "epoch": 0.0004492076690363784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 123776
    },
    {
      "epoch": 0.0004493238033872151,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 123808
    },
    {
      "epoch": 0.0004494399377380518,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 123840
    },
    {
      "epoch": 0.00044955607208888856,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 123872
    },
    {
      "epoch": 0.00044967220643972526,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7272,
      "step": 123904
    },
    {
      "epoch": 0.00044978834079056196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.732,
      "step": 123936
    },
    {
      "epoch": 0.00044990447514139866,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7358,
      "step": 123968
    },
    {
      "epoch": 0.00045002060949223536,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6924,
      "step": 124000
    },
    {
      "epoch": 0.00045013674384307206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6973,
      "step": 124032
    },
    {
      "epoch": 0.00045025287819390876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 124064
    },
    {
      "epoch": 0.00045036901254474546,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6864,
      "step": 124096
    },
    {
      "epoch": 0.00045048514689558216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 124128
    },
    {
      "epoch": 0.0004506012812464189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.691,
      "step": 124160
    },
    {
      "epoch": 0.0004507174155972556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6889,
      "step": 124192
    },
    {
      "epoch": 0.0004508335499480923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 124224
    },
    {
      "epoch": 0.000450949684298929,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 124256
    },
    {
      "epoch": 0.0004510658186497657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 124288
    },
    {
      "epoch": 0.0004511819530006024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 124320
    },
    {
      "epoch": 0.0004512980873514391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 124352
    },
    {
      "epoch": 0.0004514142217022758,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6961,
      "step": 124384
    },
    {
      "epoch": 0.0004515303560531125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 124416
    },
    {
      "epoch": 0.00045164649040394927,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 124448
    },
    {
      "epoch": 0.00045176262475478597,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 124480
    },
    {
      "epoch": 0.00045187875910562267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 124512
    },
    {
      "epoch": 0.00045199489345645937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 124544
    },
    {
      "epoch": 0.00045211102780729607,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 124576
    },
    {
      "epoch": 0.00045222716215813277,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 124608
    },
    {
      "epoch": 0.00045234329650896947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7428,
      "step": 124640
    },
    {
      "epoch": 0.00045245943085980617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 124672
    },
    {
      "epoch": 0.00045257556521064287,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 124704
    },
    {
      "epoch": 0.0004526916995614796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 124736
    },
    {
      "epoch": 0.0004528078339123163,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 124768
    },
    {
      "epoch": 0.000452923968263153,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 124800
    },
    {
      "epoch": 0.0004530401026139897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 124832
    },
    {
      "epoch": 0.0004531562369648264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 124864
    },
    {
      "epoch": 0.0004532723713156631,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 124896
    },
    {
      "epoch": 0.0004533885056664998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 124928
    },
    {
      "epoch": 0.0004535046400173365,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6787,
      "step": 124960
    },
    {
      "epoch": 0.0004536207743681732,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 124992
    },
    {
      "epoch": 0.00045373690871901,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 125024
    },
    {
      "epoch": 0.0004538530430698467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 125056
    },
    {
      "epoch": 0.00045396917742068337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 125088
    },
    {
      "epoch": 0.00045408531177152007,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 125120
    },
    {
      "epoch": 0.00045420144612235677,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 125152
    },
    {
      "epoch": 0.00045431758047319347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 125184
    },
    {
      "epoch": 0.00045443371482403017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 125216
    },
    {
      "epoch": 0.00045454984917486687,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7382,
      "step": 125248
    },
    {
      "epoch": 0.00045466598352570357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 125280
    },
    {
      "epoch": 0.0004547821178765403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 125312
    },
    {
      "epoch": 0.000454898252227377,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.69,
      "step": 125344
    },
    {
      "epoch": 0.0004550143865782137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 125376
    },
    {
      "epoch": 0.0004551305209290504,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 125408
    },
    {
      "epoch": 0.0004552466552798871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 125440
    },
    {
      "epoch": 0.0004553627896307238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 125472
    },
    {
      "epoch": 0.0004554789239815605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7372,
      "step": 125504
    },
    {
      "epoch": 0.0004555950583323972,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 125536
    },
    {
      "epoch": 0.0004557111926832339,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 125568
    },
    {
      "epoch": 0.0004558273270340707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 125600
    },
    {
      "epoch": 0.0004559434613849074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 125632
    },
    {
      "epoch": 0.0004560595957357441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 125664
    },
    {
      "epoch": 0.0004561757300865808,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 125696
    },
    {
      "epoch": 0.0004562918644374175,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6787,
      "step": 125728
    },
    {
      "epoch": 0.0004564079987882542,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 125760
    },
    {
      "epoch": 0.0004565241331390909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 125792
    },
    {
      "epoch": 0.0004566402674899276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 125824
    },
    {
      "epoch": 0.0004567564018407643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 125856
    },
    {
      "epoch": 0.00045687253619160103,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 125888
    },
    {
      "epoch": 0.00045698867054243773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 125920
    },
    {
      "epoch": 0.00045710480489327443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 125952
    },
    {
      "epoch": 0.00045722093924411113,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 125984
    },
    {
      "epoch": 0.00045733707359494783,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7293,
      "step": 126016
    },
    {
      "epoch": 0.00045745320794578453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 126048
    },
    {
      "epoch": 0.00045756934229662123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 126080
    },
    {
      "epoch": 0.00045768547664745793,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 126112
    },
    {
      "epoch": 0.00045780161099829463,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 126144
    },
    {
      "epoch": 0.0004579177453491314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 126176
    },
    {
      "epoch": 0.0004580338796999681,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 126208
    },
    {
      "epoch": 0.0004581500140508048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 126240
    },
    {
      "epoch": 0.0004582661484016415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 126272
    },
    {
      "epoch": 0.0004583822827524782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 126304
    },
    {
      "epoch": 0.0004584984171033149,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6982,
      "step": 126336
    },
    {
      "epoch": 0.0004586145514541516,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 126368
    },
    {
      "epoch": 0.0004587306858049883,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 126400
    },
    {
      "epoch": 0.000458846820155825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 126432
    },
    {
      "epoch": 0.00045896295450666174,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 126464
    },
    {
      "epoch": 0.00045907908885749844,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 126496
    },
    {
      "epoch": 0.00045919522320833514,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 126528
    },
    {
      "epoch": 0.00045931135755917184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6836,
      "step": 126560
    },
    {
      "epoch": 0.00045942749191000854,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6832,
      "step": 126592
    },
    {
      "epoch": 0.00045954362626084524,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6917,
      "step": 126624
    },
    {
      "epoch": 0.00045965976061168194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.681,
      "step": 126656
    },
    {
      "epoch": 0.00045977589496251864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6997,
      "step": 126688
    },
    {
      "epoch": 0.00045989202931335534,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6865,
      "step": 126720
    },
    {
      "epoch": 0.00046000816366419204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6829,
      "step": 126752
    },
    {
      "epoch": 0.0004601242980150288,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 126784
    },
    {
      "epoch": 0.0004602404323658655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6761,
      "step": 126816
    },
    {
      "epoch": 0.0004603565667167022,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6881,
      "step": 126848
    },
    {
      "epoch": 0.0004604727010675389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6835,
      "step": 126880
    },
    {
      "epoch": 0.0004605888354183756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6902,
      "step": 126912
    },
    {
      "epoch": 0.0004607049697692123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6776,
      "step": 126944
    },
    {
      "epoch": 0.000460821104120049,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 126976
    },
    {
      "epoch": 0.0004609372384708857,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 127008
    },
    {
      "epoch": 0.0004610533728217224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6801,
      "step": 127040
    },
    {
      "epoch": 0.00046116950717255915,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6914,
      "step": 127072
    },
    {
      "epoch": 0.00046128564152339585,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6795,
      "step": 127104
    },
    {
      "epoch": 0.00046140177587423255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6758,
      "step": 127136
    },
    {
      "epoch": 0.00046151791022506925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6899,
      "step": 127168
    },
    {
      "epoch": 0.00046163404457590595,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 127200
    },
    {
      "epoch": 0.00046175017892674265,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 127232
    },
    {
      "epoch": 0.00046186631327757935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 127264
    },
    {
      "epoch": 0.00046198244762841605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 127296
    },
    {
      "epoch": 0.00046209858197925275,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 127328
    },
    {
      "epoch": 0.0004622147163300895,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 127360
    },
    {
      "epoch": 0.0004623308506809262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 127392
    },
    {
      "epoch": 0.0004624469850317629,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6841,
      "step": 127424
    },
    {
      "epoch": 0.0004625631193825996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6839,
      "step": 127456
    },
    {
      "epoch": 0.0004626792537334363,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6837,
      "step": 127488
    },
    {
      "epoch": 0.000462795388084273,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6845,
      "step": 127520
    },
    {
      "epoch": 0.0004629115224351097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6896,
      "step": 127552
    },
    {
      "epoch": 0.0004630276567859464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6997,
      "step": 127584
    },
    {
      "epoch": 0.0004631437911367831,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6804,
      "step": 127616
    },
    {
      "epoch": 0.00046325992548761985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6948,
      "step": 127648
    },
    {
      "epoch": 0.00046337605983845655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6844,
      "step": 127680
    },
    {
      "epoch": 0.00046349219418929325,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6779,
      "step": 127712
    },
    {
      "epoch": 0.00046360832854012995,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6742,
      "step": 127744
    },
    {
      "epoch": 0.00046372446289096665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6892,
      "step": 127776
    },
    {
      "epoch": 0.00046384059724180335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6904,
      "step": 127808
    },
    {
      "epoch": 0.00046395673159264005,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6932,
      "step": 127840
    },
    {
      "epoch": 0.00046407286594347675,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6911,
      "step": 127872
    },
    {
      "epoch": 0.00046418900029431345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6744,
      "step": 127904
    },
    {
      "epoch": 0.0004643051346451502,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6874,
      "step": 127936
    },
    {
      "epoch": 0.0004644212689959869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6787,
      "step": 127968
    },
    {
      "epoch": 0.0004645374033468236,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 128000
    },
    {
      "epoch": 0.0004646535376976603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 128032
    },
    {
      "epoch": 0.000464769672048497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 128064
    },
    {
      "epoch": 0.0004648858063993337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6947,
      "step": 128096
    },
    {
      "epoch": 0.0004650019407501704,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.694,
      "step": 128128
    },
    {
      "epoch": 0.0004651180751010071,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 128160
    },
    {
      "epoch": 0.0004652342094518438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 128192
    },
    {
      "epoch": 0.00046535034380268056,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 128224
    },
    {
      "epoch": 0.00046546647815351726,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 128256
    },
    {
      "epoch": 0.00046558261250435396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6688,
      "step": 128288
    },
    {
      "epoch": 0.00046569874685519066,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6911,
      "step": 128320
    },
    {
      "epoch": 0.00046581488120602736,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6783,
      "step": 128352
    },
    {
      "epoch": 0.00046593101555686406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6816,
      "step": 128384
    },
    {
      "epoch": 0.00046604714990770076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6805,
      "step": 128416
    },
    {
      "epoch": 0.00046616328425853746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 128448
    },
    {
      "epoch": 0.00046627941860937416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6792,
      "step": 128480
    },
    {
      "epoch": 0.0004663955529602109,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6847,
      "step": 128512
    },
    {
      "epoch": 0.0004665116873110476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6842,
      "step": 128544
    },
    {
      "epoch": 0.0004666278216618843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6792,
      "step": 128576
    },
    {
      "epoch": 0.000466743956012721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 128608
    },
    {
      "epoch": 0.0004668600903635577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6859,
      "step": 128640
    },
    {
      "epoch": 0.0004669762247143944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6776,
      "step": 128672
    },
    {
      "epoch": 0.0004670923590652311,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6708,
      "step": 128704
    },
    {
      "epoch": 0.0004672084934160678,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6943,
      "step": 128736
    },
    {
      "epoch": 0.0004673246277669045,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 128768
    },
    {
      "epoch": 0.00046744076211774127,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6766,
      "step": 128800
    },
    {
      "epoch": 0.00046755689646857797,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6696,
      "step": 128832
    },
    {
      "epoch": 0.00046767303081941467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6948,
      "step": 128864
    },
    {
      "epoch": 0.00046778916517025137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 128896
    },
    {
      "epoch": 0.00046790529952108807,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 128928
    },
    {
      "epoch": 0.00046802143387192477,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 128960
    },
    {
      "epoch": 0.00046813756822276147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 128992
    },
    {
      "epoch": 0.00046825370257359817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 129024
    },
    {
      "epoch": 0.00046836983692443487,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 129056
    },
    {
      "epoch": 0.0004684859712752716,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7004,
      "step": 129088
    },
    {
      "epoch": 0.0004686021056261083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 129120
    },
    {
      "epoch": 0.000468718239976945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6814,
      "step": 129152
    },
    {
      "epoch": 0.0004688343743277817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6795,
      "step": 129184
    },
    {
      "epoch": 0.0004689505086786184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 129216
    },
    {
      "epoch": 0.0004690666430294551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.679,
      "step": 129248
    },
    {
      "epoch": 0.0004691827773802918,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6757,
      "step": 129280
    },
    {
      "epoch": 0.0004692989117311285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6885,
      "step": 129312
    },
    {
      "epoch": 0.0004694150460819652,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 129344
    },
    {
      "epoch": 0.000469531180432802,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 129376
    },
    {
      "epoch": 0.0004696473147836387,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6741,
      "step": 129408
    },
    {
      "epoch": 0.0004697634491344754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6797,
      "step": 129440
    },
    {
      "epoch": 0.0004698795834853121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.679,
      "step": 129472
    },
    {
      "epoch": 0.0004699957178361488,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6767,
      "step": 129504
    },
    {
      "epoch": 0.0004701118521869855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6918,
      "step": 129536
    },
    {
      "epoch": 0.0004702279865378222,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6849,
      "step": 129568
    },
    {
      "epoch": 0.0004703441208886589,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6828,
      "step": 129600
    },
    {
      "epoch": 0.0004704602552394956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 129632
    },
    {
      "epoch": 0.00047057638959033233,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6769,
      "step": 129664
    },
    {
      "epoch": 0.00047069252394116903,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6894,
      "step": 129696
    },
    {
      "epoch": 0.00047080865829200573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6921,
      "step": 129728
    },
    {
      "epoch": 0.00047092479264284243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6919,
      "step": 129760
    },
    {
      "epoch": 0.00047104092699367913,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 129792
    },
    {
      "epoch": 0.00047115706134451583,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 129824
    },
    {
      "epoch": 0.0004712731956953525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 129856
    },
    {
      "epoch": 0.0004713893300461892,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7387,
      "step": 129888
    },
    {
      "epoch": 0.0004715054643970259,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.74,
      "step": 129920
    },
    {
      "epoch": 0.0004716215987478627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7465,
      "step": 129952
    },
    {
      "epoch": 0.0004717377330986994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7364,
      "step": 129984
    },
    {
      "epoch": 0.0004718538674495361,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6951,
      "step": 130016
    },
    {
      "epoch": 0.0004719700018003728,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 130048
    },
    {
      "epoch": 0.0004720861361512095,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 130080
    },
    {
      "epoch": 0.0004722022705020462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 130112
    },
    {
      "epoch": 0.0004723184048528829,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7304,
      "step": 130144
    },
    {
      "epoch": 0.0004724345392037196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 130176
    },
    {
      "epoch": 0.0004725506735545563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 130208
    },
    {
      "epoch": 0.00047266680790539303,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 130240
    },
    {
      "epoch": 0.00047278294225622973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 130272
    },
    {
      "epoch": 0.00047289907660706643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 130304
    },
    {
      "epoch": 0.00047301521095790313,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6907,
      "step": 130336
    },
    {
      "epoch": 0.00047313134530873983,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7273,
      "step": 130368
    },
    {
      "epoch": 0.00047324747965957653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 130400
    },
    {
      "epoch": 0.00047336361401041323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 130432
    },
    {
      "epoch": 0.00047347974836124993,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 130464
    },
    {
      "epoch": 0.00047359588271208663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 130496
    },
    {
      "epoch": 0.0004737120170629234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7218,
      "step": 130528
    },
    {
      "epoch": 0.0004738281514137601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 130560
    },
    {
      "epoch": 0.0004739442857645968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 130592
    },
    {
      "epoch": 0.0004740604201154335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 130624
    },
    {
      "epoch": 0.0004741765544662702,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 130656
    },
    {
      "epoch": 0.0004742926888171069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 130688
    },
    {
      "epoch": 0.0004744088231679436,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 130720
    },
    {
      "epoch": 0.0004745249575187803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7437,
      "step": 130752
    },
    {
      "epoch": 0.000474641091869617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.741,
      "step": 130784
    },
    {
      "epoch": 0.00047475722622045374,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7352,
      "step": 130816
    },
    {
      "epoch": 0.00047487336057129044,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 130848
    },
    {
      "epoch": 0.00047498949492212714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 130880
    },
    {
      "epoch": 0.00047510562927296384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 130912
    },
    {
      "epoch": 0.00047522176362380054,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 130944
    },
    {
      "epoch": 0.00047533789797463724,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 130976
    },
    {
      "epoch": 0.00047545403232547394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 131008
    },
    {
      "epoch": 0.00047557016667631064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 131040
    },
    {
      "epoch": 0.00047568630102714734,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.744,
      "step": 131072
    },
    {
      "epoch": 0.0004758024353779841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7344,
      "step": 131104
    },
    {
      "epoch": 0.0004759185697288208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 131136
    },
    {
      "epoch": 0.0004760347040796575,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 131168
    },
    {
      "epoch": 0.0004761508384304942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 131200
    },
    {
      "epoch": 0.0004762669727813309,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 131232
    },
    {
      "epoch": 0.0004763831071321676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 131264
    },
    {
      "epoch": 0.0004764992414830043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 131296
    },
    {
      "epoch": 0.000476615375833841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 131328
    },
    {
      "epoch": 0.0004767315101846777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 131360
    },
    {
      "epoch": 0.00047684764453551445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 131392
    },
    {
      "epoch": 0.00047696377888635115,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 131424
    },
    {
      "epoch": 0.00047707991323718785,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 131456
    },
    {
      "epoch": 0.00047719604758802455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 131488
    },
    {
      "epoch": 0.00047731218193886125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 131520
    },
    {
      "epoch": 0.00047742831628969795,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7479,
      "step": 131552
    },
    {
      "epoch": 0.00047754445064053465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 131584
    },
    {
      "epoch": 0.00047766058499137135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7296,
      "step": 131616
    },
    {
      "epoch": 0.00047777671934220805,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7309,
      "step": 131648
    },
    {
      "epoch": 0.0004778928536930448,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7592,
      "step": 131680
    },
    {
      "epoch": 0.0004780089880438815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 131712
    },
    {
      "epoch": 0.0004781251223947182,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 131744
    },
    {
      "epoch": 0.0004782412567455549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 131776
    },
    {
      "epoch": 0.0004783573910963916,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 131808
    },
    {
      "epoch": 0.0004784735254472283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 131840
    },
    {
      "epoch": 0.000478589659798065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 131872
    },
    {
      "epoch": 0.0004787057941489017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 131904
    },
    {
      "epoch": 0.0004788219284997384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7367,
      "step": 131936
    },
    {
      "epoch": 0.0004789380628505751,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 131968
    },
    {
      "epoch": 0.00047905419720141185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 132000
    },
    {
      "epoch": 0.00047917033155224855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 132032
    },
    {
      "epoch": 0.00047928646590308525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 132064
    },
    {
      "epoch": 0.00047940260025392195,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 132096
    },
    {
      "epoch": 0.00047951873460475865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 132128
    },
    {
      "epoch": 0.00047963486895559535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 132160
    },
    {
      "epoch": 0.00047975100330643205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 132192
    },
    {
      "epoch": 0.00047986713765726875,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 132224
    },
    {
      "epoch": 0.00047998327200810545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 132256
    },
    {
      "epoch": 0.0004800994063589422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7469,
      "step": 132288
    },
    {
      "epoch": 0.0004802155407097789,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 132320
    },
    {
      "epoch": 0.0004803316750606156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 132352
    },
    {
      "epoch": 0.0004804478094114523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 132384
    },
    {
      "epoch": 0.000480563943762289,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 132416
    },
    {
      "epoch": 0.0004806800781131257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7509,
      "step": 132448
    },
    {
      "epoch": 0.0004807962124639624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7452,
      "step": 132480
    },
    {
      "epoch": 0.0004809123468147991,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7345,
      "step": 132512
    },
    {
      "epoch": 0.0004810284811656358,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7574,
      "step": 132544
    },
    {
      "epoch": 0.00048114461551647256,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 132576
    },
    {
      "epoch": 0.00048126074986730926,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 132608
    },
    {
      "epoch": 0.00048137688421814596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 132640
    },
    {
      "epoch": 0.00048149301856898266,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6982,
      "step": 132672
    },
    {
      "epoch": 0.00048160915291981936,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 132704
    },
    {
      "epoch": 0.00048172528727065606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 132736
    },
    {
      "epoch": 0.00048184142162149276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 132768
    },
    {
      "epoch": 0.00048195755597232946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 132800
    },
    {
      "epoch": 0.00048207369032316616,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 132832
    },
    {
      "epoch": 0.0004821898246740029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 132864
    },
    {
      "epoch": 0.0004823059590248396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7458,
      "step": 132896
    },
    {
      "epoch": 0.0004824220933756763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 132928
    },
    {
      "epoch": 0.000482538227726513,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.695,
      "step": 132960
    },
    {
      "epoch": 0.0004826543620773497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 132992
    },
    {
      "epoch": 0.0004827704964281864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 133024
    },
    {
      "epoch": 0.0004828866307790231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 133056
    },
    {
      "epoch": 0.0004830027651298598,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 133088
    },
    {
      "epoch": 0.0004831188994806965,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 133120
    },
    {
      "epoch": 0.00048323503383153327,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7486,
      "step": 133152
    },
    {
      "epoch": 0.00048335116818236997,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 133184
    },
    {
      "epoch": 0.00048346730253320667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7327,
      "step": 133216
    },
    {
      "epoch": 0.00048358343688404337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 133248
    },
    {
      "epoch": 0.00048369957123488007,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 133280
    },
    {
      "epoch": 0.00048381570558571677,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7529,
      "step": 133312
    },
    {
      "epoch": 0.00048393183993655347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 133344
    },
    {
      "epoch": 0.00048404797428739017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7304,
      "step": 133376
    },
    {
      "epoch": 0.00048416410863822687,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7334,
      "step": 133408
    },
    {
      "epoch": 0.0004842802429890636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 133440
    },
    {
      "epoch": 0.0004843963773399003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 133472
    },
    {
      "epoch": 0.000484512511690737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 133504
    },
    {
      "epoch": 0.0004846286460415737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 133536
    },
    {
      "epoch": 0.0004847447803924104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 133568
    },
    {
      "epoch": 0.0004848609147432471,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 133600
    },
    {
      "epoch": 0.0004849770490940838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 133632
    },
    {
      "epoch": 0.0004850931834449205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 133664
    },
    {
      "epoch": 0.0004852093177957572,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 133696
    },
    {
      "epoch": 0.000485325452146594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 133728
    },
    {
      "epoch": 0.0004854415864974307,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 133760
    },
    {
      "epoch": 0.0004855577208482674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 133792
    },
    {
      "epoch": 0.0004856738551991041,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 133824
    },
    {
      "epoch": 0.0004857899895499408,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 133856
    },
    {
      "epoch": 0.0004859061239007775,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 133888
    },
    {
      "epoch": 0.0004860222582516142,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 133920
    },
    {
      "epoch": 0.0004861383926024509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 133952
    },
    {
      "epoch": 0.0004862545269532876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 133984
    },
    {
      "epoch": 0.00048637066130412433,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 134016
    },
    {
      "epoch": 0.00048648679565496103,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7388,
      "step": 134048
    },
    {
      "epoch": 0.00048660293000579773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 134080
    },
    {
      "epoch": 0.00048671906435663443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 134112
    },
    {
      "epoch": 0.00048683519870747113,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 134144
    },
    {
      "epoch": 0.00048695133305830783,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 134176
    },
    {
      "epoch": 0.00048706746740914453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 134208
    },
    {
      "epoch": 0.00048718360175998123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7379,
      "step": 134240
    },
    {
      "epoch": 0.00048729973611081793,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7601,
      "step": 134272
    },
    {
      "epoch": 0.0004874158704616547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 134304
    },
    {
      "epoch": 0.0004875320048124914,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 134336
    },
    {
      "epoch": 0.0004876481391633281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 134368
    },
    {
      "epoch": 0.0004877642735141648,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 134400
    },
    {
      "epoch": 0.0004878804078650015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 134432
    },
    {
      "epoch": 0.0004879965422158382,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 134464
    },
    {
      "epoch": 0.0004881126765666749,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7322,
      "step": 134496
    },
    {
      "epoch": 0.0004882288109175116,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7355,
      "step": 134528
    },
    {
      "epoch": 0.0004883449452683483,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 134560
    },
    {
      "epoch": 0.000488461079619185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 134592
    },
    {
      "epoch": 0.0004885772139700217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 134624
    },
    {
      "epoch": 0.0004886933483208584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 134656
    },
    {
      "epoch": 0.0004888094826716951,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 134688
    },
    {
      "epoch": 0.0004889256170225318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6969,
      "step": 134720
    },
    {
      "epoch": 0.0004890417513733685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 134752
    },
    {
      "epoch": 0.0004891578857242053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6951,
      "step": 134784
    },
    {
      "epoch": 0.0004892740200750419,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 134816
    },
    {
      "epoch": 0.0004893901544258787,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 134848
    },
    {
      "epoch": 0.0004895062887767153,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 134880
    },
    {
      "epoch": 0.0004896224231275521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 134912
    },
    {
      "epoch": 0.0004897385574783887,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7343,
      "step": 134944
    },
    {
      "epoch": 0.0004898546918292255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 134976
    },
    {
      "epoch": 0.0004899708261800621,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 135008
    },
    {
      "epoch": 0.0004900869605308989,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.737,
      "step": 135040
    },
    {
      "epoch": 0.0004902030948817356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.732,
      "step": 135072
    },
    {
      "epoch": 0.0004903192292325723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7336,
      "step": 135104
    },
    {
      "epoch": 0.000490435363583409,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7417,
      "step": 135136
    },
    {
      "epoch": 0.0004905514979342457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 135168
    },
    {
      "epoch": 0.0004906676322850824,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 135200
    },
    {
      "epoch": 0.0004907837666359191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 135232
    },
    {
      "epoch": 0.0004908999009867558,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 135264
    },
    {
      "epoch": 0.0004910160353375925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 135296
    },
    {
      "epoch": 0.0004911321696884292,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 135328
    },
    {
      "epoch": 0.000491248304039266,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7304,
      "step": 135360
    },
    {
      "epoch": 0.0004913644383901026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 135392
    },
    {
      "epoch": 0.0004914805727409394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 135424
    },
    {
      "epoch": 0.000491596707091776,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 135456
    },
    {
      "epoch": 0.0004917128414426128,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 135488
    },
    {
      "epoch": 0.0004918289757934494,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 135520
    },
    {
      "epoch": 0.0004919451101442862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 135552
    },
    {
      "epoch": 0.0004920612444951228,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 135584
    },
    {
      "epoch": 0.0004921773788459596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 135616
    },
    {
      "epoch": 0.0004922935131967963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7281,
      "step": 135648
    },
    {
      "epoch": 0.000492409647547633,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 135680
    },
    {
      "epoch": 0.0004925257818984697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 135712
    },
    {
      "epoch": 0.0004926419162493064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 135744
    },
    {
      "epoch": 0.0004927580506001431,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.729,
      "step": 135776
    },
    {
      "epoch": 0.0004928741849509798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7448,
      "step": 135808
    },
    {
      "epoch": 0.0004929903193018165,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7448,
      "step": 135840
    },
    {
      "epoch": 0.0004931064536526532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 135872
    },
    {
      "epoch": 0.00049322258800349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7426,
      "step": 135904
    },
    {
      "epoch": 0.0004933387223543267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 135936
    },
    {
      "epoch": 0.0004934548567051633,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7509,
      "step": 135968
    },
    {
      "epoch": 0.0004935709910560001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7301,
      "step": 136000
    },
    {
      "epoch": 0.0004936871254068367,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 136032
    },
    {
      "epoch": 0.0004938032597576735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 136064
    },
    {
      "epoch": 0.0004939193941085101,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 136096
    },
    {
      "epoch": 0.0004940355284593469,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 136128
    },
    {
      "epoch": 0.0004941516628101835,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 136160
    },
    {
      "epoch": 0.0004942677971610203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 136192
    },
    {
      "epoch": 0.0004943839315118571,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7361,
      "step": 136224
    },
    {
      "epoch": 0.0004945000658626937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 136256
    },
    {
      "epoch": 0.0004946162002135305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 136288
    },
    {
      "epoch": 0.0004947323345643671,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 136320
    },
    {
      "epoch": 0.0004948484689152039,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 136352
    },
    {
      "epoch": 0.0004949646032660405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 136384
    },
    {
      "epoch": 0.0004950807376168773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 136416
    },
    {
      "epoch": 0.0004951968719677139,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 136448
    },
    {
      "epoch": 0.0004953130063185507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 136480
    },
    {
      "epoch": 0.0004954291406693874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 136512
    },
    {
      "epoch": 0.0004955452750202241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 136544
    },
    {
      "epoch": 0.0004956614093710608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7417,
      "step": 136576
    },
    {
      "epoch": 0.0004957775437218975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 136608
    },
    {
      "epoch": 0.0004958936780727342,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 136640
    },
    {
      "epoch": 0.0004960098124235709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7358,
      "step": 136672
    },
    {
      "epoch": 0.0004961259467744076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.744,
      "step": 136704
    },
    {
      "epoch": 0.0004962420811252443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 136736
    },
    {
      "epoch": 0.000496358215476081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 136768
    },
    {
      "epoch": 0.0004964743498269178,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 136800
    },
    {
      "epoch": 0.0004965904841777544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7408,
      "step": 136832
    },
    {
      "epoch": 0.0004967066185285912,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 136864
    },
    {
      "epoch": 0.0004968227528794278,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 136896
    },
    {
      "epoch": 0.0004969388872302646,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 136928
    },
    {
      "epoch": 0.0004970550215811012,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 136960
    },
    {
      "epoch": 0.000497171155931938,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7395,
      "step": 136992
    },
    {
      "epoch": 0.0004972872902827746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7323,
      "step": 137024
    },
    {
      "epoch": 0.0004974034246336114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 137056
    },
    {
      "epoch": 0.0004975195589844481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 137088
    },
    {
      "epoch": 0.0004976356933352848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 137120
    },
    {
      "epoch": 0.0004977518276861215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 137152
    },
    {
      "epoch": 0.0004978679620369582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.729,
      "step": 137184
    },
    {
      "epoch": 0.0004979840963877949,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7348,
      "step": 137216
    },
    {
      "epoch": 0.0004981002307386316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 137248
    },
    {
      "epoch": 0.0004982163650894683,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 137280
    },
    {
      "epoch": 0.000498332499440305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 137312
    },
    {
      "epoch": 0.0004984486337911417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 137344
    },
    {
      "epoch": 0.0004985647681419785,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 137376
    },
    {
      "epoch": 0.0004986809024928151,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 137408
    },
    {
      "epoch": 0.0004987970368436519,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 137440
    },
    {
      "epoch": 0.0004989131711944885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 137472
    },
    {
      "epoch": 0.0004990293055453253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7349,
      "step": 137504
    },
    {
      "epoch": 0.0004991454398961619,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.729,
      "step": 137536
    },
    {
      "epoch": 0.0004992615742469987,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7273,
      "step": 137568
    },
    {
      "epoch": 0.0004993777085978353,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7532,
      "step": 137600
    },
    {
      "epoch": 0.0004994938429486721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 137632
    },
    {
      "epoch": 0.0004996099772995088,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7389,
      "step": 137664
    },
    {
      "epoch": 0.0004997261116503455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7453,
      "step": 137696
    },
    {
      "epoch": 0.0004998422460011822,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7026,
      "step": 137728
    },
    {
      "epoch": 0.0004999583803520189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 137760
    },
    {
      "epoch": 0.0005000745147028556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 137792
    },
    {
      "epoch": 0.0005001906490536923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 137824
    },
    {
      "epoch": 0.000500306783404529,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 137856
    },
    {
      "epoch": 0.0005004229177553657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 137888
    },
    {
      "epoch": 0.0005005390521062024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 137920
    },
    {
      "epoch": 0.0005006551864570392,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.741,
      "step": 137952
    },
    {
      "epoch": 0.0005007713208078758,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 137984
    },
    {
      "epoch": 0.0005008874551587126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 138016
    },
    {
      "epoch": 0.0005010035895095492,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 138048
    },
    {
      "epoch": 0.000501119723860386,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 138080
    },
    {
      "epoch": 0.0005012358582112226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 138112
    },
    {
      "epoch": 0.0005013519925620594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 138144
    },
    {
      "epoch": 0.000501468126912896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 138176
    },
    {
      "epoch": 0.0005015842612637328,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7076,
      "step": 138208
    },
    {
      "epoch": 0.0005017003956145695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 138240
    },
    {
      "epoch": 0.0005018165299654062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 138272
    },
    {
      "epoch": 0.0005019326643162429,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 138304
    },
    {
      "epoch": 0.0005020487986670796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 138336
    },
    {
      "epoch": 0.0005021649330179163,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7491,
      "step": 138368
    },
    {
      "epoch": 0.000502281067368753,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 138400
    },
    {
      "epoch": 0.0005023972017195897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 138432
    },
    {
      "epoch": 0.0005025133360704264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7492,
      "step": 138464
    },
    {
      "epoch": 0.0005026294704212631,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 138496
    },
    {
      "epoch": 0.0005027456047720999,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 138528
    },
    {
      "epoch": 0.0005028617391229365,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7627,
      "step": 138560
    },
    {
      "epoch": 0.0005029778734737733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 138592
    },
    {
      "epoch": 0.0005030940078246099,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 138624
    },
    {
      "epoch": 0.0005032101421754467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 138656
    },
    {
      "epoch": 0.0005033262765262833,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 138688
    },
    {
      "epoch": 0.0005034424108771201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 138720
    },
    {
      "epoch": 0.0005035585452279567,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7419,
      "step": 138752
    },
    {
      "epoch": 0.0005036746795787935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 138784
    },
    {
      "epoch": 0.0005037908139296302,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 138816
    },
    {
      "epoch": 0.0005039069482804669,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 138848
    },
    {
      "epoch": 0.0005040230826313036,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 138880
    },
    {
      "epoch": 0.0005041392169821403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 138912
    },
    {
      "epoch": 0.000504255351332977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 138944
    },
    {
      "epoch": 0.0005043714856838137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 138976
    },
    {
      "epoch": 0.0005044876200346504,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 139008
    },
    {
      "epoch": 0.0005046037543854871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7499,
      "step": 139040
    },
    {
      "epoch": 0.0005047198887363238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 139072
    },
    {
      "epoch": 0.0005048360230871606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 139104
    },
    {
      "epoch": 0.0005049521574379972,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 139136
    },
    {
      "epoch": 0.000505068291788834,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 139168
    },
    {
      "epoch": 0.0005051844261396706,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7377,
      "step": 139200
    },
    {
      "epoch": 0.0005053005604905074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 139232
    },
    {
      "epoch": 0.000505416694841344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7413,
      "step": 139264
    },
    {
      "epoch": 0.0005055328291921808,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7431,
      "step": 139296
    },
    {
      "epoch": 0.0005056489635430174,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7462,
      "step": 139328
    },
    {
      "epoch": 0.0005057650978938542,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7548,
      "step": 139360
    },
    {
      "epoch": 0.0005058812322446909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 139392
    },
    {
      "epoch": 0.0005059973665955276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 139424
    },
    {
      "epoch": 0.0005061135009463643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 139456
    },
    {
      "epoch": 0.000506229635297201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 139488
    },
    {
      "epoch": 0.0005063457696480377,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 139520
    },
    {
      "epoch": 0.0005064619039988744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 139552
    },
    {
      "epoch": 0.0005065780383497111,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 139584
    },
    {
      "epoch": 0.0005066941727005478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7315,
      "step": 139616
    },
    {
      "epoch": 0.0005068103070513845,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 139648
    },
    {
      "epoch": 0.0005069264414022213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 139680
    },
    {
      "epoch": 0.0005070425757530579,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 139712
    },
    {
      "epoch": 0.0005071587101038947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 139744
    },
    {
      "epoch": 0.0005072748444547313,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 139776
    },
    {
      "epoch": 0.0005073909788055681,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 139808
    },
    {
      "epoch": 0.0005075071131564047,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 139840
    },
    {
      "epoch": 0.0005076232475072415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 139872
    },
    {
      "epoch": 0.0005077393818580781,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.729,
      "step": 139904
    },
    {
      "epoch": 0.0005078555162089149,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7419,
      "step": 139936
    },
    {
      "epoch": 0.0005079716505597517,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7248,
      "step": 139968
    },
    {
      "epoch": 0.0005080877849105883,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 140000
    },
    {
      "epoch": 0.000508203919261425,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 140032
    },
    {
      "epoch": 0.0005083200536122617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 140064
    },
    {
      "epoch": 0.0005084361879630985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.732,
      "step": 140096
    },
    {
      "epoch": 0.0005085523223139351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7365,
      "step": 140128
    },
    {
      "epoch": 0.0005086684566647719,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 140160
    },
    {
      "epoch": 0.0005087845910156085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 140192
    },
    {
      "epoch": 0.0005089007253664452,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7396,
      "step": 140224
    },
    {
      "epoch": 0.000509016859717282,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7404,
      "step": 140256
    },
    {
      "epoch": 0.0005091329940681186,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7308,
      "step": 140288
    },
    {
      "epoch": 0.0005092491284189554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 140320
    },
    {
      "epoch": 0.000509365262769792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6892,
      "step": 140352
    },
    {
      "epoch": 0.0005094813971206288,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7353,
      "step": 140384
    },
    {
      "epoch": 0.0005095975314714654,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7361,
      "step": 140416
    },
    {
      "epoch": 0.0005097136658223022,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 140448
    },
    {
      "epoch": 0.0005098298001731388,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7023,
      "step": 140480
    },
    {
      "epoch": 0.0005099459345239756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7329,
      "step": 140512
    },
    {
      "epoch": 0.0005100620688748124,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7275,
      "step": 140544
    },
    {
      "epoch": 0.000510178203225649,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 140576
    },
    {
      "epoch": 0.0005102943375764858,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 140608
    },
    {
      "epoch": 0.0005104104719273224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 140640
    },
    {
      "epoch": 0.0005105266062781592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 140672
    },
    {
      "epoch": 0.0005106427406289958,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 140704
    },
    {
      "epoch": 0.0005107588749798326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7218,
      "step": 140736
    },
    {
      "epoch": 0.0005108750093306692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 140768
    },
    {
      "epoch": 0.000510991143681506,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7377,
      "step": 140800
    },
    {
      "epoch": 0.0005111072780323427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 140832
    },
    {
      "epoch": 0.0005112234123831794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 140864
    },
    {
      "epoch": 0.0005113395467340161,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 140896
    },
    {
      "epoch": 0.0005114556810848528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 140928
    },
    {
      "epoch": 0.0005115718154356895,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 140960
    },
    {
      "epoch": 0.0005116879497865262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7441,
      "step": 140992
    },
    {
      "epoch": 0.0005118040841373629,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7291,
      "step": 141024
    },
    {
      "epoch": 0.0005119202184881996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7277,
      "step": 141056
    },
    {
      "epoch": 0.0005120363528390363,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.746,
      "step": 141088
    },
    {
      "epoch": 0.0005121524871898731,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7564,
      "step": 141120
    },
    {
      "epoch": 0.0005122686215407097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 141152
    },
    {
      "epoch": 0.0005123847558915465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 141184
    },
    {
      "epoch": 0.0005125008902423831,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 141216
    },
    {
      "epoch": 0.0005126170245932199,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 141248
    },
    {
      "epoch": 0.0005127331589440565,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 141280
    },
    {
      "epoch": 0.0005128492932948933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 141312
    },
    {
      "epoch": 0.0005129654276457299,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7357,
      "step": 141344
    },
    {
      "epoch": 0.0005130815619965667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7311,
      "step": 141376
    },
    {
      "epoch": 0.0005131976963474034,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7291,
      "step": 141408
    },
    {
      "epoch": 0.0005133138306982401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 141440
    },
    {
      "epoch": 0.0005134299650490768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 141472
    },
    {
      "epoch": 0.0005135460993999135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 141504
    },
    {
      "epoch": 0.0005136622337507502,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 141536
    },
    {
      "epoch": 0.0005137783681015869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 141568
    },
    {
      "epoch": 0.0005138945024524236,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 141600
    },
    {
      "epoch": 0.0005140106368032603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 141632
    },
    {
      "epoch": 0.000514126771154097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 141664
    },
    {
      "epoch": 0.0005142429055049338,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 141696
    },
    {
      "epoch": 0.0005143590398557704,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 141728
    },
    {
      "epoch": 0.0005144751742066072,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 141760
    },
    {
      "epoch": 0.0005145913085574438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7415,
      "step": 141792
    },
    {
      "epoch": 0.0005147074429082806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 141824
    },
    {
      "epoch": 0.0005148235772591172,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 141856
    },
    {
      "epoch": 0.000514939711609954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 141888
    },
    {
      "epoch": 0.0005150558459607906,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7349,
      "step": 141920
    },
    {
      "epoch": 0.0005151719803116274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7448,
      "step": 141952
    },
    {
      "epoch": 0.0005152881146624641,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7632,
      "step": 141984
    },
    {
      "epoch": 0.0005154042490133008,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 142016
    },
    {
      "epoch": 0.0005155203833641375,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 142048
    },
    {
      "epoch": 0.0005156365177149742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 142080
    },
    {
      "epoch": 0.0005157526520658109,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 142112
    },
    {
      "epoch": 0.0005158687864166476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 142144
    },
    {
      "epoch": 0.0005159849207674843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 142176
    },
    {
      "epoch": 0.000516101055118321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 142208
    },
    {
      "epoch": 0.0005162171894691577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 142240
    },
    {
      "epoch": 0.0005163333238199945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 142272
    },
    {
      "epoch": 0.0005164494581708311,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 142304
    },
    {
      "epoch": 0.0005165655925216679,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 142336
    },
    {
      "epoch": 0.0005166817268725045,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 142368
    },
    {
      "epoch": 0.0005167978612233413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 142400
    },
    {
      "epoch": 0.0005169139955741779,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 142432
    },
    {
      "epoch": 0.0005170301299250147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 142464
    },
    {
      "epoch": 0.0005171462642758513,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 142496
    },
    {
      "epoch": 0.0005172623986266881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 142528
    },
    {
      "epoch": 0.0005173785329775248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7361,
      "step": 142560
    },
    {
      "epoch": 0.0005174946673283615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 142592
    },
    {
      "epoch": 0.0005176108016791982,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 142624
    },
    {
      "epoch": 0.0005177269360300349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7418,
      "step": 142656
    },
    {
      "epoch": 0.0005178430703808716,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 142688
    },
    {
      "epoch": 0.0005179592047317083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.752,
      "step": 142720
    },
    {
      "epoch": 0.000518075339082545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7371,
      "step": 142752
    },
    {
      "epoch": 0.0005181914734333817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7284,
      "step": 142784
    },
    {
      "epoch": 0.0005183076077842184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7325,
      "step": 142816
    },
    {
      "epoch": 0.0005184237421350552,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7605,
      "step": 142848
    },
    {
      "epoch": 0.0005185398764858918,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7284,
      "step": 142880
    },
    {
      "epoch": 0.0005186560108367286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 142912
    },
    {
      "epoch": 0.0005187721451875652,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 142944
    },
    {
      "epoch": 0.000518888279538402,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 142976
    },
    {
      "epoch": 0.0005190044138892386,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 143008
    },
    {
      "epoch": 0.0005191205482400754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7291,
      "step": 143040
    },
    {
      "epoch": 0.000519236682590912,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 143072
    },
    {
      "epoch": 0.0005193528169417488,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 143104
    },
    {
      "epoch": 0.0005194689512925855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7343,
      "step": 143136
    },
    {
      "epoch": 0.0005195850856434222,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 143168
    },
    {
      "epoch": 0.0005197012199942589,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 143200
    },
    {
      "epoch": 0.0005198173543450956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 143232
    },
    {
      "epoch": 0.0005199334886959323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 143264
    },
    {
      "epoch": 0.000520049623046769,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 143296
    },
    {
      "epoch": 0.0005201657573976057,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7393,
      "step": 143328
    },
    {
      "epoch": 0.0005202818917484424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 143360
    },
    {
      "epoch": 0.0005203980260992791,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 143392
    },
    {
      "epoch": 0.0005205141604501159,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7008,
      "step": 143424
    },
    {
      "epoch": 0.0005206302948009525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7346,
      "step": 143456
    },
    {
      "epoch": 0.0005207464291517893,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7369,
      "step": 143488
    },
    {
      "epoch": 0.0005208625635026259,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 143520
    },
    {
      "epoch": 0.0005209786978534627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 143552
    },
    {
      "epoch": 0.0005210948322042993,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 143584
    },
    {
      "epoch": 0.0005212109665551361,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 143616
    },
    {
      "epoch": 0.0005213271009059727,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 143648
    },
    {
      "epoch": 0.0005214432352568095,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 143680
    },
    {
      "epoch": 0.0005215593696076462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7455,
      "step": 143712
    },
    {
      "epoch": 0.0005216755039584829,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7268,
      "step": 143744
    },
    {
      "epoch": 0.0005217916383093196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 143776
    },
    {
      "epoch": 0.0005219077726601563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 143808
    },
    {
      "epoch": 0.000522023907010993,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 143840
    },
    {
      "epoch": 0.0005221400413618297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 143872
    },
    {
      "epoch": 0.0005222561757126664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 143904
    },
    {
      "epoch": 0.0005223723100635031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 143936
    },
    {
      "epoch": 0.0005224884444143398,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 143968
    },
    {
      "epoch": 0.0005226045787651766,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 144000
    },
    {
      "epoch": 0.0005227207131160132,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 144032
    },
    {
      "epoch": 0.00052283684746685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7421,
      "step": 144064
    },
    {
      "epoch": 0.0005229529818176866,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 144096
    },
    {
      "epoch": 0.0005230691161685234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 144128
    },
    {
      "epoch": 0.00052318525051936,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 144160
    },
    {
      "epoch": 0.0005233013848701968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 144192
    },
    {
      "epoch": 0.0005234175192210334,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 144224
    },
    {
      "epoch": 0.0005235336535718702,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 144256
    },
    {
      "epoch": 0.000523649787922707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 144288
    },
    {
      "epoch": 0.0005237659222735436,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 144320
    },
    {
      "epoch": 0.0005238820566243804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7374,
      "step": 144352
    },
    {
      "epoch": 0.000523998190975217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 144384
    },
    {
      "epoch": 0.0005241143253260538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 144416
    },
    {
      "epoch": 0.0005242304596768904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 144448
    },
    {
      "epoch": 0.0005243465940277272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7418,
      "step": 144480
    },
    {
      "epoch": 0.0005244627283785638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7484,
      "step": 144512
    },
    {
      "epoch": 0.0005245788627294006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7367,
      "step": 144544
    },
    {
      "epoch": 0.0005246949970802373,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7331,
      "step": 144576
    },
    {
      "epoch": 0.000524811131431074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 144608
    },
    {
      "epoch": 0.0005249272657819107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 144640
    },
    {
      "epoch": 0.0005250434001327474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 144672
    },
    {
      "epoch": 0.0005251595344835841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 144704
    },
    {
      "epoch": 0.0005252756688344208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 144736
    },
    {
      "epoch": 0.0005253918031852575,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 144768
    },
    {
      "epoch": 0.0005255079375360942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7272,
      "step": 144800
    },
    {
      "epoch": 0.0005256240718869309,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 144832
    },
    {
      "epoch": 0.0005257402062377677,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.732,
      "step": 144864
    },
    {
      "epoch": 0.0005258563405886043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 144896
    },
    {
      "epoch": 0.0005259724749394411,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 144928
    },
    {
      "epoch": 0.0005260886092902777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 144960
    },
    {
      "epoch": 0.0005262047436411145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 144992
    },
    {
      "epoch": 0.0005263208779919511,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 145024
    },
    {
      "epoch": 0.0005264370123427879,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 145056
    },
    {
      "epoch": 0.0005265531466936245,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7349,
      "step": 145088
    },
    {
      "epoch": 0.0005266692810444613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 145120
    },
    {
      "epoch": 0.000526785415395298,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 145152
    },
    {
      "epoch": 0.0005269015497461347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7404,
      "step": 145184
    },
    {
      "epoch": 0.0005270176840969714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7262,
      "step": 145216
    },
    {
      "epoch": 0.0005271338184478081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 145248
    },
    {
      "epoch": 0.0005272499527986448,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7359,
      "step": 145280
    },
    {
      "epoch": 0.0005273660871494815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 145312
    },
    {
      "epoch": 0.0005274822215003182,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 145344
    },
    {
      "epoch": 0.0005275983558511549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7388,
      "step": 145376
    },
    {
      "epoch": 0.0005277144902019916,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7458,
      "step": 145408
    },
    {
      "epoch": 0.0005278306245528283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7484,
      "step": 145440
    },
    {
      "epoch": 0.000527946758903665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 145472
    },
    {
      "epoch": 0.0005280628932545018,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 145504
    },
    {
      "epoch": 0.0005281790276053384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 145536
    },
    {
      "epoch": 0.0005282951619561752,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 145568
    },
    {
      "epoch": 0.0005284112963070118,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 145600
    },
    {
      "epoch": 0.0005285274306578486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 145632
    },
    {
      "epoch": 0.0005286435650086852,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 145664
    },
    {
      "epoch": 0.000528759699359522,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 145696
    },
    {
      "epoch": 0.0005288758337103586,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 145728
    },
    {
      "epoch": 0.0005289919680611954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 145760
    },
    {
      "epoch": 0.0005291081024120321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 145792
    },
    {
      "epoch": 0.0005292242367628688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 145824
    },
    {
      "epoch": 0.0005293403711137055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 145856
    },
    {
      "epoch": 0.0005294565054645422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 145888
    },
    {
      "epoch": 0.0005295726398153789,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 145920
    },
    {
      "epoch": 0.0005296887741662156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 145952
    },
    {
      "epoch": 0.0005298049085170523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7056,
      "step": 145984
    },
    {
      "epoch": 0.000529921042867889,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 146016
    },
    {
      "epoch": 0.0005300371772187257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 146048
    },
    {
      "epoch": 0.0005301533115695625,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7543,
      "step": 146080
    },
    {
      "epoch": 0.0005302694459203991,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7562,
      "step": 146112
    },
    {
      "epoch": 0.0005303855802712359,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 146144
    },
    {
      "epoch": 0.0005305017146220725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 146176
    },
    {
      "epoch": 0.0005306178489729093,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7329,
      "step": 146208
    },
    {
      "epoch": 0.0005307339833237459,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7425,
      "step": 146240
    },
    {
      "epoch": 0.0005308501176745827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7467,
      "step": 146272
    },
    {
      "epoch": 0.0005309662520254193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 146304
    },
    {
      "epoch": 0.0005310823863762561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 146336
    },
    {
      "epoch": 0.0005311985207270928,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 146368
    },
    {
      "epoch": 0.0005313146550779295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.739,
      "step": 146400
    },
    {
      "epoch": 0.0005314307894287662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 146432
    },
    {
      "epoch": 0.0005315469237796029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 146464
    },
    {
      "epoch": 0.0005316630581304396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 146496
    },
    {
      "epoch": 0.0005317791924812763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 146528
    },
    {
      "epoch": 0.000531895326832113,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 146560
    },
    {
      "epoch": 0.0005320114611829497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 146592
    },
    {
      "epoch": 0.0005321275955337864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 146624
    },
    {
      "epoch": 0.0005322437298846232,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 146656
    },
    {
      "epoch": 0.0005323598642354598,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7297,
      "step": 146688
    },
    {
      "epoch": 0.0005324759985862966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 146720
    },
    {
      "epoch": 0.0005325921329371332,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 146752
    },
    {
      "epoch": 0.00053270826728797,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 146784
    },
    {
      "epoch": 0.0005328244016388066,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 146816
    },
    {
      "epoch": 0.0005329405359896434,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 146848
    },
    {
      "epoch": 0.00053305667034048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 146880
    },
    {
      "epoch": 0.0005331728046913168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 146912
    },
    {
      "epoch": 0.0005332889390421535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7414,
      "step": 146944
    },
    {
      "epoch": 0.0005334050733929902,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 146976
    },
    {
      "epoch": 0.0005335212077438269,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7514,
      "step": 147008
    },
    {
      "epoch": 0.0005336373420946636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7248,
      "step": 147040
    },
    {
      "epoch": 0.0005337534764455003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 147072
    },
    {
      "epoch": 0.000533869610796337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 147104
    },
    {
      "epoch": 0.0005339857451471737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7516,
      "step": 147136
    },
    {
      "epoch": 0.0005341018794980104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 147168
    },
    {
      "epoch": 0.0005342180138488471,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 147200
    },
    {
      "epoch": 0.0005343341481996839,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 147232
    },
    {
      "epoch": 0.0005344502825505205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 147264
    },
    {
      "epoch": 0.0005345664169013573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 147296
    },
    {
      "epoch": 0.0005346825512521939,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 147328
    },
    {
      "epoch": 0.0005347986856030307,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 147360
    },
    {
      "epoch": 0.0005349148199538673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 147392
    },
    {
      "epoch": 0.0005350309543047041,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 147424
    },
    {
      "epoch": 0.0005351470886555407,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 147456
    },
    {
      "epoch": 0.0005352632230063775,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 147488
    },
    {
      "epoch": 0.0005353793573572142,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 147520
    },
    {
      "epoch": 0.0005354954917080509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 147552
    },
    {
      "epoch": 0.0005356116260588876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 147584
    },
    {
      "epoch": 0.0005357277604097243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7315,
      "step": 147616
    },
    {
      "epoch": 0.000535843894760561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 147648
    },
    {
      "epoch": 0.0005359600291113977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6895,
      "step": 147680
    },
    {
      "epoch": 0.0005360761634622344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6985,
      "step": 147712
    },
    {
      "epoch": 0.0005361922978130711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 147744
    },
    {
      "epoch": 0.0005363084321639078,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 147776
    },
    {
      "epoch": 0.0005364245665147446,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 147808
    },
    {
      "epoch": 0.0005365407008655812,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 147840
    },
    {
      "epoch": 0.000536656835216418,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7455,
      "step": 147872
    },
    {
      "epoch": 0.0005367729695672546,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 147904
    },
    {
      "epoch": 0.0005368891039180914,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7491,
      "step": 147936
    },
    {
      "epoch": 0.000537005238268928,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 147968
    },
    {
      "epoch": 0.0005371213726197648,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7379,
      "step": 148000
    },
    {
      "epoch": 0.0005372375069706014,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7275,
      "step": 148032
    },
    {
      "epoch": 0.0005373536413214382,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 148064
    },
    {
      "epoch": 0.000537469775672275,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 148096
    },
    {
      "epoch": 0.0005375859100231116,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 148128
    },
    {
      "epoch": 0.0005377020443739483,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7393,
      "step": 148160
    },
    {
      "epoch": 0.000537818178724785,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 148192
    },
    {
      "epoch": 0.0005379343130756217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7248,
      "step": 148224
    },
    {
      "epoch": 0.0005380504474264584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7177,
      "step": 148256
    },
    {
      "epoch": 0.0005381665817772951,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 148288
    },
    {
      "epoch": 0.0005382827161281318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 148320
    },
    {
      "epoch": 0.0005383988504789685,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 148352
    },
    {
      "epoch": 0.0005385149848298053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 148384
    },
    {
      "epoch": 0.0005386311191806419,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 148416
    },
    {
      "epoch": 0.0005387472535314787,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7266,
      "step": 148448
    },
    {
      "epoch": 0.0005388633878823153,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 148480
    },
    {
      "epoch": 0.0005389795222331521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 148512
    },
    {
      "epoch": 0.0005390956565839887,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 148544
    },
    {
      "epoch": 0.0005392117909348255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 148576
    },
    {
      "epoch": 0.0005393279252856621,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 148608
    },
    {
      "epoch": 0.0005394440596364989,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 148640
    },
    {
      "epoch": 0.0005395601939873357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 148672
    },
    {
      "epoch": 0.0005396763283381723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 148704
    },
    {
      "epoch": 0.000539792462689009,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 148736
    },
    {
      "epoch": 0.0005399085970398457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7565,
      "step": 148768
    },
    {
      "epoch": 0.0005400247313906825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.742,
      "step": 148800
    },
    {
      "epoch": 0.0005401408657415191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7462,
      "step": 148832
    },
    {
      "epoch": 0.0005402570000923559,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7431,
      "step": 148864
    },
    {
      "epoch": 0.0005403731344431925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 148896
    },
    {
      "epoch": 0.0005404892687940293,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 148928
    },
    {
      "epoch": 0.000540605403144866,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 148960
    },
    {
      "epoch": 0.0005407215374957027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 148992
    },
    {
      "epoch": 0.0005408376718465394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 149024
    },
    {
      "epoch": 0.000540953806197376,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 149056
    },
    {
      "epoch": 0.0005410699405482128,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 149088
    },
    {
      "epoch": 0.0005411860748990495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 149120
    },
    {
      "epoch": 0.0005413022092498862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 149152
    },
    {
      "epoch": 0.0005414183436007229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 149184
    },
    {
      "epoch": 0.0005415344779515596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 149216
    },
    {
      "epoch": 0.0005416506123023964,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 149248
    },
    {
      "epoch": 0.000541766746653233,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 149280
    },
    {
      "epoch": 0.0005418828810040698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 149312
    },
    {
      "epoch": 0.0005419990153549064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 149344
    },
    {
      "epoch": 0.0005421151497057432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 149376
    },
    {
      "epoch": 0.0005422312840565798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 149408
    },
    {
      "epoch": 0.0005423474184074166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 149440
    },
    {
      "epoch": 0.0005424635527582532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 149472
    },
    {
      "epoch": 0.00054257968710909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7304,
      "step": 149504
    },
    {
      "epoch": 0.0005426958214599267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7361,
      "step": 149536
    },
    {
      "epoch": 0.0005428119558107634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7383,
      "step": 149568
    },
    {
      "epoch": 0.0005429280901616001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7383,
      "step": 149600
    },
    {
      "epoch": 0.0005430442245124368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7434,
      "step": 149632
    },
    {
      "epoch": 0.0005431603588632735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7349,
      "step": 149664
    },
    {
      "epoch": 0.0005432764932141102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7284,
      "step": 149696
    },
    {
      "epoch": 0.0005433926275649469,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 149728
    },
    {
      "epoch": 0.0005435087619157836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 149760
    },
    {
      "epoch": 0.0005436248962666203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 149792
    },
    {
      "epoch": 0.0005437410306174571,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 149824
    },
    {
      "epoch": 0.0005438571649682937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 149856
    },
    {
      "epoch": 0.0005439732993191305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 149888
    },
    {
      "epoch": 0.0005440894336699671,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7386,
      "step": 149920
    },
    {
      "epoch": 0.0005442055680208039,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7397,
      "step": 149952
    },
    {
      "epoch": 0.0005443217023716405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 149984
    },
    {
      "epoch": 0.0005444378367224773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 150016
    },
    {
      "epoch": 0.0005445539710733139,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 150048
    },
    {
      "epoch": 0.0005446701054241507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 150080
    },
    {
      "epoch": 0.0005447862397749874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 150112
    },
    {
      "epoch": 0.0005449023741258241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 150144
    },
    {
      "epoch": 0.0005450185084766608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 150176
    },
    {
      "epoch": 0.0005451346428274975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7489,
      "step": 150208
    },
    {
      "epoch": 0.0005452507771783342,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 150240
    },
    {
      "epoch": 0.0005453669115291709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 150272
    },
    {
      "epoch": 0.0005454830458800076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 150304
    },
    {
      "epoch": 0.0005455991802308443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 150336
    },
    {
      "epoch": 0.000545715314581681,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.739,
      "step": 150368
    },
    {
      "epoch": 0.0005458314489325178,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 150400
    },
    {
      "epoch": 0.0005459475832833544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 150432
    },
    {
      "epoch": 0.0005460637176341912,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 150464
    },
    {
      "epoch": 0.0005461798519850278,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7462,
      "step": 150496
    },
    {
      "epoch": 0.0005462959863358646,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7674,
      "step": 150528
    },
    {
      "epoch": 0.0005464121206867012,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 150560
    },
    {
      "epoch": 0.000546528255037538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 150592
    },
    {
      "epoch": 0.0005466443893883746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 150624
    },
    {
      "epoch": 0.0005467605237392114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 150656
    },
    {
      "epoch": 0.0005468766580900481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 150688
    },
    {
      "epoch": 0.0005469927924408848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 150720
    },
    {
      "epoch": 0.0005471089267917215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 150752
    },
    {
      "epoch": 0.0005472250611425582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 150784
    },
    {
      "epoch": 0.0005473411954933949,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.744,
      "step": 150816
    },
    {
      "epoch": 0.0005474573298442316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 150848
    },
    {
      "epoch": 0.0005475734641950683,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7237,
      "step": 150880
    },
    {
      "epoch": 0.000547689598545905,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 150912
    },
    {
      "epoch": 0.0005478057328967417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 150944
    },
    {
      "epoch": 0.0005479218672475785,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 150976
    },
    {
      "epoch": 0.0005480380015984151,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 151008
    },
    {
      "epoch": 0.0005481541359492519,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 151040
    },
    {
      "epoch": 0.0005482702703000885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7013,
      "step": 151072
    },
    {
      "epoch": 0.0005483864046509253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 151104
    },
    {
      "epoch": 0.0005485025390017619,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7296,
      "step": 151136
    },
    {
      "epoch": 0.0005486186733525987,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 151168
    },
    {
      "epoch": 0.0005487348077034353,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 151200
    },
    {
      "epoch": 0.0005488509420542721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 151232
    },
    {
      "epoch": 0.0005489670764051088,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 151264
    },
    {
      "epoch": 0.0005490832107559455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.749,
      "step": 151296
    },
    {
      "epoch": 0.0005491993451067822,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7404,
      "step": 151328
    },
    {
      "epoch": 0.0005493154794576189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 151360
    },
    {
      "epoch": 0.0005494316138084556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7397,
      "step": 151392
    },
    {
      "epoch": 0.0005495477481592923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7358,
      "step": 151424
    },
    {
      "epoch": 0.000549663882510129,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.733,
      "step": 151456
    },
    {
      "epoch": 0.0005497800168609657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 151488
    },
    {
      "epoch": 0.0005498961512118024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 151520
    },
    {
      "epoch": 0.0005500122855626392,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.732,
      "step": 151552
    },
    {
      "epoch": 0.0005501284199134758,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 151584
    },
    {
      "epoch": 0.0005502445542643126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 151616
    },
    {
      "epoch": 0.0005503606886151492,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 151648
    },
    {
      "epoch": 0.000550476822965986,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 151680
    },
    {
      "epoch": 0.0005505929573168226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7403,
      "step": 151712
    },
    {
      "epoch": 0.0005507090916676594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 151744
    },
    {
      "epoch": 0.000550825226018496,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 151776
    },
    {
      "epoch": 0.0005509413603693328,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 151808
    },
    {
      "epoch": 0.0005510574947201695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 151840
    },
    {
      "epoch": 0.0005511736290710062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 151872
    },
    {
      "epoch": 0.0005512897634218429,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 151904
    },
    {
      "epoch": 0.0005514058977726796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 151936
    },
    {
      "epoch": 0.0005515220321235163,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 151968
    },
    {
      "epoch": 0.000551638166474353,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 152000
    },
    {
      "epoch": 0.0005517543008251897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 152032
    },
    {
      "epoch": 0.0005518704351760264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 152064
    },
    {
      "epoch": 0.0005519865695268631,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 152096
    },
    {
      "epoch": 0.0005521027038776999,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 152128
    },
    {
      "epoch": 0.0005522188382285365,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7421,
      "step": 152160
    },
    {
      "epoch": 0.0005523349725793733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 152192
    },
    {
      "epoch": 0.0005524511069302099,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7446,
      "step": 152224
    },
    {
      "epoch": 0.0005525672412810467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7365,
      "step": 152256
    },
    {
      "epoch": 0.0005526833756318833,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7638,
      "step": 152288
    },
    {
      "epoch": 0.0005527995099827201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7379,
      "step": 152320
    },
    {
      "epoch": 0.0005529156443335567,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 152352
    },
    {
      "epoch": 0.0005530317786843935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 152384
    },
    {
      "epoch": 0.0005531479130352302,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 152416
    },
    {
      "epoch": 0.0005532640473860669,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 152448
    },
    {
      "epoch": 0.0005533801817369036,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 152480
    },
    {
      "epoch": 0.0005534963160877403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 152512
    },
    {
      "epoch": 0.000553612450438577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7268,
      "step": 152544
    },
    {
      "epoch": 0.0005537285847894137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 152576
    },
    {
      "epoch": 0.0005538447191402504,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 152608
    },
    {
      "epoch": 0.0005539608534910871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 152640
    },
    {
      "epoch": 0.0005540769878419238,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 152672
    },
    {
      "epoch": 0.0005541931221927606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7076,
      "step": 152704
    },
    {
      "epoch": 0.0005543092565435972,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 152736
    },
    {
      "epoch": 0.000554425390894434,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 152768
    },
    {
      "epoch": 0.0005545415252452706,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 152800
    },
    {
      "epoch": 0.0005546576595961074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 152832
    },
    {
      "epoch": 0.000554773793946944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 152864
    },
    {
      "epoch": 0.0005548899282977808,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 152896
    },
    {
      "epoch": 0.0005550060626486174,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 152928
    },
    {
      "epoch": 0.0005551221969994542,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 152960
    },
    {
      "epoch": 0.000555238331350291,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 152992
    },
    {
      "epoch": 0.0005553544657011276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7295,
      "step": 153024
    },
    {
      "epoch": 0.0005554706000519644,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 153056
    },
    {
      "epoch": 0.000555586734402801,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7467,
      "step": 153088
    },
    {
      "epoch": 0.0005557028687536378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 153120
    },
    {
      "epoch": 0.0005558190031044744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7681,
      "step": 153152
    },
    {
      "epoch": 0.0005559351374553112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 153184
    },
    {
      "epoch": 0.0005560512718061478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 153216
    },
    {
      "epoch": 0.0005561674061569846,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 153248
    },
    {
      "epoch": 0.0005562835405078213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 153280
    },
    {
      "epoch": 0.000556399674858658,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 153312
    },
    {
      "epoch": 0.0005565158092094947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 153344
    },
    {
      "epoch": 0.0005566319435603314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 153376
    },
    {
      "epoch": 0.0005567480779111681,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 153408
    },
    {
      "epoch": 0.0005568642122620048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7347,
      "step": 153440
    },
    {
      "epoch": 0.0005569803466128415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 153472
    },
    {
      "epoch": 0.0005570964809636782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 153504
    },
    {
      "epoch": 0.0005572126153145149,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 153536
    },
    {
      "epoch": 0.0005573287496653517,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 153568
    },
    {
      "epoch": 0.0005574448840161883,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 153600
    },
    {
      "epoch": 0.0005575610183670251,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 153632
    },
    {
      "epoch": 0.0005576771527178617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 153664
    },
    {
      "epoch": 0.0005577932870686985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 153696
    },
    {
      "epoch": 0.0005579094214195351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 153728
    },
    {
      "epoch": 0.0005580255557703719,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7322,
      "step": 153760
    },
    {
      "epoch": 0.0005581416901212085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 153792
    },
    {
      "epoch": 0.0005582578244720453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 153824
    },
    {
      "epoch": 0.000558373958822882,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7343,
      "step": 153856
    },
    {
      "epoch": 0.0005584900931737187,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7405,
      "step": 153888
    },
    {
      "epoch": 0.0005586062275245554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7345,
      "step": 153920
    },
    {
      "epoch": 0.0005587223618753921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 153952
    },
    {
      "epoch": 0.0005588384962262288,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 153984
    },
    {
      "epoch": 0.0005589546305770655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7506,
      "step": 154016
    },
    {
      "epoch": 0.0005590707649279022,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7454,
      "step": 154048
    },
    {
      "epoch": 0.0005591868992787389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 154080
    },
    {
      "epoch": 0.0005593030336295756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 154112
    },
    {
      "epoch": 0.0005594191679804124,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 154144
    },
    {
      "epoch": 0.000559535302331249,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 154176
    },
    {
      "epoch": 0.0005596514366820858,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 154208
    },
    {
      "epoch": 0.0005597675710329224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 154240
    },
    {
      "epoch": 0.0005598837053837592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 154272
    },
    {
      "epoch": 0.0005599998397345958,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 154304
    },
    {
      "epoch": 0.0005601159740854326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7266,
      "step": 154336
    },
    {
      "epoch": 0.0005602321084362692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 154368
    },
    {
      "epoch": 0.000560348242787106,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 154400
    },
    {
      "epoch": 0.0005604643771379427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7076,
      "step": 154432
    },
    {
      "epoch": 0.0005605805114887794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 154464
    },
    {
      "epoch": 0.0005606966458396161,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 154496
    },
    {
      "epoch": 0.0005608127801904528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 154528
    },
    {
      "epoch": 0.0005609289145412895,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 154560
    },
    {
      "epoch": 0.0005610450488921262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 154592
    },
    {
      "epoch": 0.0005611611832429629,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7311,
      "step": 154624
    },
    {
      "epoch": 0.0005612773175937996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7427,
      "step": 154656
    },
    {
      "epoch": 0.0005613934519446363,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 154688
    },
    {
      "epoch": 0.0005615095862954731,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 154720
    },
    {
      "epoch": 0.0005616257206463097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 154752
    },
    {
      "epoch": 0.0005617418549971465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.746,
      "step": 154784
    },
    {
      "epoch": 0.0005618579893479831,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7352,
      "step": 154816
    },
    {
      "epoch": 0.0005619741236988199,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7315,
      "step": 154848
    },
    {
      "epoch": 0.0005620902580496565,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7453,
      "step": 154880
    },
    {
      "epoch": 0.0005622063924004933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7348,
      "step": 154912
    },
    {
      "epoch": 0.0005623225267513299,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 154944
    },
    {
      "epoch": 0.0005624386611021667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 154976
    },
    {
      "epoch": 0.0005625547954530034,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 155008
    },
    {
      "epoch": 0.0005626709298038401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 155040
    },
    {
      "epoch": 0.0005627870641546768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 155072
    },
    {
      "epoch": 0.0005629031985055135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 155104
    },
    {
      "epoch": 0.0005630193328563502,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7351,
      "step": 155136
    },
    {
      "epoch": 0.0005631354672071869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 155168
    },
    {
      "epoch": 0.0005632516015580236,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 155200
    },
    {
      "epoch": 0.0005633677359088603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7395,
      "step": 155232
    },
    {
      "epoch": 0.000563483870259697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 155264
    },
    {
      "epoch": 0.0005636000046105338,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 155296
    },
    {
      "epoch": 0.0005637161389613704,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 155328
    },
    {
      "epoch": 0.0005638322733122072,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 155360
    },
    {
      "epoch": 0.0005639484076630438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 155392
    },
    {
      "epoch": 0.0005640645420138806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 155424
    },
    {
      "epoch": 0.0005641806763647172,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 155456
    },
    {
      "epoch": 0.000564296810715554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7293,
      "step": 155488
    },
    {
      "epoch": 0.0005644129450663906,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7378,
      "step": 155520
    },
    {
      "epoch": 0.0005645290794172274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 155552
    },
    {
      "epoch": 0.0005646452137680641,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7396,
      "step": 155584
    },
    {
      "epoch": 0.0005647613481189008,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7248,
      "step": 155616
    },
    {
      "epoch": 0.0005648774824697375,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 155648
    },
    {
      "epoch": 0.0005649936168205742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7398,
      "step": 155680
    },
    {
      "epoch": 0.0005651097511714109,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7458,
      "step": 155712
    },
    {
      "epoch": 0.0005652258855222476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7469,
      "step": 155744
    },
    {
      "epoch": 0.0005653420198730843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 155776
    },
    {
      "epoch": 0.000565458154223921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 155808
    },
    {
      "epoch": 0.0005655742885747577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 155840
    },
    {
      "epoch": 0.0005656904229255945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 155872
    },
    {
      "epoch": 0.0005658065572764311,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 155904
    },
    {
      "epoch": 0.0005659226916272679,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 155936
    },
    {
      "epoch": 0.0005660388259781045,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 155968
    },
    {
      "epoch": 0.0005661549603289413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7329,
      "step": 156000
    },
    {
      "epoch": 0.0005662710946797779,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 156032
    },
    {
      "epoch": 0.0005663872290306147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 156064
    },
    {
      "epoch": 0.0005665033633814513,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.732,
      "step": 156096
    },
    {
      "epoch": 0.0005666194977322881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 156128
    },
    {
      "epoch": 0.0005667356320831248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 156160
    },
    {
      "epoch": 0.0005668517664339615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 156192
    },
    {
      "epoch": 0.0005669679007847982,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 156224
    },
    {
      "epoch": 0.0005670840351356349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 156256
    },
    {
      "epoch": 0.0005672001694864716,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 156288
    },
    {
      "epoch": 0.0005673163038373083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 156320
    },
    {
      "epoch": 0.000567432438188145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 156352
    },
    {
      "epoch": 0.0005675485725389817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7342,
      "step": 156384
    },
    {
      "epoch": 0.0005676647068898184,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7401,
      "step": 156416
    },
    {
      "epoch": 0.0005677808412406551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7377,
      "step": 156448
    },
    {
      "epoch": 0.0005678969755914918,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 156480
    },
    {
      "epoch": 0.0005680131099423286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7413,
      "step": 156512
    },
    {
      "epoch": 0.0005681292442931652,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 156544
    },
    {
      "epoch": 0.000568245378644002,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 156576
    },
    {
      "epoch": 0.0005683615129948386,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7498,
      "step": 156608
    },
    {
      "epoch": 0.0005684776473456754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7161,
      "step": 156640
    },
    {
      "epoch": 0.000568593781696512,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 156672
    },
    {
      "epoch": 0.0005687099160473488,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 156704
    },
    {
      "epoch": 0.0005688260503981854,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 156736
    },
    {
      "epoch": 0.0005689421847490222,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 156768
    },
    {
      "epoch": 0.000569058319099859,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7161,
      "step": 156800
    },
    {
      "epoch": 0.0005691744534506956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 156832
    },
    {
      "epoch": 0.0005692905878015323,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 156864
    },
    {
      "epoch": 0.000569406722152369,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 156896
    },
    {
      "epoch": 0.0005695228565032057,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 156928
    },
    {
      "epoch": 0.0005696389908540424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 156960
    },
    {
      "epoch": 0.0005697551252048791,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7301,
      "step": 156992
    },
    {
      "epoch": 0.0005698712595557158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 157024
    },
    {
      "epoch": 0.0005699873939065525,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 157056
    },
    {
      "epoch": 0.0005701035282573893,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 157088
    },
    {
      "epoch": 0.000570219662608226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 157120
    },
    {
      "epoch": 0.0005703357969590627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 157152
    },
    {
      "epoch": 0.0005704519313098993,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 157184
    },
    {
      "epoch": 0.0005705680656607361,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 157216
    },
    {
      "epoch": 0.0005706842000115727,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7322,
      "step": 157248
    },
    {
      "epoch": 0.0005708003343624095,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7494,
      "step": 157280
    },
    {
      "epoch": 0.0005709164687132461,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 157312
    },
    {
      "epoch": 0.0005710326030640829,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 157344
    },
    {
      "epoch": 0.0005711487374149197,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 157376
    },
    {
      "epoch": 0.0005712648717657563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7336,
      "step": 157408
    },
    {
      "epoch": 0.0005713810061165931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7563,
      "step": 157440
    },
    {
      "epoch": 0.0005714971404674297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 157472
    },
    {
      "epoch": 0.0005716132748182665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6943,
      "step": 157504
    },
    {
      "epoch": 0.0005717294091691031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 157536
    },
    {
      "epoch": 0.0005718455435199399,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7346,
      "step": 157568
    },
    {
      "epoch": 0.0005719616778707765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 157600
    },
    {
      "epoch": 0.0005720778122216133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 157632
    },
    {
      "epoch": 0.00057219394657245,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 157664
    },
    {
      "epoch": 0.0005723100809232867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 157696
    },
    {
      "epoch": 0.0005724262152741234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 157728
    },
    {
      "epoch": 0.00057254234962496,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 157760
    },
    {
      "epoch": 0.0005726584839757968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 157792
    },
    {
      "epoch": 0.0005727746183266335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 157824
    },
    {
      "epoch": 0.0005728907526774702,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 157856
    },
    {
      "epoch": 0.0005730068870283069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 157888
    },
    {
      "epoch": 0.0005731230213791436,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 157920
    },
    {
      "epoch": 0.0005732391557299804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 157952
    },
    {
      "epoch": 0.000573355290080817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 157984
    },
    {
      "epoch": 0.0005734714244316538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 158016
    },
    {
      "epoch": 0.0005735875587824904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 158048
    },
    {
      "epoch": 0.0005737036931333272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 158080
    },
    {
      "epoch": 0.0005738198274841638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 158112
    },
    {
      "epoch": 0.0005739359618350006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 158144
    },
    {
      "epoch": 0.0005740520961858372,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7519,
      "step": 158176
    },
    {
      "epoch": 0.000574168230536674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 158208
    },
    {
      "epoch": 0.0005742843648875107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 158240
    },
    {
      "epoch": 0.0005744004992383474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 158272
    },
    {
      "epoch": 0.0005745166335891841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7443,
      "step": 158304
    },
    {
      "epoch": 0.0005746327679400208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 158336
    },
    {
      "epoch": 0.0005747489022908575,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 158368
    },
    {
      "epoch": 0.0005748650366416942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 158400
    },
    {
      "epoch": 0.0005749811709925309,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7268,
      "step": 158432
    },
    {
      "epoch": 0.0005750973053433676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 158464
    },
    {
      "epoch": 0.0005752134396942043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 158496
    },
    {
      "epoch": 0.0005753295740450411,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 158528
    },
    {
      "epoch": 0.0005754457083958777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 158560
    },
    {
      "epoch": 0.0005755618427467145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 158592
    },
    {
      "epoch": 0.0005756779770975511,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 158624
    },
    {
      "epoch": 0.0005757941114483879,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 158656
    },
    {
      "epoch": 0.0005759102457992245,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 158688
    },
    {
      "epoch": 0.0005760263801500613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 158720
    },
    {
      "epoch": 0.0005761425145008979,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 158752
    },
    {
      "epoch": 0.0005762586488517347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7385,
      "step": 158784
    },
    {
      "epoch": 0.0005763747832025714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 158816
    },
    {
      "epoch": 0.0005764909175534081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 158848
    },
    {
      "epoch": 0.0005766070519042448,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6973,
      "step": 158880
    },
    {
      "epoch": 0.0005767231862550815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 158912
    },
    {
      "epoch": 0.0005768393206059182,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 158944
    },
    {
      "epoch": 0.0005769554549567549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.738,
      "step": 158976
    },
    {
      "epoch": 0.0005770715893075916,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7326,
      "step": 159008
    },
    {
      "epoch": 0.0005771877236584283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7331,
      "step": 159040
    },
    {
      "epoch": 0.000577303858009265,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 159072
    },
    {
      "epoch": 0.0005774199923601018,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7424,
      "step": 159104
    },
    {
      "epoch": 0.0005775361267109384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 159136
    },
    {
      "epoch": 0.0005776522610617752,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7367,
      "step": 159168
    },
    {
      "epoch": 0.0005777683954126118,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 159200
    },
    {
      "epoch": 0.0005778845297634486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 159232
    },
    {
      "epoch": 0.0005780006641142852,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7284,
      "step": 159264
    },
    {
      "epoch": 0.000578116798465122,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 159296
    },
    {
      "epoch": 0.0005782329328159586,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 159328
    },
    {
      "epoch": 0.0005783490671667954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.737,
      "step": 159360
    },
    {
      "epoch": 0.0005784652015176321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 159392
    },
    {
      "epoch": 0.0005785813358684688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 159424
    },
    {
      "epoch": 0.0005786974702193055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 159456
    },
    {
      "epoch": 0.0005788136045701422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 159488
    },
    {
      "epoch": 0.0005789297389209789,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 159520
    },
    {
      "epoch": 0.0005790458732718156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7102,
      "step": 159552
    },
    {
      "epoch": 0.0005791620076226523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 159584
    },
    {
      "epoch": 0.000579278141973489,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 159616
    },
    {
      "epoch": 0.0005793942763243257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 159648
    },
    {
      "epoch": 0.0005795104106751625,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 159680
    },
    {
      "epoch": 0.0005796265450259991,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 159712
    },
    {
      "epoch": 0.0005797426793768359,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 159744
    },
    {
      "epoch": 0.0005798588137276725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 159776
    },
    {
      "epoch": 0.0005799749480785093,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7389,
      "step": 159808
    },
    {
      "epoch": 0.0005800910824293459,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 159840
    },
    {
      "epoch": 0.0005802072167801827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 159872
    },
    {
      "epoch": 0.0005803233511310193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 159904
    },
    {
      "epoch": 0.0005804394854818561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7443,
      "step": 159936
    },
    {
      "epoch": 0.0005805556198326928,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 159968
    },
    {
      "epoch": 0.0005806717541835295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7337,
      "step": 160000
    },
    {
      "epoch": 0.0005807878885343662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7585,
      "step": 160032
    },
    {
      "epoch": 0.0005809040228852029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 160064
    },
    {
      "epoch": 0.0005810201572360396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 160096
    },
    {
      "epoch": 0.0005811362915868763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 160128
    },
    {
      "epoch": 0.000581252425937713,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 160160
    },
    {
      "epoch": 0.0005813685602885497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 160192
    },
    {
      "epoch": 0.0005814846946393864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 160224
    },
    {
      "epoch": 0.0005816008289902232,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6994,
      "step": 160256
    },
    {
      "epoch": 0.0005817169633410598,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 160288
    },
    {
      "epoch": 0.0005818330976918966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 160320
    },
    {
      "epoch": 0.0005819492320427332,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 160352
    },
    {
      "epoch": 0.00058206536639357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7288,
      "step": 160384
    },
    {
      "epoch": 0.0005821815007444066,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 160416
    },
    {
      "epoch": 0.0005822976350952434,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 160448
    },
    {
      "epoch": 0.00058241376944608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 160480
    },
    {
      "epoch": 0.0005825299037969168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 160512
    },
    {
      "epoch": 0.0005826460381477535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 160544
    },
    {
      "epoch": 0.0005827621724985902,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 160576
    },
    {
      "epoch": 0.0005828783068494269,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 160608
    },
    {
      "epoch": 0.0005829944412002636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7161,
      "step": 160640
    },
    {
      "epoch": 0.0005831105755511003,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 160672
    },
    {
      "epoch": 0.000583226709901937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 160704
    },
    {
      "epoch": 0.0005833428442527737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.743,
      "step": 160736
    },
    {
      "epoch": 0.0005834589786036104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 160768
    },
    {
      "epoch": 0.0005835751129544471,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7621,
      "step": 160800
    },
    {
      "epoch": 0.0005836912473052839,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 160832
    },
    {
      "epoch": 0.0005838073816561205,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 160864
    },
    {
      "epoch": 0.0005839235160069573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7315,
      "step": 160896
    },
    {
      "epoch": 0.0005840396503577939,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 160928
    },
    {
      "epoch": 0.0005841557847086307,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 160960
    },
    {
      "epoch": 0.0005842719190594673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 160992
    },
    {
      "epoch": 0.0005843880534103041,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 161024
    },
    {
      "epoch": 0.0005845041877611407,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 161056
    },
    {
      "epoch": 0.0005846203221119775,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 161088
    },
    {
      "epoch": 0.0005847364564628142,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.745,
      "step": 161120
    },
    {
      "epoch": 0.0005848525908136509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 161152
    },
    {
      "epoch": 0.0005849687251644876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 161184
    },
    {
      "epoch": 0.0005850848595153243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 161216
    },
    {
      "epoch": 0.000585200993866161,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 161248
    },
    {
      "epoch": 0.0005853171282169977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6996,
      "step": 161280
    },
    {
      "epoch": 0.0005854332625678344,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 161312
    },
    {
      "epoch": 0.0005855493969186711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 161344
    },
    {
      "epoch": 0.0005856655312695078,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 161376
    },
    {
      "epoch": 0.0005857816656203446,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7388,
      "step": 161408
    },
    {
      "epoch": 0.0005858977999711812,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 161440
    },
    {
      "epoch": 0.000586013934322018,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 161472
    },
    {
      "epoch": 0.0005861300686728546,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 161504
    },
    {
      "epoch": 0.0005862462030236914,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 161536
    },
    {
      "epoch": 0.000586362337374528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 161568
    },
    {
      "epoch": 0.0005864784717253648,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 161600
    },
    {
      "epoch": 0.0005865946060762014,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 161632
    },
    {
      "epoch": 0.0005867107404270382,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 161664
    },
    {
      "epoch": 0.000586826874777875,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7407,
      "step": 161696
    },
    {
      "epoch": 0.0005869430091287116,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7727,
      "step": 161728
    },
    {
      "epoch": 0.0005870591434795484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 161760
    },
    {
      "epoch": 0.000587175277830385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.69,
      "step": 161792
    },
    {
      "epoch": 0.0005872914121812218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6926,
      "step": 161824
    },
    {
      "epoch": 0.0005874075465320584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 161856
    },
    {
      "epoch": 0.0005875236808828952,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 161888
    },
    {
      "epoch": 0.0005876398152337318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 161920
    },
    {
      "epoch": 0.0005877559495845686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 161952
    },
    {
      "epoch": 0.0005878720839354053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 161984
    },
    {
      "epoch": 0.000587988218286242,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 162016
    },
    {
      "epoch": 0.0005881043526370787,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 162048
    },
    {
      "epoch": 0.0005882204869879154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 162080
    },
    {
      "epoch": 0.0005883366213387521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 162112
    },
    {
      "epoch": 0.0005884527556895888,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 162144
    },
    {
      "epoch": 0.0005885688900404255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 162176
    },
    {
      "epoch": 0.0005886850243912622,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 162208
    },
    {
      "epoch": 0.0005888011587420989,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6947,
      "step": 162240
    },
    {
      "epoch": 0.0005889172930929357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 162272
    },
    {
      "epoch": 0.0005890334274437723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 162304
    },
    {
      "epoch": 0.0005891495617946091,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 162336
    },
    {
      "epoch": 0.0005892656961454457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 162368
    },
    {
      "epoch": 0.0005893818304962825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 162400
    },
    {
      "epoch": 0.0005894979648471191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 162432
    },
    {
      "epoch": 0.0005896140991979559,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 162464
    },
    {
      "epoch": 0.0005897302335487925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 162496
    },
    {
      "epoch": 0.0005898463678996293,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7366,
      "step": 162528
    },
    {
      "epoch": 0.000589962502250466,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 162560
    },
    {
      "epoch": 0.0005900786366013027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7457,
      "step": 162592
    },
    {
      "epoch": 0.0005901947709521394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7277,
      "step": 162624
    },
    {
      "epoch": 0.0005903109053029761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6927,
      "step": 162656
    },
    {
      "epoch": 0.0005904270396538128,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 162688
    },
    {
      "epoch": 0.0005905431740046495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 162720
    },
    {
      "epoch": 0.0005906593083554862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 162752
    },
    {
      "epoch": 0.0005907754427063229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 162784
    },
    {
      "epoch": 0.0005908915770571596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 162816
    },
    {
      "epoch": 0.0005910077114079964,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7363,
      "step": 162848
    },
    {
      "epoch": 0.000591123845758833,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 162880
    },
    {
      "epoch": 0.0005912399801096698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 162912
    },
    {
      "epoch": 0.0005913561144605064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 162944
    },
    {
      "epoch": 0.0005914722488113432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 162976
    },
    {
      "epoch": 0.0005915883831621798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 163008
    },
    {
      "epoch": 0.0005917045175130166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 163040
    },
    {
      "epoch": 0.0005918206518638532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7361,
      "step": 163072
    },
    {
      "epoch": 0.00059193678621469,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 163104
    },
    {
      "epoch": 0.0005920529205655267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 163136
    },
    {
      "epoch": 0.0005921690549163634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7161,
      "step": 163168
    },
    {
      "epoch": 0.0005922851892672001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 163200
    },
    {
      "epoch": 0.0005924013236180368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7013,
      "step": 163232
    },
    {
      "epoch": 0.0005925174579688735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 163264
    },
    {
      "epoch": 0.0005926335923197102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 163296
    },
    {
      "epoch": 0.0005927497266705469,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 163328
    },
    {
      "epoch": 0.0005928658610213836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 163360
    },
    {
      "epoch": 0.0005929819953722203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7375,
      "step": 163392
    },
    {
      "epoch": 0.0005930981297230571,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 163424
    },
    {
      "epoch": 0.0005932142640738937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7483,
      "step": 163456
    },
    {
      "epoch": 0.0005933303984247305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7514,
      "step": 163488
    },
    {
      "epoch": 0.0005934465327755671,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 163520
    },
    {
      "epoch": 0.0005935626671264039,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 163552
    },
    {
      "epoch": 0.0005936788014772405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 163584
    },
    {
      "epoch": 0.0005937949358280773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6897,
      "step": 163616
    },
    {
      "epoch": 0.0005939110701789139,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 163648
    },
    {
      "epoch": 0.0005940272045297507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 163680
    },
    {
      "epoch": 0.0005941433388805874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 163712
    },
    {
      "epoch": 0.0005942594732314241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7482,
      "step": 163744
    },
    {
      "epoch": 0.0005943756075822608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 163776
    },
    {
      "epoch": 0.0005944917419330975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 163808
    },
    {
      "epoch": 0.0005946078762839342,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 163840
    },
    {
      "epoch": 0.0005947240106347709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 163872
    },
    {
      "epoch": 0.0005948401449856076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 163904
    },
    {
      "epoch": 0.0005949562793364443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 163936
    },
    {
      "epoch": 0.000595072413687281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 163968
    },
    {
      "epoch": 0.0005951885480381178,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6956,
      "step": 164000
    },
    {
      "epoch": 0.0005953046823889544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 164032
    },
    {
      "epoch": 0.0005954208167397912,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 164064
    },
    {
      "epoch": 0.0005955369510906278,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 164096
    },
    {
      "epoch": 0.0005956530854414646,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 164128
    },
    {
      "epoch": 0.0005957692197923012,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 164160
    },
    {
      "epoch": 0.000595885354143138,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 164192
    },
    {
      "epoch": 0.0005960014884939746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 164224
    },
    {
      "epoch": 0.0005961176228448114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7368,
      "step": 164256
    },
    {
      "epoch": 0.0005962337571956481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 164288
    },
    {
      "epoch": 0.0005963498915464848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7396,
      "step": 164320
    },
    {
      "epoch": 0.0005964660258973215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7371,
      "step": 164352
    },
    {
      "epoch": 0.0005965821602481582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 164384
    },
    {
      "epoch": 0.0005966982945989949,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 164416
    },
    {
      "epoch": 0.0005968144289498316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 164448
    },
    {
      "epoch": 0.0005969305633006683,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 164480
    },
    {
      "epoch": 0.000597046697651505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 164512
    },
    {
      "epoch": 0.0005971628320023417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 164544
    },
    {
      "epoch": 0.0005972789663531785,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 164576
    },
    {
      "epoch": 0.0005973951007040151,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 164608
    },
    {
      "epoch": 0.0005975112350548519,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 164640
    },
    {
      "epoch": 0.0005976273694056885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 164672
    },
    {
      "epoch": 0.0005977435037565253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 164704
    },
    {
      "epoch": 0.0005978596381073619,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6982,
      "step": 164736
    },
    {
      "epoch": 0.0005979757724581987,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 164768
    },
    {
      "epoch": 0.0005980919068090353,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7268,
      "step": 164800
    },
    {
      "epoch": 0.0005982080411598721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 164832
    },
    {
      "epoch": 0.0005983241755107088,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 164864
    },
    {
      "epoch": 0.0005984403098615455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 164896
    },
    {
      "epoch": 0.0005985564442123822,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7237,
      "step": 164928
    },
    {
      "epoch": 0.0005986725785632189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 164960
    },
    {
      "epoch": 0.0005987887129140556,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 164992
    },
    {
      "epoch": 0.0005989048472648923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 165024
    },
    {
      "epoch": 0.000599020981615729,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 165056
    },
    {
      "epoch": 0.0005991371159665657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 165088
    },
    {
      "epoch": 0.0005992532503174024,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 165120
    },
    {
      "epoch": 0.0005993693846682392,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7326,
      "step": 165152
    },
    {
      "epoch": 0.0005994855190190758,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7329,
      "step": 165184
    },
    {
      "epoch": 0.0005996016533699126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 165216
    },
    {
      "epoch": 0.0005997177877207492,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7378,
      "step": 165248
    },
    {
      "epoch": 0.000599833922071586,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 165280
    },
    {
      "epoch": 0.0005999500564224226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6857,
      "step": 165312
    },
    {
      "epoch": 0.0006000661907732594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6924,
      "step": 165344
    },
    {
      "epoch": 0.000600182325124096,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 165376
    },
    {
      "epoch": 0.0006002984594749328,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 165408
    },
    {
      "epoch": 0.0006004145938257696,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 165440
    },
    {
      "epoch": 0.0006005307281766062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 165472
    },
    {
      "epoch": 0.000600646862527443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 165504
    },
    {
      "epoch": 0.0006007629968782796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 165536
    },
    {
      "epoch": 0.0006008791312291164,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 165568
    },
    {
      "epoch": 0.000600995265579953,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 165600
    },
    {
      "epoch": 0.0006011113999307898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 165632
    },
    {
      "epoch": 0.0006012275342816264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 165664
    },
    {
      "epoch": 0.0006013436686324632,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 165696
    },
    {
      "epoch": 0.0006014598029832999,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 165728
    },
    {
      "epoch": 0.0006015759373341365,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6963,
      "step": 165760
    },
    {
      "epoch": 0.0006016920716849733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 165792
    },
    {
      "epoch": 0.00060180820603581,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7435,
      "step": 165824
    },
    {
      "epoch": 0.0006019243403866467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 165856
    },
    {
      "epoch": 0.0006020404747374833,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 165888
    },
    {
      "epoch": 0.0006021566090883201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 165920
    },
    {
      "epoch": 0.0006022727434391567,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 165952
    },
    {
      "epoch": 0.0006023888777899935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 165984
    },
    {
      "epoch": 0.0006025050121408303,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 166016
    },
    {
      "epoch": 0.0006026211464916669,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 166048
    },
    {
      "epoch": 0.0006027372808425037,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 166080
    },
    {
      "epoch": 0.0006028534151933403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7419,
      "step": 166112
    },
    {
      "epoch": 0.0006029695495441771,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 166144
    },
    {
      "epoch": 0.0006030856838950137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6936,
      "step": 166176
    },
    {
      "epoch": 0.0006032018182458505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 166208
    },
    {
      "epoch": 0.0006033179525966871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 166240
    },
    {
      "epoch": 0.0006034340869475239,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 166272
    },
    {
      "epoch": 0.0006035502212983606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 166304
    },
    {
      "epoch": 0.0006036663556491973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 166336
    },
    {
      "epoch": 0.000603782490000034,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 166368
    },
    {
      "epoch": 0.0006038986243508707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 166400
    },
    {
      "epoch": 0.0006040147587017074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 166432
    },
    {
      "epoch": 0.0006041308930525441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 166464
    },
    {
      "epoch": 0.0006042470274033808,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 166496
    },
    {
      "epoch": 0.0006043631617542175,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 166528
    },
    {
      "epoch": 0.0006044792961050542,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 166560
    },
    {
      "epoch": 0.000604595430455891,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 166592
    },
    {
      "epoch": 0.0006047115648067276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 166624
    },
    {
      "epoch": 0.0006048276991575644,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 166656
    },
    {
      "epoch": 0.000604943833508401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 166688
    },
    {
      "epoch": 0.0006050599678592378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 166720
    },
    {
      "epoch": 0.0006051761022100744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 166752
    },
    {
      "epoch": 0.0006052922365609112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 166784
    },
    {
      "epoch": 0.0006054083709117478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 166816
    },
    {
      "epoch": 0.0006055245052625846,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7345,
      "step": 166848
    },
    {
      "epoch": 0.0006056406396134213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 166880
    },
    {
      "epoch": 0.000605756773964258,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7345,
      "step": 166912
    },
    {
      "epoch": 0.0006058729083150947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6982,
      "step": 166944
    },
    {
      "epoch": 0.0006059890426659314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 166976
    },
    {
      "epoch": 0.0006061051770167681,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 167008
    },
    {
      "epoch": 0.0006062213113676048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6947,
      "step": 167040
    },
    {
      "epoch": 0.0006063374457184415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6947,
      "step": 167072
    },
    {
      "epoch": 0.0006064535800692782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 167104
    },
    {
      "epoch": 0.0006065697144201149,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 167136
    },
    {
      "epoch": 0.0006066858487709516,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 167168
    },
    {
      "epoch": 0.0006068019831217883,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 167200
    },
    {
      "epoch": 0.0006069181174726251,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 167232
    },
    {
      "epoch": 0.0006070342518234617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7308,
      "step": 167264
    },
    {
      "epoch": 0.0006071503861742985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 167296
    },
    {
      "epoch": 0.0006072665205251351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 167328
    },
    {
      "epoch": 0.0006073826548759719,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 167360
    },
    {
      "epoch": 0.0006074987892268085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 167392
    },
    {
      "epoch": 0.0006076149235776453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 167424
    },
    {
      "epoch": 0.0006077310579284819,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7349,
      "step": 167456
    },
    {
      "epoch": 0.0006078471922793187,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 167488
    },
    {
      "epoch": 0.0006079633266301554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 167520
    },
    {
      "epoch": 0.0006080794609809921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 167552
    },
    {
      "epoch": 0.0006081955953318288,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7371,
      "step": 167584
    },
    {
      "epoch": 0.0006083117296826655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 167616
    },
    {
      "epoch": 0.0006084278640335022,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 167648
    },
    {
      "epoch": 0.0006085439983843389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 167680
    },
    {
      "epoch": 0.0006086601327351756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 167712
    },
    {
      "epoch": 0.0006087762670860123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 167744
    },
    {
      "epoch": 0.000608892401436849,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 167776
    },
    {
      "epoch": 0.0006090085357876858,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 167808
    },
    {
      "epoch": 0.0006091246701385224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 167840
    },
    {
      "epoch": 0.0006092408044893592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7413,
      "step": 167872
    },
    {
      "epoch": 0.0006093569388401958,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6946,
      "step": 167904
    },
    {
      "epoch": 0.0006094730731910326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 167936
    },
    {
      "epoch": 0.0006095892075418692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 167968
    },
    {
      "epoch": 0.000609705341892706,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 168000
    },
    {
      "epoch": 0.0006098214762435426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 168032
    },
    {
      "epoch": 0.0006099376105943794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 168064
    },
    {
      "epoch": 0.0006100537449452161,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 168096
    },
    {
      "epoch": 0.0006101698792960528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 168128
    },
    {
      "epoch": 0.0006102860136468895,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 168160
    },
    {
      "epoch": 0.0006104021479977262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7348,
      "step": 168192
    },
    {
      "epoch": 0.0006105182823485629,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 168224
    },
    {
      "epoch": 0.0006106344166993996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 168256
    },
    {
      "epoch": 0.0006107505510502363,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 168288
    },
    {
      "epoch": 0.000610866685401073,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7352,
      "step": 168320
    },
    {
      "epoch": 0.0006109828197519097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 168352
    },
    {
      "epoch": 0.0006110989541027465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 168384
    },
    {
      "epoch": 0.0006112150884535831,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 168416
    },
    {
      "epoch": 0.0006113312228044199,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.742,
      "step": 168448
    },
    {
      "epoch": 0.0006114473571552565,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 168480
    },
    {
      "epoch": 0.0006115634915060933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 168512
    },
    {
      "epoch": 0.0006116796258569299,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 168544
    },
    {
      "epoch": 0.0006117957602077667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 168576
    },
    {
      "epoch": 0.0006119118945586033,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7483,
      "step": 168608
    },
    {
      "epoch": 0.0006120280289094401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7297,
      "step": 168640
    },
    {
      "epoch": 0.0006121441632602768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 168672
    },
    {
      "epoch": 0.0006122602976111135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 168704
    },
    {
      "epoch": 0.0006123764319619502,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 168736
    },
    {
      "epoch": 0.0006124925663127869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 168768
    },
    {
      "epoch": 0.0006126087006636236,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 168800
    },
    {
      "epoch": 0.0006127248350144603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6972,
      "step": 168832
    },
    {
      "epoch": 0.000612840969365297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 168864
    },
    {
      "epoch": 0.0006129571037161337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 168896
    },
    {
      "epoch": 0.0006130732380669704,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6961,
      "step": 168928
    },
    {
      "epoch": 0.0006131893724178072,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 168960
    },
    {
      "epoch": 0.0006133055067686438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7302,
      "step": 168992
    },
    {
      "epoch": 0.0006134216411194806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 169024
    },
    {
      "epoch": 0.0006135377754703172,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 169056
    },
    {
      "epoch": 0.000613653909821154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6905,
      "step": 169088
    },
    {
      "epoch": 0.0006137700441719906,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6976,
      "step": 169120
    },
    {
      "epoch": 0.0006138861785228274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 169152
    },
    {
      "epoch": 0.000614002312873664,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 169184
    },
    {
      "epoch": 0.0006141184472245008,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7447,
      "step": 169216
    },
    {
      "epoch": 0.0006142345815753375,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 169248
    },
    {
      "epoch": 0.0006143507159261742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 169280
    },
    {
      "epoch": 0.0006144668502770109,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 169312
    },
    {
      "epoch": 0.0006145829846278476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7355,
      "step": 169344
    },
    {
      "epoch": 0.0006146991189786843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 169376
    },
    {
      "epoch": 0.000614815253329521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 169408
    },
    {
      "epoch": 0.0006149313876803577,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 169440
    },
    {
      "epoch": 0.0006150475220311944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7272,
      "step": 169472
    },
    {
      "epoch": 0.0006151636563820311,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 169504
    },
    {
      "epoch": 0.0006152797907328679,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 169536
    },
    {
      "epoch": 0.0006153959250837045,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 169568
    },
    {
      "epoch": 0.0006155120594345413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 169600
    },
    {
      "epoch": 0.0006156281937853779,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 169632
    },
    {
      "epoch": 0.0006157443281362147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 169664
    },
    {
      "epoch": 0.0006158604624870513,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6905,
      "step": 169696
    },
    {
      "epoch": 0.0006159765968378881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 169728
    },
    {
      "epoch": 0.0006160927311887247,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6973,
      "step": 169760
    },
    {
      "epoch": 0.0006162088655395615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 169792
    },
    {
      "epoch": 0.0006163249998903983,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6994,
      "step": 169824
    },
    {
      "epoch": 0.0006164411342412349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 169856
    },
    {
      "epoch": 0.0006165572685920717,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 169888
    },
    {
      "epoch": 0.0006166734029429083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 169920
    },
    {
      "epoch": 0.000616789537293745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 169952
    },
    {
      "epoch": 0.0006169056716445817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 169984
    },
    {
      "epoch": 0.0006170218059954185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 170016
    },
    {
      "epoch": 0.0006171379403462551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 170048
    },
    {
      "epoch": 0.0006172540746970919,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 170080
    },
    {
      "epoch": 0.0006173702090479286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 170112
    },
    {
      "epoch": 0.0006174863433987653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 170144
    },
    {
      "epoch": 0.000617602477749602,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 170176
    },
    {
      "epoch": 0.0006177186121004387,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 170208
    },
    {
      "epoch": 0.0006178347464512754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7369,
      "step": 170240
    },
    {
      "epoch": 0.000617950880802112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 170272
    },
    {
      "epoch": 0.0006180670151529488,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 170304
    },
    {
      "epoch": 0.0006181831495037855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 170336
    },
    {
      "epoch": 0.0006182992838546222,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 170368
    },
    {
      "epoch": 0.000618415418205459,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 170400
    },
    {
      "epoch": 0.0006185315525562956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 170432
    },
    {
      "epoch": 0.0006186476869071324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 170464
    },
    {
      "epoch": 0.000618763821257969,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7351,
      "step": 170496
    },
    {
      "epoch": 0.0006188799556088058,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 170528
    },
    {
      "epoch": 0.0006189960899596424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 170560
    },
    {
      "epoch": 0.0006191122243104792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 170592
    },
    {
      "epoch": 0.0006192283586613158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 170624
    },
    {
      "epoch": 0.0006193444930121526,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 170656
    },
    {
      "epoch": 0.0006194606273629893,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 170688
    },
    {
      "epoch": 0.000619576761713826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 170720
    },
    {
      "epoch": 0.0006196928960646627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 170752
    },
    {
      "epoch": 0.0006198090304154994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 170784
    },
    {
      "epoch": 0.0006199251647663361,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 170816
    },
    {
      "epoch": 0.0006200412991171728,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 170848
    },
    {
      "epoch": 0.0006201574334680095,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7023,
      "step": 170880
    },
    {
      "epoch": 0.0006202735678188462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 170912
    },
    {
      "epoch": 0.0006203897021696829,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7302,
      "step": 170944
    },
    {
      "epoch": 0.0006205058365205197,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7365,
      "step": 170976
    },
    {
      "epoch": 0.0006206219708713563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 171008
    },
    {
      "epoch": 0.0006207381052221931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 171040
    },
    {
      "epoch": 0.0006208542395730297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 171072
    },
    {
      "epoch": 0.0006209703739238665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7353,
      "step": 171104
    },
    {
      "epoch": 0.0006210865082747031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 171136
    },
    {
      "epoch": 0.0006212026426255399,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 171168
    },
    {
      "epoch": 0.0006213187769763765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 171200
    },
    {
      "epoch": 0.0006214349113272133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 171232
    },
    {
      "epoch": 0.00062155104567805,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 171264
    },
    {
      "epoch": 0.0006216671800288867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 171296
    },
    {
      "epoch": 0.0006217833143797234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 171328
    },
    {
      "epoch": 0.0006218994487305601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7355,
      "step": 171360
    },
    {
      "epoch": 0.0006220155830813968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 171392
    },
    {
      "epoch": 0.0006221317174322335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 171424
    },
    {
      "epoch": 0.0006222478517830702,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 171456
    },
    {
      "epoch": 0.0006223639861339069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 171488
    },
    {
      "epoch": 0.0006224801204847436,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 171520
    },
    {
      "epoch": 0.0006225962548355804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 171552
    },
    {
      "epoch": 0.000622712389186417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 171584
    },
    {
      "epoch": 0.0006228285235372538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 171616
    },
    {
      "epoch": 0.0006229446578880904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 171648
    },
    {
      "epoch": 0.0006230607922389272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 171680
    },
    {
      "epoch": 0.0006231769265897638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 171712
    },
    {
      "epoch": 0.0006232930609406006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6932,
      "step": 171744
    },
    {
      "epoch": 0.0006234091952914372,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 171776
    },
    {
      "epoch": 0.000623525329642274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 171808
    },
    {
      "epoch": 0.0006236414639931107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7397,
      "step": 171840
    },
    {
      "epoch": 0.0006237575983439474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 171872
    },
    {
      "epoch": 0.0006238737326947841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7296,
      "step": 171904
    },
    {
      "epoch": 0.0006239898670456208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 171936
    },
    {
      "epoch": 0.0006241060013964575,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.73,
      "step": 171968
    },
    {
      "epoch": 0.0006242221357472942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 172000
    },
    {
      "epoch": 0.0006243382700981309,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 172032
    },
    {
      "epoch": 0.0006244544044489676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 172064
    },
    {
      "epoch": 0.0006245705387998043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.692,
      "step": 172096
    },
    {
      "epoch": 0.0006246866731506411,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 172128
    },
    {
      "epoch": 0.0006248028075014777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 172160
    },
    {
      "epoch": 0.0006249189418523145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 172192
    },
    {
      "epoch": 0.0006250350762031511,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 172224
    },
    {
      "epoch": 0.0006251512105539879,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7301,
      "step": 172256
    },
    {
      "epoch": 0.0006252673449048245,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7353,
      "step": 172288
    },
    {
      "epoch": 0.0006253834792556613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 172320
    },
    {
      "epoch": 0.0006254996136064979,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 172352
    },
    {
      "epoch": 0.0006256157479573347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 172384
    },
    {
      "epoch": 0.0006257318823081714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 172416
    },
    {
      "epoch": 0.0006258480166590081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 172448
    },
    {
      "epoch": 0.0006259641510098448,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 172480
    },
    {
      "epoch": 0.0006260802853606815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 172512
    },
    {
      "epoch": 0.0006261964197115182,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 172544
    },
    {
      "epoch": 0.0006263125540623549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 172576
    },
    {
      "epoch": 0.0006264286884131916,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 172608
    },
    {
      "epoch": 0.0006265448227640283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 172640
    },
    {
      "epoch": 0.000626660957114865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 172672
    },
    {
      "epoch": 0.0006267770914657018,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7425,
      "step": 172704
    },
    {
      "epoch": 0.0006268932258165384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7428,
      "step": 172736
    },
    {
      "epoch": 0.0006270093601673752,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 172768
    },
    {
      "epoch": 0.0006271254945182118,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 172800
    },
    {
      "epoch": 0.0006272416288690486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 172832
    },
    {
      "epoch": 0.0006273577632198852,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 172864
    },
    {
      "epoch": 0.000627473897570722,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 172896
    },
    {
      "epoch": 0.0006275900319215586,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 172928
    },
    {
      "epoch": 0.0006277061662723954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 172960
    },
    {
      "epoch": 0.0006278223006232321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6997,
      "step": 172992
    },
    {
      "epoch": 0.0006279384349740688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 173024
    },
    {
      "epoch": 0.0006280545693249055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 173056
    },
    {
      "epoch": 0.0006281707036757422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 173088
    },
    {
      "epoch": 0.0006282868380265789,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 173120
    },
    {
      "epoch": 0.0006284029723774156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 173152
    },
    {
      "epoch": 0.0006285191067282523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6976,
      "step": 173184
    },
    {
      "epoch": 0.000628635241079089,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 173216
    },
    {
      "epoch": 0.0006287513754299257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 173248
    },
    {
      "epoch": 0.0006288675097807625,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 173280
    },
    {
      "epoch": 0.0006289836441315991,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 173312
    },
    {
      "epoch": 0.0006290997784824359,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 173344
    },
    {
      "epoch": 0.0006292159128332725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 173376
    },
    {
      "epoch": 0.0006293320471841093,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 173408
    },
    {
      "epoch": 0.0006294481815349459,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 173440
    },
    {
      "epoch": 0.0006295643158857827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 173472
    },
    {
      "epoch": 0.0006296804502366193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 173504
    },
    {
      "epoch": 0.0006297965845874561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 173536
    },
    {
      "epoch": 0.0006299127189382928,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7375,
      "step": 173568
    },
    {
      "epoch": 0.0006300288532891295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7334,
      "step": 173600
    },
    {
      "epoch": 0.0006301449876399662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 173632
    },
    {
      "epoch": 0.0006302611219908029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 173664
    },
    {
      "epoch": 0.0006303772563416396,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7352,
      "step": 173696
    },
    {
      "epoch": 0.0006304933906924763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 173728
    },
    {
      "epoch": 0.000630609525043313,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7412,
      "step": 173760
    },
    {
      "epoch": 0.0006307256593941497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 173792
    },
    {
      "epoch": 0.0006308417937449864,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6879,
      "step": 173824
    },
    {
      "epoch": 0.0006309579280958232,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 173856
    },
    {
      "epoch": 0.0006310740624466598,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 173888
    },
    {
      "epoch": 0.0006311901967974966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 173920
    },
    {
      "epoch": 0.0006313063311483332,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 173952
    },
    {
      "epoch": 0.00063142246549917,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 173984
    },
    {
      "epoch": 0.0006315385998500066,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 174016
    },
    {
      "epoch": 0.0006316547342008434,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 174048
    },
    {
      "epoch": 0.00063177086855168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 174080
    },
    {
      "epoch": 0.0006318870029025168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 174112
    },
    {
      "epoch": 0.0006320031372533536,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 174144
    },
    {
      "epoch": 0.0006321192716041902,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 174176
    },
    {
      "epoch": 0.000632235405955027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 174208
    },
    {
      "epoch": 0.0006323515403058636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 174240
    },
    {
      "epoch": 0.0006324676746567004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 174272
    },
    {
      "epoch": 0.000632583809007537,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 174304
    },
    {
      "epoch": 0.0006326999433583738,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 174336
    },
    {
      "epoch": 0.0006328160777092104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 174368
    },
    {
      "epoch": 0.0006329322120600472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 174400
    },
    {
      "epoch": 0.0006330483464108839,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7386,
      "step": 174432
    },
    {
      "epoch": 0.0006331644807617206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.743,
      "step": 174464
    },
    {
      "epoch": 0.0006332806151125573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 174496
    },
    {
      "epoch": 0.000633396749463394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 174528
    },
    {
      "epoch": 0.0006335128838142307,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 174560
    },
    {
      "epoch": 0.0006336290181650674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 174592
    },
    {
      "epoch": 0.0006337451525159041,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.743,
      "step": 174624
    },
    {
      "epoch": 0.0006338612868667408,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 174656
    },
    {
      "epoch": 0.0006339774212175775,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6954,
      "step": 174688
    },
    {
      "epoch": 0.0006340935555684143,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 174720
    },
    {
      "epoch": 0.0006342096899192509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 174752
    },
    {
      "epoch": 0.0006343258242700877,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 174784
    },
    {
      "epoch": 0.0006344419586209243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6972,
      "step": 174816
    },
    {
      "epoch": 0.0006345580929717611,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 174848
    },
    {
      "epoch": 0.0006346742273225977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.739,
      "step": 174880
    },
    {
      "epoch": 0.0006347903616734345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 174912
    },
    {
      "epoch": 0.0006349064960242711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 174944
    },
    {
      "epoch": 0.0006350226303751079,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 174976
    },
    {
      "epoch": 0.0006351387647259446,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 175008
    },
    {
      "epoch": 0.0006352548990767813,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 175040
    },
    {
      "epoch": 0.000635371033427618,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 175072
    },
    {
      "epoch": 0.0006354871677784547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 175104
    },
    {
      "epoch": 0.0006356033021292914,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 175136
    },
    {
      "epoch": 0.0006357194364801281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 175168
    },
    {
      "epoch": 0.0006358355708309648,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 175200
    },
    {
      "epoch": 0.0006359517051818015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 175232
    },
    {
      "epoch": 0.0006360678395326382,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 175264
    },
    {
      "epoch": 0.000636183973883475,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7272,
      "step": 175296
    },
    {
      "epoch": 0.0006363001082343116,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7493,
      "step": 175328
    },
    {
      "epoch": 0.0006364162425851484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 175360
    },
    {
      "epoch": 0.000636532376935985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 175392
    },
    {
      "epoch": 0.0006366485112868218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 175424
    },
    {
      "epoch": 0.0006367646456376584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7322,
      "step": 175456
    },
    {
      "epoch": 0.0006368807799884952,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 175488
    },
    {
      "epoch": 0.0006369969143393318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 175520
    },
    {
      "epoch": 0.0006371130486901686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6836,
      "step": 175552
    },
    {
      "epoch": 0.0006372291830410053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 175584
    },
    {
      "epoch": 0.000637345317391842,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 175616
    },
    {
      "epoch": 0.0006374614517426787,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 175648
    },
    {
      "epoch": 0.0006375775860935154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7346,
      "step": 175680
    },
    {
      "epoch": 0.0006376937204443521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 175712
    },
    {
      "epoch": 0.0006378098547951888,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 175744
    },
    {
      "epoch": 0.0006379259891460255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 175776
    },
    {
      "epoch": 0.0006380421234968622,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 175808
    },
    {
      "epoch": 0.0006381582578476989,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 175840
    },
    {
      "epoch": 0.0006382743921985357,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 175872
    },
    {
      "epoch": 0.0006383905265493723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 175904
    },
    {
      "epoch": 0.0006385066609002091,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 175936
    },
    {
      "epoch": 0.0006386227952510457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 175968
    },
    {
      "epoch": 0.0006387389296018825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 176000
    },
    {
      "epoch": 0.0006388550639527191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 176032
    },
    {
      "epoch": 0.0006389711983035559,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 176064
    },
    {
      "epoch": 0.0006390873326543925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 176096
    },
    {
      "epoch": 0.0006392034670052293,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 176128
    },
    {
      "epoch": 0.000639319601356066,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 176160
    },
    {
      "epoch": 0.0006394357357069027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7308,
      "step": 176192
    },
    {
      "epoch": 0.0006395518700577394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 176224
    },
    {
      "epoch": 0.0006396680044085761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 176256
    },
    {
      "epoch": 0.0006397841387594128,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 176288
    },
    {
      "epoch": 0.0006399002731102495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 176320
    },
    {
      "epoch": 0.0006400164074610862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7385,
      "step": 176352
    },
    {
      "epoch": 0.0006401325418119229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7056,
      "step": 176384
    },
    {
      "epoch": 0.0006402486761627596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 176416
    },
    {
      "epoch": 0.0006403648105135964,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7004,
      "step": 176448
    },
    {
      "epoch": 0.000640480944864433,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 176480
    },
    {
      "epoch": 0.0006405970792152698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 176512
    },
    {
      "epoch": 0.0006407132135661064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 176544
    },
    {
      "epoch": 0.0006408293479169432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 176576
    },
    {
      "epoch": 0.0006409454822677798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7293,
      "step": 176608
    },
    {
      "epoch": 0.0006410616166186166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 176640
    },
    {
      "epoch": 0.0006411777509694532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 176672
    },
    {
      "epoch": 0.00064129388532029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 176704
    },
    {
      "epoch": 0.0006414100196711267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6912,
      "step": 176736
    },
    {
      "epoch": 0.0006415261540219634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 176768
    },
    {
      "epoch": 0.0006416422883728001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 176800
    },
    {
      "epoch": 0.0006417584227236368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 176832
    },
    {
      "epoch": 0.0006418745570744735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 176864
    },
    {
      "epoch": 0.0006419906914253102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 176896
    },
    {
      "epoch": 0.0006421068257761469,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 176928
    },
    {
      "epoch": 0.0006422229601269836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 176960
    },
    {
      "epoch": 0.0006423390944778203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 176992
    },
    {
      "epoch": 0.0006424552288286571,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7346,
      "step": 177024
    },
    {
      "epoch": 0.0006425713631794937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7335,
      "step": 177056
    },
    {
      "epoch": 0.0006426874975303305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7432,
      "step": 177088
    },
    {
      "epoch": 0.0006428036318811671,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 177120
    },
    {
      "epoch": 0.0006429197662320039,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7353,
      "step": 177152
    },
    {
      "epoch": 0.0006430359005828405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7272,
      "step": 177184
    },
    {
      "epoch": 0.0006431520349336773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7337,
      "step": 177216
    },
    {
      "epoch": 0.0006432681692845139,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 177248
    },
    {
      "epoch": 0.0006433843036353507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 177280
    },
    {
      "epoch": 0.0006435004379861874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 177312
    },
    {
      "epoch": 0.0006436165723370241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 177344
    },
    {
      "epoch": 0.0006437327066878608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 177376
    },
    {
      "epoch": 0.0006438488410386975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 177408
    },
    {
      "epoch": 0.0006439649753895342,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 177440
    },
    {
      "epoch": 0.0006440811097403709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 177472
    },
    {
      "epoch": 0.0006441972440912076,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7311,
      "step": 177504
    },
    {
      "epoch": 0.0006443133784420443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 177536
    },
    {
      "epoch": 0.000644429512792881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 177568
    },
    {
      "epoch": 0.0006445456471437178,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 177600
    },
    {
      "epoch": 0.0006446617814945544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 177632
    },
    {
      "epoch": 0.0006447779158453912,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 177664
    },
    {
      "epoch": 0.0006448940501962278,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 177696
    },
    {
      "epoch": 0.0006450101845470646,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 177728
    },
    {
      "epoch": 0.0006451263188979012,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 177760
    },
    {
      "epoch": 0.000645242453248738,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 177792
    },
    {
      "epoch": 0.0006453585875995746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 177824
    },
    {
      "epoch": 0.0006454747219504114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 177856
    },
    {
      "epoch": 0.000645590856301248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 177888
    },
    {
      "epoch": 0.0006457069906520848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 177920
    },
    {
      "epoch": 0.0006458231250029215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7405,
      "step": 177952
    },
    {
      "epoch": 0.0006459392593537582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7281,
      "step": 177984
    },
    {
      "epoch": 0.000646055393704595,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7273,
      "step": 178016
    },
    {
      "epoch": 0.0006461715280554316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7433,
      "step": 178048
    },
    {
      "epoch": 0.0006462876624062683,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7327,
      "step": 178080
    },
    {
      "epoch": 0.000646403796757105,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6963,
      "step": 178112
    },
    {
      "epoch": 0.0006465199311079417,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6977,
      "step": 178144
    },
    {
      "epoch": 0.0006466360654587784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7262,
      "step": 178176
    },
    {
      "epoch": 0.0006467521998096151,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 178208
    },
    {
      "epoch": 0.0006468683341604519,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 178240
    },
    {
      "epoch": 0.0006469844685112885,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6963,
      "step": 178272
    },
    {
      "epoch": 0.0006471006028621253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 178304
    },
    {
      "epoch": 0.000647216737212962,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 178336
    },
    {
      "epoch": 0.0006473328715637987,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 178368
    },
    {
      "epoch": 0.0006474490059146353,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 178400
    },
    {
      "epoch": 0.0006475651402654721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 178432
    },
    {
      "epoch": 0.0006476812746163087,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 178464
    },
    {
      "epoch": 0.0006477974089671455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 178496
    },
    {
      "epoch": 0.0006479135433179823,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 178528
    },
    {
      "epoch": 0.0006480296776688189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6932,
      "step": 178560
    },
    {
      "epoch": 0.0006481458120196557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 178592
    },
    {
      "epoch": 0.0006482619463704923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 178624
    },
    {
      "epoch": 0.000648378080721329,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 178656
    },
    {
      "epoch": 0.0006484942150721657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 178688
    },
    {
      "epoch": 0.0006486103494230025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 178720
    },
    {
      "epoch": 0.0006487264837738391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7275,
      "step": 178752
    },
    {
      "epoch": 0.0006488426181246759,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7422,
      "step": 178784
    },
    {
      "epoch": 0.0006489587524755126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 178816
    },
    {
      "epoch": 0.0006490748868263493,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7556,
      "step": 178848
    },
    {
      "epoch": 0.000649191021177186,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 178880
    },
    {
      "epoch": 0.0006493071555280227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 178912
    },
    {
      "epoch": 0.0006494232898788594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 178944
    },
    {
      "epoch": 0.000649539424229696,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 178976
    },
    {
      "epoch": 0.0006496555585805328,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 179008
    },
    {
      "epoch": 0.0006497716929313695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 179040
    },
    {
      "epoch": 0.0006498878272822062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 179072
    },
    {
      "epoch": 0.000650003961633043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 179104
    },
    {
      "epoch": 0.0006501200959838796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 179136
    },
    {
      "epoch": 0.0006502362303347164,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 179168
    },
    {
      "epoch": 0.000650352364685553,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 179200
    },
    {
      "epoch": 0.0006504684990363898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 179232
    },
    {
      "epoch": 0.0006505846333872264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 179264
    },
    {
      "epoch": 0.0006507007677380632,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 179296
    },
    {
      "epoch": 0.0006508169020888998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6986,
      "step": 179328
    },
    {
      "epoch": 0.0006509330364397366,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 179360
    },
    {
      "epoch": 0.0006510491707905733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 179392
    },
    {
      "epoch": 0.00065116530514141,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 179424
    },
    {
      "epoch": 0.0006512814394922467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 179456
    },
    {
      "epoch": 0.0006513975738430834,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 179488
    },
    {
      "epoch": 0.0006515137081939201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 179520
    },
    {
      "epoch": 0.0006516298425447568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 179552
    },
    {
      "epoch": 0.0006517459768955935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 179584
    },
    {
      "epoch": 0.0006518621112464302,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 179616
    },
    {
      "epoch": 0.0006519782455972669,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 179648
    },
    {
      "epoch": 0.0006520943799481037,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 179680
    },
    {
      "epoch": 0.0006522105142989403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7645,
      "step": 179712
    },
    {
      "epoch": 0.0006523266486497771,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 179744
    },
    {
      "epoch": 0.0006524427830006137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 179776
    },
    {
      "epoch": 0.0006525589173514505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7277,
      "step": 179808
    },
    {
      "epoch": 0.0006526750517022871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 179840
    },
    {
      "epoch": 0.0006527911860531239,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6955,
      "step": 179872
    },
    {
      "epoch": 0.0006529073204039605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 179904
    },
    {
      "epoch": 0.0006530234547547973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 179936
    },
    {
      "epoch": 0.000653139589105634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 179968
    },
    {
      "epoch": 0.0006532557234564707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 180000
    },
    {
      "epoch": 0.0006533718578073074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 180032
    },
    {
      "epoch": 0.0006534879921581441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6996,
      "step": 180064
    },
    {
      "epoch": 0.0006536041265089808,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 180096
    },
    {
      "epoch": 0.0006537202608598175,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 180128
    },
    {
      "epoch": 0.0006538363952106542,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 180160
    },
    {
      "epoch": 0.0006539525295614909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 180192
    },
    {
      "epoch": 0.0006540686639123276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 180224
    },
    {
      "epoch": 0.0006541847982631644,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 180256
    },
    {
      "epoch": 0.000654300932614001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 180288
    },
    {
      "epoch": 0.0006544170669648378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.691,
      "step": 180320
    },
    {
      "epoch": 0.0006545332013156744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 180352
    },
    {
      "epoch": 0.0006546493356665112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 180384
    },
    {
      "epoch": 0.0006547654700173478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 180416
    },
    {
      "epoch": 0.0006548816043681846,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 180448
    },
    {
      "epoch": 0.0006549977387190212,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 180480
    },
    {
      "epoch": 0.000655113873069858,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 180512
    },
    {
      "epoch": 0.0006552300074206947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7502,
      "step": 180544
    },
    {
      "epoch": 0.0006553461417715314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7485,
      "step": 180576
    },
    {
      "epoch": 0.0006554622761223681,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 180608
    },
    {
      "epoch": 0.0006555784104732048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 180640
    },
    {
      "epoch": 0.0006556945448240415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 180672
    },
    {
      "epoch": 0.0006558106791748782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 180704
    },
    {
      "epoch": 0.0006559268135257149,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 180736
    },
    {
      "epoch": 0.0006560429478765516,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 180768
    },
    {
      "epoch": 0.0006561590822273883,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 180800
    },
    {
      "epoch": 0.0006562752165782251,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 180832
    },
    {
      "epoch": 0.0006563913509290617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 180864
    },
    {
      "epoch": 0.0006565074852798985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 180896
    },
    {
      "epoch": 0.0006566236196307351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 180928
    },
    {
      "epoch": 0.0006567397539815719,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 180960
    },
    {
      "epoch": 0.0006568558883324085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 180992
    },
    {
      "epoch": 0.0006569720226832453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 181024
    },
    {
      "epoch": 0.0006570881570340819,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 181056
    },
    {
      "epoch": 0.0006572042913849187,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 181088
    },
    {
      "epoch": 0.0006573204257357554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 181120
    },
    {
      "epoch": 0.0006574365600865921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 181152
    },
    {
      "epoch": 0.0006575526944374288,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 181184
    },
    {
      "epoch": 0.0006576688287882655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 181216
    },
    {
      "epoch": 0.0006577849631391022,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 181248
    },
    {
      "epoch": 0.0006579010974899389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 181280
    },
    {
      "epoch": 0.0006580172318407756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 181312
    },
    {
      "epoch": 0.0006581333661916123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 181344
    },
    {
      "epoch": 0.000658249500542449,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 181376
    },
    {
      "epoch": 0.0006583656348932858,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7437,
      "step": 181408
    },
    {
      "epoch": 0.0006584817692441224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 181440
    },
    {
      "epoch": 0.0006585979035949592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7509,
      "step": 181472
    },
    {
      "epoch": 0.0006587140379457958,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7391,
      "step": 181504
    },
    {
      "epoch": 0.0006588301722966326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7004,
      "step": 181536
    },
    {
      "epoch": 0.0006589463066474692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 181568
    },
    {
      "epoch": 0.000659062440998306,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 181600
    },
    {
      "epoch": 0.0006591785753491426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6907,
      "step": 181632
    },
    {
      "epoch": 0.0006592947096999794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 181664
    },
    {
      "epoch": 0.0006594108440508161,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 181696
    },
    {
      "epoch": 0.0006595269784016528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 181728
    },
    {
      "epoch": 0.0006596431127524895,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 181760
    },
    {
      "epoch": 0.0006597592471033262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 181792
    },
    {
      "epoch": 0.0006598753814541629,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 181824
    },
    {
      "epoch": 0.0006599915158049996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 181856
    },
    {
      "epoch": 0.0006601076501558363,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7376,
      "step": 181888
    },
    {
      "epoch": 0.000660223784506673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7161,
      "step": 181920
    },
    {
      "epoch": 0.0006603399188575097,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 181952
    },
    {
      "epoch": 0.0006604560532083465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 181984
    },
    {
      "epoch": 0.0006605721875591831,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 182016
    },
    {
      "epoch": 0.0006606883219100199,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7076,
      "step": 182048
    },
    {
      "epoch": 0.0006608044562608565,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 182080
    },
    {
      "epoch": 0.0006609205906116933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 182112
    },
    {
      "epoch": 0.0006610367249625299,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.754,
      "step": 182144
    },
    {
      "epoch": 0.0006611528593133667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 182176
    },
    {
      "epoch": 0.0006612689936642033,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 182208
    },
    {
      "epoch": 0.0006613851280150401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 182240
    },
    {
      "epoch": 0.0006615012623658768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7367,
      "step": 182272
    },
    {
      "epoch": 0.0006616173967167135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7429,
      "step": 182304
    },
    {
      "epoch": 0.0006617335310675502,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7464,
      "step": 182336
    },
    {
      "epoch": 0.0006618496654183869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 182368
    },
    {
      "epoch": 0.0006619657997692236,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 182400
    },
    {
      "epoch": 0.0006620819341200603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 182432
    },
    {
      "epoch": 0.000662198068470897,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 182464
    },
    {
      "epoch": 0.0006623142028217337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 182496
    },
    {
      "epoch": 0.0006624303371725704,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6976,
      "step": 182528
    },
    {
      "epoch": 0.0006625464715234072,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 182560
    },
    {
      "epoch": 0.0006626626058742438,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 182592
    },
    {
      "epoch": 0.0006627787402250806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 182624
    },
    {
      "epoch": 0.0006628948745759172,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 182656
    },
    {
      "epoch": 0.000663011008926754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6947,
      "step": 182688
    },
    {
      "epoch": 0.0006631271432775906,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 182720
    },
    {
      "epoch": 0.0006632432776284274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 182752
    },
    {
      "epoch": 0.000663359411979264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 182784
    },
    {
      "epoch": 0.0006634755463301008,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 182816
    },
    {
      "epoch": 0.0006635916806809376,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 182848
    },
    {
      "epoch": 0.0006637078150317742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 182880
    },
    {
      "epoch": 0.000663823949382611,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 182912
    },
    {
      "epoch": 0.0006639400837334476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 182944
    },
    {
      "epoch": 0.0006640562180842844,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 182976
    },
    {
      "epoch": 0.000664172352435121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 183008
    },
    {
      "epoch": 0.0006642884867859578,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 183040
    },
    {
      "epoch": 0.0006644046211367944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7411,
      "step": 183072
    },
    {
      "epoch": 0.0006645207554876312,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 183104
    },
    {
      "epoch": 0.0006646368898384679,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7374,
      "step": 183136
    },
    {
      "epoch": 0.0006647530241893046,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7446,
      "step": 183168
    },
    {
      "epoch": 0.0006648691585401413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 183200
    },
    {
      "epoch": 0.000664985292890978,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7484,
      "step": 183232
    },
    {
      "epoch": 0.0006651014272418147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 183264
    },
    {
      "epoch": 0.0006652175615926514,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 183296
    },
    {
      "epoch": 0.0006653336959434881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 183328
    },
    {
      "epoch": 0.0006654498302943248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 183360
    },
    {
      "epoch": 0.0006655659646451615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6924,
      "step": 183392
    },
    {
      "epoch": 0.0006656820989959983,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6962,
      "step": 183424
    },
    {
      "epoch": 0.0006657982333468349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 183456
    },
    {
      "epoch": 0.0006659143676976717,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 183488
    },
    {
      "epoch": 0.0006660305020485083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 183520
    },
    {
      "epoch": 0.0006661466363993451,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 183552
    },
    {
      "epoch": 0.0006662627707501817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 183584
    },
    {
      "epoch": 0.0006663789051010185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 183616
    },
    {
      "epoch": 0.0006664950394518551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 183648
    },
    {
      "epoch": 0.0006666111738026919,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7037,
      "step": 183680
    },
    {
      "epoch": 0.0006667273081535286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 183712
    },
    {
      "epoch": 0.0006668434425043653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 183744
    },
    {
      "epoch": 0.000666959576855202,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 183776
    },
    {
      "epoch": 0.0006670757112060387,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 183808
    },
    {
      "epoch": 0.0006671918455568754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7202,
      "step": 183840
    },
    {
      "epoch": 0.0006673079799077121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 183872
    },
    {
      "epoch": 0.0006674241142585488,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7433,
      "step": 183904
    },
    {
      "epoch": 0.0006675402486093855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 183936
    },
    {
      "epoch": 0.0006676563829602222,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 183968
    },
    {
      "epoch": 0.000667772517311059,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 184000
    },
    {
      "epoch": 0.0006678886516618956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 184032
    },
    {
      "epoch": 0.0006680047860127324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7545,
      "step": 184064
    },
    {
      "epoch": 0.000668120920363569,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7456,
      "step": 184096
    },
    {
      "epoch": 0.0006682370547144058,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 184128
    },
    {
      "epoch": 0.0006683531890652424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 184160
    },
    {
      "epoch": 0.0006684693234160792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 184192
    },
    {
      "epoch": 0.0006685854577669158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 184224
    },
    {
      "epoch": 0.0006687015921177526,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 184256
    },
    {
      "epoch": 0.0006688177264685893,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 184288
    },
    {
      "epoch": 0.000668933860819426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 184320
    },
    {
      "epoch": 0.0006690499951702627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 184352
    },
    {
      "epoch": 0.0006691661295210994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 184384
    },
    {
      "epoch": 0.0006692822638719361,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 184416
    },
    {
      "epoch": 0.0006693983982227728,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 184448
    },
    {
      "epoch": 0.0006695145325736095,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 184480
    },
    {
      "epoch": 0.0006696306669244462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7466,
      "step": 184512
    },
    {
      "epoch": 0.0006697468012752829,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 184544
    },
    {
      "epoch": 0.0006698629356261197,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 184576
    },
    {
      "epoch": 0.0006699790699769563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 184608
    },
    {
      "epoch": 0.0006700952043277931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.73,
      "step": 184640
    },
    {
      "epoch": 0.0006702113386786297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 184672
    },
    {
      "epoch": 0.0006703274730294665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6997,
      "step": 184704
    },
    {
      "epoch": 0.0006704436073803031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 184736
    },
    {
      "epoch": 0.0006705597417311399,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.733,
      "step": 184768
    },
    {
      "epoch": 0.0006706758760819765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 184800
    },
    {
      "epoch": 0.0006707920104328133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7371,
      "step": 184832
    },
    {
      "epoch": 0.00067090814478365,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7362,
      "step": 184864
    },
    {
      "epoch": 0.0006710242791344867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 184896
    },
    {
      "epoch": 0.0006711404134853234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7609,
      "step": 184928
    },
    {
      "epoch": 0.0006712565478361601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 184960
    },
    {
      "epoch": 0.0006713726821869968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 184992
    },
    {
      "epoch": 0.0006714888165378335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 185024
    },
    {
      "epoch": 0.0006716049508886702,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 185056
    },
    {
      "epoch": 0.0006717210852395069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 185088
    },
    {
      "epoch": 0.0006718372195903436,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 185120
    },
    {
      "epoch": 0.0006719533539411804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6915,
      "step": 185152
    },
    {
      "epoch": 0.000672069488292017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 185184
    },
    {
      "epoch": 0.0006721856226428538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 185216
    },
    {
      "epoch": 0.0006723017569936904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 185248
    },
    {
      "epoch": 0.0006724178913445272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 185280
    },
    {
      "epoch": 0.0006725340256953638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 185312
    },
    {
      "epoch": 0.0006726501600462006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 185344
    },
    {
      "epoch": 0.0006727662943970372,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 185376
    },
    {
      "epoch": 0.000672882428747874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 185408
    },
    {
      "epoch": 0.0006729985630987107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 185440
    },
    {
      "epoch": 0.0006731146974495474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 185472
    },
    {
      "epoch": 0.0006732308318003841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 185504
    },
    {
      "epoch": 0.0006733469661512208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 185536
    },
    {
      "epoch": 0.0006734631005020575,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 185568
    },
    {
      "epoch": 0.0006735792348528942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 185600
    },
    {
      "epoch": 0.0006736953692037309,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.736,
      "step": 185632
    },
    {
      "epoch": 0.0006738115035545676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7393,
      "step": 185664
    },
    {
      "epoch": 0.0006739276379054043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7384,
      "step": 185696
    },
    {
      "epoch": 0.0006740437722562411,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 185728
    },
    {
      "epoch": 0.0006741599066070777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 185760
    },
    {
      "epoch": 0.0006742760409579145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7545,
      "step": 185792
    },
    {
      "epoch": 0.0006743921753087511,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7344,
      "step": 185824
    },
    {
      "epoch": 0.0006745083096595879,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 185856
    },
    {
      "epoch": 0.0006746244440104245,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 185888
    },
    {
      "epoch": 0.0006747405783612613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6932,
      "step": 185920
    },
    {
      "epoch": 0.0006748567127120979,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 185952
    },
    {
      "epoch": 0.0006749728470629347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 185984
    },
    {
      "epoch": 0.0006750889814137714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 186016
    },
    {
      "epoch": 0.0006752051157646081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 186048
    },
    {
      "epoch": 0.0006753212501154448,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 186080
    },
    {
      "epoch": 0.0006754373844662815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 186112
    },
    {
      "epoch": 0.0006755535188171182,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 186144
    },
    {
      "epoch": 0.0006756696531679549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 186176
    },
    {
      "epoch": 0.0006757857875187916,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 186208
    },
    {
      "epoch": 0.0006759019218696283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 186240
    },
    {
      "epoch": 0.000676018056220465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 186272
    },
    {
      "epoch": 0.0006761341905713018,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7102,
      "step": 186304
    },
    {
      "epoch": 0.0006762503249221384,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 186336
    },
    {
      "epoch": 0.0006763664592729752,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 186368
    },
    {
      "epoch": 0.0006764825936238118,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 186400
    },
    {
      "epoch": 0.0006765987279746486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 186432
    },
    {
      "epoch": 0.0006767148623254852,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 186464
    },
    {
      "epoch": 0.000676830996676322,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 186496
    },
    {
      "epoch": 0.0006769471310271586,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 186528
    },
    {
      "epoch": 0.0006770632653779954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7384,
      "step": 186560
    },
    {
      "epoch": 0.0006771793997288321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 186592
    },
    {
      "epoch": 0.0006772955340796688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 186624
    },
    {
      "epoch": 0.0006774116684305055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.744,
      "step": 186656
    },
    {
      "epoch": 0.0006775278027813422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 186688
    },
    {
      "epoch": 0.000677643937132179,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 186720
    },
    {
      "epoch": 0.0006777600714830156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 186752
    },
    {
      "epoch": 0.0006778762058338523,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 186784
    },
    {
      "epoch": 0.000677992340184689,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 186816
    },
    {
      "epoch": 0.0006781084745355257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 186848
    },
    {
      "epoch": 0.0006782246088863625,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 186880
    },
    {
      "epoch": 0.0006783407432371991,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 186912
    },
    {
      "epoch": 0.0006784568775880359,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 186944
    },
    {
      "epoch": 0.0006785730119388725,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 186976
    },
    {
      "epoch": 0.0006786891462897093,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7296,
      "step": 187008
    },
    {
      "epoch": 0.000678805280640546,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 187040
    },
    {
      "epoch": 0.0006789214149913827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 187072
    },
    {
      "epoch": 0.0006790375493422193,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6896,
      "step": 187104
    },
    {
      "epoch": 0.0006791536836930561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 187136
    },
    {
      "epoch": 0.0006792698180438929,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7153,
      "step": 187168
    },
    {
      "epoch": 0.0006793859523947295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 187200
    },
    {
      "epoch": 0.0006795020867455663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 187232
    },
    {
      "epoch": 0.0006796182210964029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7266,
      "step": 187264
    },
    {
      "epoch": 0.0006797343554472397,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 187296
    },
    {
      "epoch": 0.0006798504897980763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 187328
    },
    {
      "epoch": 0.0006799666241489131,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7309,
      "step": 187360
    },
    {
      "epoch": 0.0006800827584997497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 187392
    },
    {
      "epoch": 0.0006801988928505865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7355,
      "step": 187424
    },
    {
      "epoch": 0.0006803150272014232,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7331,
      "step": 187456
    },
    {
      "epoch": 0.0006804311615522599,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 187488
    },
    {
      "epoch": 0.0006805472959030966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 187520
    },
    {
      "epoch": 0.0006806634302539333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 187552
    },
    {
      "epoch": 0.00068077956460477,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7459,
      "step": 187584
    },
    {
      "epoch": 0.0006808956989556067,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 187616
    },
    {
      "epoch": 0.0006810118333064434,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 187648
    },
    {
      "epoch": 0.0006811279676572801,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 187680
    },
    {
      "epoch": 0.0006812441020081168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 187712
    },
    {
      "epoch": 0.0006813602363589536,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 187744
    },
    {
      "epoch": 0.0006814763707097902,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 187776
    },
    {
      "epoch": 0.000681592505060627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 187808
    },
    {
      "epoch": 0.0006817086394114636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 187840
    },
    {
      "epoch": 0.0006818247737623004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 187872
    },
    {
      "epoch": 0.000681940908113137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 187904
    },
    {
      "epoch": 0.0006820570424639738,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 187936
    },
    {
      "epoch": 0.0006821731768148104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 187968
    },
    {
      "epoch": 0.0006822893111656472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 188000
    },
    {
      "epoch": 0.0006824054455164839,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7403,
      "step": 188032
    },
    {
      "epoch": 0.0006825215798673206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 188064
    },
    {
      "epoch": 0.0006826377142181573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6818,
      "step": 188096
    },
    {
      "epoch": 0.000682753848568994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 188128
    },
    {
      "epoch": 0.0006828699829198307,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 188160
    },
    {
      "epoch": 0.0006829861172706674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 188192
    },
    {
      "epoch": 0.0006831022516215041,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 188224
    },
    {
      "epoch": 0.0006832183859723408,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7326,
      "step": 188256
    },
    {
      "epoch": 0.0006833345203231775,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 188288
    },
    {
      "epoch": 0.0006834506546740143,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 188320
    },
    {
      "epoch": 0.0006835667890248509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.739,
      "step": 188352
    },
    {
      "epoch": 0.0006836829233756877,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 188384
    },
    {
      "epoch": 0.0006837990577265243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7008,
      "step": 188416
    },
    {
      "epoch": 0.0006839151920773611,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 188448
    },
    {
      "epoch": 0.0006840313264281977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 188480
    },
    {
      "epoch": 0.0006841474607790345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 188512
    },
    {
      "epoch": 0.0006842635951298711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 188544
    },
    {
      "epoch": 0.0006843797294807079,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 188576
    },
    {
      "epoch": 0.0006844958638315445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 188608
    },
    {
      "epoch": 0.0006846119981823813,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 188640
    },
    {
      "epoch": 0.000684728132533218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 188672
    },
    {
      "epoch": 0.0006848442668840547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 188704
    },
    {
      "epoch": 0.0006849604012348914,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 188736
    },
    {
      "epoch": 0.0006850765355857281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 188768
    },
    {
      "epoch": 0.0006851926699365648,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 188800
    },
    {
      "epoch": 0.0006853088042874015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6944,
      "step": 188832
    },
    {
      "epoch": 0.0006854249386382382,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 188864
    },
    {
      "epoch": 0.0006855410729890749,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 188896
    },
    {
      "epoch": 0.0006856572073399116,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 188928
    },
    {
      "epoch": 0.0006857733416907484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 188960
    },
    {
      "epoch": 0.000685889476041585,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 188992
    },
    {
      "epoch": 0.0006860056103924218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 189024
    },
    {
      "epoch": 0.0006861217447432584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 189056
    },
    {
      "epoch": 0.0006862378790940952,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 189088
    },
    {
      "epoch": 0.0006863540134449318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 189120
    },
    {
      "epoch": 0.0006864701477957686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.738,
      "step": 189152
    },
    {
      "epoch": 0.0006865862821466052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 189184
    },
    {
      "epoch": 0.000686702416497442,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7435,
      "step": 189216
    },
    {
      "epoch": 0.0006868185508482787,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 189248
    },
    {
      "epoch": 0.0006869346851991154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 189280
    },
    {
      "epoch": 0.0006870508195499521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 189312
    },
    {
      "epoch": 0.0006871669539007888,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7413,
      "step": 189344
    },
    {
      "epoch": 0.0006872830882516255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7286,
      "step": 189376
    },
    {
      "epoch": 0.0006873992226024622,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 189408
    },
    {
      "epoch": 0.0006875153569532989,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6982,
      "step": 189440
    },
    {
      "epoch": 0.0006876314913041356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 189472
    },
    {
      "epoch": 0.0006877476256549723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 189504
    },
    {
      "epoch": 0.0006878637600058091,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 189536
    },
    {
      "epoch": 0.0006879798943566457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 189568
    },
    {
      "epoch": 0.0006880960287074825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 189600
    },
    {
      "epoch": 0.0006882121630583191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 189632
    },
    {
      "epoch": 0.0006883282974091559,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 189664
    },
    {
      "epoch": 0.0006884444317599925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 189696
    },
    {
      "epoch": 0.0006885605661108293,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 189728
    },
    {
      "epoch": 0.0006886767004616659,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 189760
    },
    {
      "epoch": 0.0006887928348125027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 189792
    },
    {
      "epoch": 0.0006889089691633394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 189824
    },
    {
      "epoch": 0.0006890251035141761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6985,
      "step": 189856
    },
    {
      "epoch": 0.0006891412378650128,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 189888
    },
    {
      "epoch": 0.0006892573722158495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 189920
    },
    {
      "epoch": 0.0006893735065666862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7479,
      "step": 189952
    },
    {
      "epoch": 0.0006894896409175229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 189984
    },
    {
      "epoch": 0.0006896057752683596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 190016
    },
    {
      "epoch": 0.0006897219096191963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7296,
      "step": 190048
    },
    {
      "epoch": 0.000689838043970033,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7441,
      "step": 190080
    },
    {
      "epoch": 0.0006899541783208698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 190112
    },
    {
      "epoch": 0.0006900703126717064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 190144
    },
    {
      "epoch": 0.0006901864470225432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 190176
    },
    {
      "epoch": 0.0006903025813733798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 190208
    },
    {
      "epoch": 0.0006904187157242166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 190240
    },
    {
      "epoch": 0.0006905348500750532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 190272
    },
    {
      "epoch": 0.00069065098442589,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 190304
    },
    {
      "epoch": 0.0006907671187767266,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 190336
    },
    {
      "epoch": 0.0006908832531275634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 190368
    },
    {
      "epoch": 0.0006909993874784001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 190400
    },
    {
      "epoch": 0.0006911155218292368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6897,
      "step": 190432
    },
    {
      "epoch": 0.0006912316561800735,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6947,
      "step": 190464
    },
    {
      "epoch": 0.0006913477905309102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 190496
    },
    {
      "epoch": 0.0006914639248817469,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 190528
    },
    {
      "epoch": 0.0006915800592325836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 190560
    },
    {
      "epoch": 0.0006916961935834203,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 190592
    },
    {
      "epoch": 0.000691812327934257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 190624
    },
    {
      "epoch": 0.0006919284622850937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 190656
    },
    {
      "epoch": 0.0006920445966359305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 190688
    },
    {
      "epoch": 0.0006921607309867671,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 190720
    },
    {
      "epoch": 0.0006922768653376039,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.733,
      "step": 190752
    },
    {
      "epoch": 0.0006923929996884405,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 190784
    },
    {
      "epoch": 0.0006925091340392773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 190816
    },
    {
      "epoch": 0.0006926252683901139,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 190848
    },
    {
      "epoch": 0.0006927414027409507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 190880
    },
    {
      "epoch": 0.0006928575370917873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.736,
      "step": 190912
    },
    {
      "epoch": 0.0006929736714426241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7416,
      "step": 190944
    },
    {
      "epoch": 0.0006930898057934609,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7322,
      "step": 190976
    },
    {
      "epoch": 0.0006932059401442975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7008,
      "step": 191008
    },
    {
      "epoch": 0.0006933220744951343,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6956,
      "step": 191040
    },
    {
      "epoch": 0.0006934382088459709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7273,
      "step": 191072
    },
    {
      "epoch": 0.0006935543431968077,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7415,
      "step": 191104
    },
    {
      "epoch": 0.0006936704775476443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 191136
    },
    {
      "epoch": 0.000693786611898481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 191168
    },
    {
      "epoch": 0.0006939027462493177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 191200
    },
    {
      "epoch": 0.0006940188806001544,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 191232
    },
    {
      "epoch": 0.0006941350149509912,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 191264
    },
    {
      "epoch": 0.0006942511493018278,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 191296
    },
    {
      "epoch": 0.0006943672836526646,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 191328
    },
    {
      "epoch": 0.0006944834180035012,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7023,
      "step": 191360
    },
    {
      "epoch": 0.000694599552354338,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 191392
    },
    {
      "epoch": 0.0006947156867051746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 191424
    },
    {
      "epoch": 0.0006948318210560114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 191456
    },
    {
      "epoch": 0.000694947955406848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 191488
    },
    {
      "epoch": 0.0006950640897576848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 191520
    },
    {
      "epoch": 0.0006951802241085216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 191552
    },
    {
      "epoch": 0.0006952963584593582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 191584
    },
    {
      "epoch": 0.000695412492810195,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 191616
    },
    {
      "epoch": 0.0006955286271610316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 191648
    },
    {
      "epoch": 0.0006956447615118684,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 191680
    },
    {
      "epoch": 0.000695760895862705,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 191712
    },
    {
      "epoch": 0.0006958770302135418,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7336,
      "step": 191744
    },
    {
      "epoch": 0.0006959931645643784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7351,
      "step": 191776
    },
    {
      "epoch": 0.0006961092989152152,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 191808
    },
    {
      "epoch": 0.0006962254332660519,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 191840
    },
    {
      "epoch": 0.0006963415676168886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 191872
    },
    {
      "epoch": 0.0006964577019677253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 191904
    },
    {
      "epoch": 0.000696573836318562,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 191936
    },
    {
      "epoch": 0.0006966899706693987,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7383,
      "step": 191968
    },
    {
      "epoch": 0.0006968061050202354,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 192000
    },
    {
      "epoch": 0.0006969222393710721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6985,
      "step": 192032
    },
    {
      "epoch": 0.0006970383737219088,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 192064
    },
    {
      "epoch": 0.0006971545080727455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 192096
    },
    {
      "epoch": 0.0006972706424235823,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 192128
    },
    {
      "epoch": 0.0006973867767744189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 192160
    },
    {
      "epoch": 0.0006975029111252557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 192192
    },
    {
      "epoch": 0.0006976190454760923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 192224
    },
    {
      "epoch": 0.0006977351798269291,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 192256
    },
    {
      "epoch": 0.0006978513141777657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7297,
      "step": 192288
    },
    {
      "epoch": 0.0006979674485286025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 192320
    },
    {
      "epoch": 0.0006980835828794391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 192352
    },
    {
      "epoch": 0.0006981997172302759,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 192384
    },
    {
      "epoch": 0.0006983158515811126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 192416
    },
    {
      "epoch": 0.0006984319859319493,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 192448
    },
    {
      "epoch": 0.000698548120282786,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 192480
    },
    {
      "epoch": 0.0006986642546336227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 192512
    },
    {
      "epoch": 0.0006987803889844594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 192544
    },
    {
      "epoch": 0.0006988965233352961,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7441,
      "step": 192576
    },
    {
      "epoch": 0.0006990126576861328,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 192608
    },
    {
      "epoch": 0.0006991287920369695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 192640
    },
    {
      "epoch": 0.0006992449263878062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7593,
      "step": 192672
    },
    {
      "epoch": 0.000699361060738643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6916,
      "step": 192704
    },
    {
      "epoch": 0.0006994771950894796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 192736
    },
    {
      "epoch": 0.0006995933294403164,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 192768
    },
    {
      "epoch": 0.000699709463791153,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 192800
    },
    {
      "epoch": 0.0006998255981419898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 192832
    },
    {
      "epoch": 0.0006999417324928264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7372,
      "step": 192864
    },
    {
      "epoch": 0.0007000578668436632,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 192896
    },
    {
      "epoch": 0.0007001740011944998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 192928
    },
    {
      "epoch": 0.0007002901355453366,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 192960
    },
    {
      "epoch": 0.0007004062698961733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 192992
    },
    {
      "epoch": 0.00070052240424701,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 193024
    },
    {
      "epoch": 0.0007006385385978467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 193056
    },
    {
      "epoch": 0.0007007546729486834,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 193088
    },
    {
      "epoch": 0.0007008708072995201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 193120
    },
    {
      "epoch": 0.0007009869416503568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 193152
    },
    {
      "epoch": 0.0007011030760011935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 193184
    },
    {
      "epoch": 0.0007012192103520302,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6919,
      "step": 193216
    },
    {
      "epoch": 0.0007013353447028669,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 193248
    },
    {
      "epoch": 0.0007014514790537037,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 193280
    },
    {
      "epoch": 0.0007015676134045403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7347,
      "step": 193312
    },
    {
      "epoch": 0.0007016837477553771,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 193344
    },
    {
      "epoch": 0.0007017998821062137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 193376
    },
    {
      "epoch": 0.0007019160164570505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 193408
    },
    {
      "epoch": 0.0007020321508078871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7372,
      "step": 193440
    },
    {
      "epoch": 0.0007021482851587239,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.738,
      "step": 193472
    },
    {
      "epoch": 0.0007022644195095605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 193504
    },
    {
      "epoch": 0.0007023805538603973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7366,
      "step": 193536
    },
    {
      "epoch": 0.000702496688211234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 193568
    },
    {
      "epoch": 0.0007026128225620707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 193600
    },
    {
      "epoch": 0.0007027289569129074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 193632
    },
    {
      "epoch": 0.0007028450912637441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 193664
    },
    {
      "epoch": 0.0007029612256145808,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 193696
    },
    {
      "epoch": 0.0007030773599654175,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 193728
    },
    {
      "epoch": 0.0007031934943162542,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 193760
    },
    {
      "epoch": 0.0007033096286670909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 193792
    },
    {
      "epoch": 0.0007034257630179276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 193824
    },
    {
      "epoch": 0.0007035418973687644,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 193856
    },
    {
      "epoch": 0.000703658031719601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 193888
    },
    {
      "epoch": 0.0007037741660704378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 193920
    },
    {
      "epoch": 0.0007038903004212744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 193952
    },
    {
      "epoch": 0.0007040064347721112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 193984
    },
    {
      "epoch": 0.0007041225691229478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 194016
    },
    {
      "epoch": 0.0007042387034737846,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 194048
    },
    {
      "epoch": 0.0007043548378246212,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 194080
    },
    {
      "epoch": 0.000704470972175458,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6986,
      "step": 194112
    },
    {
      "epoch": 0.0007045871065262947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7366,
      "step": 194144
    },
    {
      "epoch": 0.0007047032408771314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 194176
    },
    {
      "epoch": 0.0007048193752279681,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 194208
    },
    {
      "epoch": 0.0007049355095788048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 194240
    },
    {
      "epoch": 0.0007050516439296415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 194272
    },
    {
      "epoch": 0.0007051677782804782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7296,
      "step": 194304
    },
    {
      "epoch": 0.0007052839126313149,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7379,
      "step": 194336
    },
    {
      "epoch": 0.0007054000469821516,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 194368
    },
    {
      "epoch": 0.0007055161813329883,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7369,
      "step": 194400
    },
    {
      "epoch": 0.0007056323156838251,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 194432
    },
    {
      "epoch": 0.0007057484500346617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 194464
    },
    {
      "epoch": 0.0007058645843854985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 194496
    },
    {
      "epoch": 0.0007059807187363351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 194528
    },
    {
      "epoch": 0.0007060968530871719,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 194560
    },
    {
      "epoch": 0.0007062129874380085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 194592
    },
    {
      "epoch": 0.0007063291217888453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7436,
      "step": 194624
    },
    {
      "epoch": 0.0007064452561396819,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 194656
    },
    {
      "epoch": 0.0007065613904905187,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 194688
    },
    {
      "epoch": 0.0007066775248413554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 194720
    },
    {
      "epoch": 0.0007067936591921921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 194752
    },
    {
      "epoch": 0.0007069097935430288,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 194784
    },
    {
      "epoch": 0.0007070259278938655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 194816
    },
    {
      "epoch": 0.0007071420622447022,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 194848
    },
    {
      "epoch": 0.0007072581965955389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6863,
      "step": 194880
    },
    {
      "epoch": 0.0007073743309463756,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 194912
    },
    {
      "epoch": 0.0007074904652972123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 194944
    },
    {
      "epoch": 0.000707606599648049,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6931,
      "step": 194976
    },
    {
      "epoch": 0.0007077227339988858,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 195008
    },
    {
      "epoch": 0.0007078388683497224,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.744,
      "step": 195040
    },
    {
      "epoch": 0.0007079550027005592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 195072
    },
    {
      "epoch": 0.0007080711370513958,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 195104
    },
    {
      "epoch": 0.0007081872714022326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 195136
    },
    {
      "epoch": 0.0007083034057530692,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7395,
      "step": 195168
    },
    {
      "epoch": 0.000708419540103906,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 195200
    },
    {
      "epoch": 0.0007085356744547426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7414,
      "step": 195232
    },
    {
      "epoch": 0.0007086518088055794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 195264
    },
    {
      "epoch": 0.0007087679431564162,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 195296
    },
    {
      "epoch": 0.0007088840775072528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7037,
      "step": 195328
    },
    {
      "epoch": 0.0007090002118580896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 195360
    },
    {
      "epoch": 0.0007091163462089262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 195392
    },
    {
      "epoch": 0.000709232480559763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 195424
    },
    {
      "epoch": 0.0007093486149105996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 195456
    },
    {
      "epoch": 0.0007094647492614364,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7493,
      "step": 195488
    },
    {
      "epoch": 0.000709580883612273,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7366,
      "step": 195520
    },
    {
      "epoch": 0.0007096970179631098,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6952,
      "step": 195552
    },
    {
      "epoch": 0.0007098131523139465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 195584
    },
    {
      "epoch": 0.0007099292866647832,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 195616
    },
    {
      "epoch": 0.0007100454210156199,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 195648
    },
    {
      "epoch": 0.0007101615553664566,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 195680
    },
    {
      "epoch": 0.0007102776897172933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 195712
    },
    {
      "epoch": 0.00071039382406813,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 195744
    },
    {
      "epoch": 0.0007105099584189667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 195776
    },
    {
      "epoch": 0.0007106260927698034,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 195808
    },
    {
      "epoch": 0.0007107422271206401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 195840
    },
    {
      "epoch": 0.0007108583614714769,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 195872
    },
    {
      "epoch": 0.0007109744958223135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 195904
    },
    {
      "epoch": 0.0007110906301731503,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7277,
      "step": 195936
    },
    {
      "epoch": 0.0007112067645239869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 195968
    },
    {
      "epoch": 0.0007113228988748237,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 196000
    },
    {
      "epoch": 0.0007114390332256603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7372,
      "step": 196032
    },
    {
      "epoch": 0.0007115551675764971,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 196064
    },
    {
      "epoch": 0.0007116713019273337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7459,
      "step": 196096
    },
    {
      "epoch": 0.0007117874362781705,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 196128
    },
    {
      "epoch": 0.0007119035706290072,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 196160
    },
    {
      "epoch": 0.0007120197049798439,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 196192
    },
    {
      "epoch": 0.0007121358393306806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 196224
    },
    {
      "epoch": 0.0007122519736815173,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 196256
    },
    {
      "epoch": 0.000712368108032354,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 196288
    },
    {
      "epoch": 0.0007124842423831907,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 196320
    },
    {
      "epoch": 0.0007126003767340274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7293,
      "step": 196352
    },
    {
      "epoch": 0.0007127165110848641,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7374,
      "step": 196384
    },
    {
      "epoch": 0.0007128326454357008,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 196416
    },
    {
      "epoch": 0.0007129487797865376,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7036,
      "step": 196448
    },
    {
      "epoch": 0.0007130649141373742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 196480
    },
    {
      "epoch": 0.000713181048488211,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 196512
    },
    {
      "epoch": 0.0007132971828390476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6959,
      "step": 196544
    },
    {
      "epoch": 0.0007134133171898844,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6886,
      "step": 196576
    },
    {
      "epoch": 0.000713529451540721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 196608
    },
    {
      "epoch": 0.0007136455858915578,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 196640
    },
    {
      "epoch": 0.0007137617202423944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 196672
    },
    {
      "epoch": 0.0007138778545932312,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 196704
    },
    {
      "epoch": 0.0007139939889440679,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 196736
    },
    {
      "epoch": 0.0007141101232949046,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 196768
    },
    {
      "epoch": 0.0007142262576457413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7402,
      "step": 196800
    },
    {
      "epoch": 0.000714342391996578,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 196832
    },
    {
      "epoch": 0.0007144585263474147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 196864
    },
    {
      "epoch": 0.0007145746606982514,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 196896
    },
    {
      "epoch": 0.0007146907950490881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 196928
    },
    {
      "epoch": 0.0007148069293999248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 196960
    },
    {
      "epoch": 0.0007149230637507615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 196992
    },
    {
      "epoch": 0.0007150391981015983,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 197024
    },
    {
      "epoch": 0.0007151553324524349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 197056
    },
    {
      "epoch": 0.0007152714668032717,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 197088
    },
    {
      "epoch": 0.0007153876011541083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 197120
    },
    {
      "epoch": 0.0007155037355049451,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 197152
    },
    {
      "epoch": 0.0007156198698557817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 197184
    },
    {
      "epoch": 0.0007157360042066185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7347,
      "step": 197216
    },
    {
      "epoch": 0.0007158521385574551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 197248
    },
    {
      "epoch": 0.0007159682729082919,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 197280
    },
    {
      "epoch": 0.0007160844072591286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 197312
    },
    {
      "epoch": 0.0007162005416099653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 197344
    },
    {
      "epoch": 0.000716316675960802,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 197376
    },
    {
      "epoch": 0.0007164328103116387,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 197408
    },
    {
      "epoch": 0.0007165489446624754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 197440
    },
    {
      "epoch": 0.0007166650790133121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6952,
      "step": 197472
    },
    {
      "epoch": 0.0007167812133641488,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 197504
    },
    {
      "epoch": 0.0007168973477149855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 197536
    },
    {
      "epoch": 0.0007170134820658222,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7304,
      "step": 197568
    },
    {
      "epoch": 0.000717129616416659,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 197600
    },
    {
      "epoch": 0.0007172457507674956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 197632
    },
    {
      "epoch": 0.0007173618851183324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7342,
      "step": 197664
    },
    {
      "epoch": 0.000717478019469169,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7301,
      "step": 197696
    },
    {
      "epoch": 0.0007175941538200058,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 197728
    },
    {
      "epoch": 0.0007177102881708424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 197760
    },
    {
      "epoch": 0.0007178264225216792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7333,
      "step": 197792
    },
    {
      "epoch": 0.0007179425568725158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7337,
      "step": 197824
    },
    {
      "epoch": 0.0007180586912233526,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 197856
    },
    {
      "epoch": 0.0007181748255741893,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 197888
    },
    {
      "epoch": 0.000718290959925026,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7107,
      "step": 197920
    },
    {
      "epoch": 0.0007184070942758627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 197952
    },
    {
      "epoch": 0.0007185232286266994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 197984
    },
    {
      "epoch": 0.0007186393629775361,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 198016
    },
    {
      "epoch": 0.0007187554973283728,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 198048
    },
    {
      "epoch": 0.0007188716316792095,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 198080
    },
    {
      "epoch": 0.0007189877660300462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 198112
    },
    {
      "epoch": 0.0007191039003808829,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7333,
      "step": 198144
    },
    {
      "epoch": 0.0007192200347317197,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 198176
    },
    {
      "epoch": 0.0007193361690825563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 198208
    },
    {
      "epoch": 0.0007194523034333931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 198240
    },
    {
      "epoch": 0.0007195684377842297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6962,
      "step": 198272
    },
    {
      "epoch": 0.0007196845721350665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6832,
      "step": 198304
    },
    {
      "epoch": 0.0007198007064859031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6934,
      "step": 198336
    },
    {
      "epoch": 0.0007199168408367399,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 198368
    },
    {
      "epoch": 0.0007200329751875765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 198400
    },
    {
      "epoch": 0.0007201491095384133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 198432
    },
    {
      "epoch": 0.00072026524388925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7427,
      "step": 198464
    },
    {
      "epoch": 0.0007203813782400867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 198496
    },
    {
      "epoch": 0.0007204975125909234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 198528
    },
    {
      "epoch": 0.0007206136469417601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7488,
      "step": 198560
    },
    {
      "epoch": 0.0007207297812925968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 198592
    },
    {
      "epoch": 0.0007208459156434335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 198624
    },
    {
      "epoch": 0.0007209620499942702,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7325,
      "step": 198656
    },
    {
      "epoch": 0.0007210781843451069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 198688
    },
    {
      "epoch": 0.0007211943186959436,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7056,
      "step": 198720
    },
    {
      "epoch": 0.0007213104530467804,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 198752
    },
    {
      "epoch": 0.000721426587397617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 198784
    },
    {
      "epoch": 0.0007215427217484538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 198816
    },
    {
      "epoch": 0.0007216588560992904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7056,
      "step": 198848
    },
    {
      "epoch": 0.0007217749904501272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 198880
    },
    {
      "epoch": 0.0007218911248009638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 198912
    },
    {
      "epoch": 0.0007220072591518006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 198944
    },
    {
      "epoch": 0.0007221233935026372,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 198976
    },
    {
      "epoch": 0.000722239527853474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 199008
    },
    {
      "epoch": 0.0007223556622043107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 199040
    },
    {
      "epoch": 0.0007224717965551474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 199072
    },
    {
      "epoch": 0.0007225879309059841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 199104
    },
    {
      "epoch": 0.0007227040652568208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 199136
    },
    {
      "epoch": 0.0007228201996076575,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6912,
      "step": 199168
    },
    {
      "epoch": 0.0007229363339584942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 199200
    },
    {
      "epoch": 0.0007230524683093309,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 199232
    },
    {
      "epoch": 0.0007231686026601676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 199264
    },
    {
      "epoch": 0.0007232847370110043,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 199296
    },
    {
      "epoch": 0.000723400871361841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 199328
    },
    {
      "epoch": 0.0007235170057126777,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 199360
    },
    {
      "epoch": 0.0007236331400635145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 199392
    },
    {
      "epoch": 0.0007237492744143511,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7365,
      "step": 199424
    },
    {
      "epoch": 0.0007238654087651879,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 199456
    },
    {
      "epoch": 0.0007239815431160245,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 199488
    },
    {
      "epoch": 0.0007240976774668613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 199520
    },
    {
      "epoch": 0.0007242138118176979,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7347,
      "step": 199552
    },
    {
      "epoch": 0.0007243299461685347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 199584
    },
    {
      "epoch": 0.0007244460805193713,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7177,
      "step": 199616
    },
    {
      "epoch": 0.0007245622148702081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 199648
    },
    {
      "epoch": 0.0007246783492210449,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 199680
    },
    {
      "epoch": 0.0007247944835718815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 199712
    },
    {
      "epoch": 0.0007249106179227183,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 199744
    },
    {
      "epoch": 0.0007250267522735549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 199776
    },
    {
      "epoch": 0.0007251428866243917,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 199808
    },
    {
      "epoch": 0.0007252590209752283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 199840
    },
    {
      "epoch": 0.000725375155326065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 199872
    },
    {
      "epoch": 0.0007254912896769017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 199904
    },
    {
      "epoch": 0.0007256074240277385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 199936
    },
    {
      "epoch": 0.0007257235583785752,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 199968
    },
    {
      "epoch": 0.0007258396927294119,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 200000
    },
    {
      "epoch": 0.0007259558270802486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 200032
    },
    {
      "epoch": 0.0007260719614310853,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6853,
      "step": 200064
    },
    {
      "epoch": 0.000726188095781922,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 200096
    },
    {
      "epoch": 0.0007263042301327587,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 200128
    },
    {
      "epoch": 0.0007264203644835954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 200160
    },
    {
      "epoch": 0.000726536498834432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 200192
    },
    {
      "epoch": 0.0007266526331852688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 200224
    },
    {
      "epoch": 0.0007267687675361056,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 200256
    },
    {
      "epoch": 0.0007268849018869422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 200288
    },
    {
      "epoch": 0.000727001036237779,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7461,
      "step": 200320
    },
    {
      "epoch": 0.0007271171705886156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 200352
    },
    {
      "epoch": 0.0007272333049394524,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 200384
    },
    {
      "epoch": 0.000727349439290289,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 200416
    },
    {
      "epoch": 0.0007274655736411258,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 200448
    },
    {
      "epoch": 0.0007275817079919624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 200480
    },
    {
      "epoch": 0.0007276978423427992,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 200512
    },
    {
      "epoch": 0.0007278139766936359,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 200544
    },
    {
      "epoch": 0.0007279301110444726,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 200576
    },
    {
      "epoch": 0.0007280462453953093,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 200608
    },
    {
      "epoch": 0.000728162379746146,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 200640
    },
    {
      "epoch": 0.0007282785140969827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 200672
    },
    {
      "epoch": 0.0007283946484478194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 200704
    },
    {
      "epoch": 0.0007285107827986561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 200736
    },
    {
      "epoch": 0.0007286269171494928,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 200768
    },
    {
      "epoch": 0.0007287430515003295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 200800
    },
    {
      "epoch": 0.0007288591858511663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 200832
    },
    {
      "epoch": 0.0007289753202020029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 200864
    },
    {
      "epoch": 0.0007290914545528397,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 200896
    },
    {
      "epoch": 0.0007292075889036763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 200928
    },
    {
      "epoch": 0.0007293237232545131,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 200960
    },
    {
      "epoch": 0.0007294398576053497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 200992
    },
    {
      "epoch": 0.0007295559919561865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 201024
    },
    {
      "epoch": 0.0007296721263070231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7304,
      "step": 201056
    },
    {
      "epoch": 0.0007297882606578599,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7399,
      "step": 201088
    },
    {
      "epoch": 0.0007299043950086966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.741,
      "step": 201120
    },
    {
      "epoch": 0.0007300205293595333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 201152
    },
    {
      "epoch": 0.00073013666371037,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7554,
      "step": 201184
    },
    {
      "epoch": 0.0007302527980612067,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 201216
    },
    {
      "epoch": 0.0007303689324120434,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 201248
    },
    {
      "epoch": 0.0007304850667628801,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 201280
    },
    {
      "epoch": 0.0007306012011137168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 201312
    },
    {
      "epoch": 0.0007307173354645535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 201344
    },
    {
      "epoch": 0.0007308334698153902,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 201376
    },
    {
      "epoch": 0.000730949604166227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 201408
    },
    {
      "epoch": 0.0007310657385170636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 201440
    },
    {
      "epoch": 0.0007311818728679004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 201472
    },
    {
      "epoch": 0.000731298007218737,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 201504
    },
    {
      "epoch": 0.0007314141415695738,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 201536
    },
    {
      "epoch": 0.0007315302759204104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 201568
    },
    {
      "epoch": 0.0007316464102712472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 201600
    },
    {
      "epoch": 0.0007317625446220838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 201632
    },
    {
      "epoch": 0.0007318786789729206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 201664
    },
    {
      "epoch": 0.0007319948133237573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 201696
    },
    {
      "epoch": 0.000732110947674594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 201728
    },
    {
      "epoch": 0.0007322270820254307,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 201760
    },
    {
      "epoch": 0.0007323432163762674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 201792
    },
    {
      "epoch": 0.0007324593507271041,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6886,
      "step": 201824
    },
    {
      "epoch": 0.0007325754850779408,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 201856
    },
    {
      "epoch": 0.0007326916194287775,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 201888
    },
    {
      "epoch": 0.0007328077537796142,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7309,
      "step": 201920
    },
    {
      "epoch": 0.0007329238881304509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 201952
    },
    {
      "epoch": 0.0007330400224812877,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7487,
      "step": 201984
    },
    {
      "epoch": 0.0007331561568321243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 202016
    },
    {
      "epoch": 0.0007332722911829611,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7385,
      "step": 202048
    },
    {
      "epoch": 0.0007333884255337977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7378,
      "step": 202080
    },
    {
      "epoch": 0.0007335045598846345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 202112
    },
    {
      "epoch": 0.0007336206942354711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 202144
    },
    {
      "epoch": 0.0007337368285863079,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 202176
    },
    {
      "epoch": 0.0007338529629371445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 202208
    },
    {
      "epoch": 0.0007339690972879813,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 202240
    },
    {
      "epoch": 0.000734085231638818,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 202272
    },
    {
      "epoch": 0.0007342013659896547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7363,
      "step": 202304
    },
    {
      "epoch": 0.0007343175003404914,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 202336
    },
    {
      "epoch": 0.0007344336346913281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 202368
    },
    {
      "epoch": 0.0007345497690421648,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 202400
    },
    {
      "epoch": 0.0007346659033930015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 202432
    },
    {
      "epoch": 0.0007347820377438382,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 202464
    },
    {
      "epoch": 0.0007348981720946749,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 202496
    },
    {
      "epoch": 0.0007350143064455116,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 202528
    },
    {
      "epoch": 0.0007351304407963484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 202560
    },
    {
      "epoch": 0.000735246575147185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 202592
    },
    {
      "epoch": 0.0007353627094980218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 202624
    },
    {
      "epoch": 0.0007354788438488584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 202656
    },
    {
      "epoch": 0.0007355949781996952,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6896,
      "step": 202688
    },
    {
      "epoch": 0.0007357111125505318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 202720
    },
    {
      "epoch": 0.0007358272469013686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 202752
    },
    {
      "epoch": 0.0007359433812522052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 202784
    },
    {
      "epoch": 0.000736059515603042,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 202816
    },
    {
      "epoch": 0.0007361756499538787,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 202848
    },
    {
      "epoch": 0.0007362917843047154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7504,
      "step": 202880
    },
    {
      "epoch": 0.0007364079186555521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7286,
      "step": 202912
    },
    {
      "epoch": 0.0007365240530063888,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7493,
      "step": 202944
    },
    {
      "epoch": 0.0007366401873572255,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 202976
    },
    {
      "epoch": 0.0007367563217080622,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 203008
    },
    {
      "epoch": 0.0007368724560588989,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 203040
    },
    {
      "epoch": 0.0007369885904097356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 203072
    },
    {
      "epoch": 0.0007371047247605723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 203104
    },
    {
      "epoch": 0.0007372208591114091,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 203136
    },
    {
      "epoch": 0.0007373369934622457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 203168
    },
    {
      "epoch": 0.0007374531278130825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 203200
    },
    {
      "epoch": 0.0007375692621639191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 203232
    },
    {
      "epoch": 0.0007376853965147559,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 203264
    },
    {
      "epoch": 0.0007378015308655925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 203296
    },
    {
      "epoch": 0.0007379176652164293,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 203328
    },
    {
      "epoch": 0.0007380337995672659,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 203360
    },
    {
      "epoch": 0.0007381499339181027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 203392
    },
    {
      "epoch": 0.0007382660682689394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7153,
      "step": 203424
    },
    {
      "epoch": 0.0007383822026197761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 203456
    },
    {
      "epoch": 0.0007384983369706128,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 203488
    },
    {
      "epoch": 0.0007386144713214495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 203520
    },
    {
      "epoch": 0.0007387306056722862,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.693,
      "step": 203552
    },
    {
      "epoch": 0.0007388467400231229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 203584
    },
    {
      "epoch": 0.0007389628743739596,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 203616
    },
    {
      "epoch": 0.0007390790087247963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 203648
    },
    {
      "epoch": 0.000739195143075633,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7359,
      "step": 203680
    },
    {
      "epoch": 0.0007393112774264698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 203712
    },
    {
      "epoch": 0.0007394274117773064,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7502,
      "step": 203744
    },
    {
      "epoch": 0.0007395435461281432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 203776
    },
    {
      "epoch": 0.0007396596804789798,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7503,
      "step": 203808
    },
    {
      "epoch": 0.0007397758148298166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7356,
      "step": 203840
    },
    {
      "epoch": 0.0007398919491806532,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 203872
    },
    {
      "epoch": 0.00074000808353149,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 203904
    },
    {
      "epoch": 0.0007401242178823266,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 203936
    },
    {
      "epoch": 0.0007402403522331634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 203968
    },
    {
      "epoch": 0.0007403564865840002,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 204000
    },
    {
      "epoch": 0.0007404726209348368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 204032
    },
    {
      "epoch": 0.0007405887552856736,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 204064
    },
    {
      "epoch": 0.0007407048896365102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 204096
    },
    {
      "epoch": 0.000740821023987347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 204128
    },
    {
      "epoch": 0.0007409371583381836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 204160
    },
    {
      "epoch": 0.0007410532926890204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.695,
      "step": 204192
    },
    {
      "epoch": 0.000741169427039857,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 204224
    },
    {
      "epoch": 0.0007412855613906938,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7237,
      "step": 204256
    },
    {
      "epoch": 0.0007414016957415305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7322,
      "step": 204288
    },
    {
      "epoch": 0.0007415178300923672,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 204320
    },
    {
      "epoch": 0.0007416339644432039,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 204352
    },
    {
      "epoch": 0.0007417500987940406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 204384
    },
    {
      "epoch": 0.0007418662331448773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 204416
    },
    {
      "epoch": 0.000741982367495714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 204448
    },
    {
      "epoch": 0.0007420985018465507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 204480
    },
    {
      "epoch": 0.0007422146361973874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 204512
    },
    {
      "epoch": 0.0007423307705482241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 204544
    },
    {
      "epoch": 0.0007424469048990609,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 204576
    },
    {
      "epoch": 0.0007425630392498975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7457,
      "step": 204608
    },
    {
      "epoch": 0.0007426791736007343,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 204640
    },
    {
      "epoch": 0.0007427953079515709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.745,
      "step": 204672
    },
    {
      "epoch": 0.0007429114423024077,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7441,
      "step": 204704
    },
    {
      "epoch": 0.0007430275766532443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 204736
    },
    {
      "epoch": 0.0007431437110040811,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6911,
      "step": 204768
    },
    {
      "epoch": 0.0007432598453549177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 204800
    },
    {
      "epoch": 0.0007433759797057545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 204832
    },
    {
      "epoch": 0.0007434921140565912,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 204864
    },
    {
      "epoch": 0.0007436082484074279,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 204896
    },
    {
      "epoch": 0.0007437243827582646,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 204928
    },
    {
      "epoch": 0.0007438405171091013,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 204960
    },
    {
      "epoch": 0.000743956651459938,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 204992
    },
    {
      "epoch": 0.0007440727858107747,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 205024
    },
    {
      "epoch": 0.0007441889201616114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 205056
    },
    {
      "epoch": 0.0007443050545124481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 205088
    },
    {
      "epoch": 0.0007444211888632848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 205120
    },
    {
      "epoch": 0.0007445373232141216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 205152
    },
    {
      "epoch": 0.0007446534575649582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 205184
    },
    {
      "epoch": 0.000744769591915795,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 205216
    },
    {
      "epoch": 0.0007448857262666316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 205248
    },
    {
      "epoch": 0.0007450018606174684,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 205280
    },
    {
      "epoch": 0.000745117994968305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 205312
    },
    {
      "epoch": 0.0007452341293191418,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 205344
    },
    {
      "epoch": 0.0007453502636699784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 205376
    },
    {
      "epoch": 0.0007454663980208152,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 205408
    },
    {
      "epoch": 0.0007455825323716519,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7331,
      "step": 205440
    },
    {
      "epoch": 0.0007456986667224886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7433,
      "step": 205472
    },
    {
      "epoch": 0.0007458148010733253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 205504
    },
    {
      "epoch": 0.000745930935424162,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 205536
    },
    {
      "epoch": 0.0007460470697749987,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.736,
      "step": 205568
    },
    {
      "epoch": 0.0007461632041258354,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 205600
    },
    {
      "epoch": 0.0007462793384766721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 205632
    },
    {
      "epoch": 0.0007463954728275088,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 205664
    },
    {
      "epoch": 0.0007465116071783455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 205696
    },
    {
      "epoch": 0.0007466277415291823,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 205728
    },
    {
      "epoch": 0.0007467438758800189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7019,
      "step": 205760
    },
    {
      "epoch": 0.0007468600102308557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 205792
    },
    {
      "epoch": 0.0007469761445816923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.737,
      "step": 205824
    },
    {
      "epoch": 0.0007470922789325291,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 205856
    },
    {
      "epoch": 0.0007472084132833657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 205888
    },
    {
      "epoch": 0.0007473245476342025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 205920
    },
    {
      "epoch": 0.0007474406819850391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6954,
      "step": 205952
    },
    {
      "epoch": 0.0007475568163358759,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 205984
    },
    {
      "epoch": 0.0007476729506867126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 206016
    },
    {
      "epoch": 0.0007477890850375493,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 206048
    },
    {
      "epoch": 0.000747905219388386,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 206080
    },
    {
      "epoch": 0.0007480213537392227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 206112
    },
    {
      "epoch": 0.0007481374880900594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 206144
    },
    {
      "epoch": 0.0007482536224408961,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 206176
    },
    {
      "epoch": 0.0007483697567917328,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 206208
    },
    {
      "epoch": 0.0007484858911425695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 206240
    },
    {
      "epoch": 0.0007486020254934062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 206272
    },
    {
      "epoch": 0.000748718159844243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7346,
      "step": 206304
    },
    {
      "epoch": 0.0007488342941950796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 206336
    },
    {
      "epoch": 0.0007489504285459164,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7351,
      "step": 206368
    },
    {
      "epoch": 0.000749066562896753,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7514,
      "step": 206400
    },
    {
      "epoch": 0.0007491826972475898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7443,
      "step": 206432
    },
    {
      "epoch": 0.0007492988315984264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 206464
    },
    {
      "epoch": 0.0007494149659492632,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 206496
    },
    {
      "epoch": 0.0007495311003000998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6905,
      "step": 206528
    },
    {
      "epoch": 0.0007496472346509366,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 206560
    },
    {
      "epoch": 0.0007497633690017733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 206592
    },
    {
      "epoch": 0.00074987950335261,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 206624
    },
    {
      "epoch": 0.0007499956377034467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 206656
    },
    {
      "epoch": 0.0007501117720542834,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.731,
      "step": 206688
    },
    {
      "epoch": 0.0007502279064051201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 206720
    },
    {
      "epoch": 0.0007503440407559568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 206752
    },
    {
      "epoch": 0.0007504601751067935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 206784
    },
    {
      "epoch": 0.0007505763094576302,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 206816
    },
    {
      "epoch": 0.0007506924438084669,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 206848
    },
    {
      "epoch": 0.0007508085781593037,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 206880
    },
    {
      "epoch": 0.0007509247125101403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7402,
      "step": 206912
    },
    {
      "epoch": 0.0007510408468609771,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 206944
    },
    {
      "epoch": 0.0007511569812118137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 206976
    },
    {
      "epoch": 0.0007512731155626505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 207008
    },
    {
      "epoch": 0.0007513892499134871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 207040
    },
    {
      "epoch": 0.0007515053842643239,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 207072
    },
    {
      "epoch": 0.0007516215186151605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 207104
    },
    {
      "epoch": 0.0007517376529659973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 207136
    },
    {
      "epoch": 0.000751853787316834,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 207168
    },
    {
      "epoch": 0.0007519699216676707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 207200
    },
    {
      "epoch": 0.0007520860560185074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7391,
      "step": 207232
    },
    {
      "epoch": 0.0007522021903693441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7399,
      "step": 207264
    },
    {
      "epoch": 0.0007523183247201808,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 207296
    },
    {
      "epoch": 0.0007524344590710175,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 207328
    },
    {
      "epoch": 0.0007525505934218542,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 207360
    },
    {
      "epoch": 0.0007526667277726909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 207392
    },
    {
      "epoch": 0.0007527828621235276,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 207424
    },
    {
      "epoch": 0.0007528989964743644,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 207456
    },
    {
      "epoch": 0.000753015130825201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 207488
    },
    {
      "epoch": 0.0007531312651760378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 207520
    },
    {
      "epoch": 0.0007532473995268744,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 207552
    },
    {
      "epoch": 0.0007533635338777112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7418,
      "step": 207584
    },
    {
      "epoch": 0.0007534796682285478,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 207616
    },
    {
      "epoch": 0.0007535958025793846,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 207648
    },
    {
      "epoch": 0.0007537119369302212,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 207680
    },
    {
      "epoch": 0.000753828071281058,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 207712
    },
    {
      "epoch": 0.0007539442056318947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 207744
    },
    {
      "epoch": 0.0007540603399827314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7277,
      "step": 207776
    },
    {
      "epoch": 0.0007541764743335681,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 207808
    },
    {
      "epoch": 0.0007542926086844048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 207840
    },
    {
      "epoch": 0.0007544087430352415,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 207872
    },
    {
      "epoch": 0.0007545248773860782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 207904
    },
    {
      "epoch": 0.000754641011736915,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 207936
    },
    {
      "epoch": 0.0007547571460877516,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 207968
    },
    {
      "epoch": 0.0007548732804385883,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 208000
    },
    {
      "epoch": 0.0007549894147894251,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7401,
      "step": 208032
    },
    {
      "epoch": 0.0007551055491402617,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 208064
    },
    {
      "epoch": 0.0007552216834910985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 208096
    },
    {
      "epoch": 0.0007553378178419351,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7291,
      "step": 208128
    },
    {
      "epoch": 0.0007554539521927719,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 208160
    },
    {
      "epoch": 0.0007555700865436085,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7403,
      "step": 208192
    },
    {
      "epoch": 0.0007556862208944453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 208224
    },
    {
      "epoch": 0.000755802355245282,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 208256
    },
    {
      "epoch": 0.0007559184895961187,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.699,
      "step": 208288
    },
    {
      "epoch": 0.0007560346239469555,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 208320
    },
    {
      "epoch": 0.0007561507582977921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 208352
    },
    {
      "epoch": 0.0007562668926486289,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 208384
    },
    {
      "epoch": 0.0007563830269994655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 208416
    },
    {
      "epoch": 0.0007564991613503023,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7331,
      "step": 208448
    },
    {
      "epoch": 0.0007566152957011389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 208480
    },
    {
      "epoch": 0.0007567314300519757,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 208512
    },
    {
      "epoch": 0.0007568475644028123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 208544
    },
    {
      "epoch": 0.0007569636987536491,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 208576
    },
    {
      "epoch": 0.0007570798331044858,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 208608
    },
    {
      "epoch": 0.0007571959674553225,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 208640
    },
    {
      "epoch": 0.0007573121018061592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 208672
    },
    {
      "epoch": 0.0007574282361569959,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 208704
    },
    {
      "epoch": 0.0007575443705078326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 208736
    },
    {
      "epoch": 0.0007576605048586693,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7489,
      "step": 208768
    },
    {
      "epoch": 0.000757776639209506,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 208800
    },
    {
      "epoch": 0.0007578927735603427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 208832
    },
    {
      "epoch": 0.0007580089079111794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 208864
    },
    {
      "epoch": 0.0007581250422620162,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 208896
    },
    {
      "epoch": 0.0007582411766128528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 208928
    },
    {
      "epoch": 0.0007583573109636896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 208960
    },
    {
      "epoch": 0.0007584734453145262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7444,
      "step": 208992
    },
    {
      "epoch": 0.000758589579665363,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 209024
    },
    {
      "epoch": 0.0007587057140161996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 209056
    },
    {
      "epoch": 0.0007588218483670364,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 209088
    },
    {
      "epoch": 0.000758937982717873,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 209120
    },
    {
      "epoch": 0.0007590541170687098,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6962,
      "step": 209152
    },
    {
      "epoch": 0.0007591702514195465,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 209184
    },
    {
      "epoch": 0.0007592863857703832,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 209216
    },
    {
      "epoch": 0.0007594025201212199,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 209248
    },
    {
      "epoch": 0.0007595186544720566,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 209280
    },
    {
      "epoch": 0.0007596347888228933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 209312
    },
    {
      "epoch": 0.00075975092317373,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7372,
      "step": 209344
    },
    {
      "epoch": 0.0007598670575245667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 209376
    },
    {
      "epoch": 0.0007599831918754034,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 209408
    },
    {
      "epoch": 0.0007600993262262401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 209440
    },
    {
      "epoch": 0.0007602154605770769,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 209472
    },
    {
      "epoch": 0.0007603315949279135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 209504
    },
    {
      "epoch": 0.0007604477292787503,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.732,
      "step": 209536
    },
    {
      "epoch": 0.0007605638636295869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 209568
    },
    {
      "epoch": 0.0007606799979804237,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 209600
    },
    {
      "epoch": 0.0007607961323312603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7448,
      "step": 209632
    },
    {
      "epoch": 0.0007609122666820971,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 209664
    },
    {
      "epoch": 0.0007610284010329337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 209696
    },
    {
      "epoch": 0.0007611445353837705,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 209728
    },
    {
      "epoch": 0.0007612606697346072,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 209760
    },
    {
      "epoch": 0.0007613768040854439,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 209792
    },
    {
      "epoch": 0.0007614929384362806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7405,
      "step": 209824
    },
    {
      "epoch": 0.0007616090727871173,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7357,
      "step": 209856
    },
    {
      "epoch": 0.000761725207137954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 209888
    },
    {
      "epoch": 0.0007618413414887907,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 209920
    },
    {
      "epoch": 0.0007619574758396274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7416,
      "step": 209952
    },
    {
      "epoch": 0.0007620736101904641,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 209984
    },
    {
      "epoch": 0.0007621897445413008,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 210016
    },
    {
      "epoch": 0.0007623058788921375,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6962,
      "step": 210048
    },
    {
      "epoch": 0.0007624220132429742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 210080
    },
    {
      "epoch": 0.000762538147593811,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 210112
    },
    {
      "epoch": 0.0007626542819446476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 210144
    },
    {
      "epoch": 0.0007627704162954844,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 210176
    },
    {
      "epoch": 0.000762886550646321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 210208
    },
    {
      "epoch": 0.0007630026849971578,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 210240
    },
    {
      "epoch": 0.0007631188193479944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 210272
    },
    {
      "epoch": 0.0007632349536988312,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 210304
    },
    {
      "epoch": 0.0007633510880496678,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 210336
    },
    {
      "epoch": 0.0007634672224005046,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 210368
    },
    {
      "epoch": 0.0007635833567513413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7288,
      "step": 210400
    },
    {
      "epoch": 0.000763699491102178,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.733,
      "step": 210432
    },
    {
      "epoch": 0.0007638156254530147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 210464
    },
    {
      "epoch": 0.0007639317598038514,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 210496
    },
    {
      "epoch": 0.0007640478941546881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7442,
      "step": 210528
    },
    {
      "epoch": 0.0007641640285055248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7291,
      "step": 210560
    },
    {
      "epoch": 0.0007642801628563615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 210592
    },
    {
      "epoch": 0.0007643962972071982,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 210624
    },
    {
      "epoch": 0.0007645124315580349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 210656
    },
    {
      "epoch": 0.0007646285659088717,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7411,
      "step": 210688
    },
    {
      "epoch": 0.0007647447002597083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 210720
    },
    {
      "epoch": 0.0007648608346105451,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 210752
    },
    {
      "epoch": 0.0007649769689613817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 210784
    },
    {
      "epoch": 0.0007650931033122185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7344,
      "step": 210816
    },
    {
      "epoch": 0.0007652092376630551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 210848
    },
    {
      "epoch": 0.0007653253720138919,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 210880
    },
    {
      "epoch": 0.0007654415063647285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6977,
      "step": 210912
    },
    {
      "epoch": 0.0007655576407155653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 210944
    },
    {
      "epoch": 0.000765673775066402,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 210976
    },
    {
      "epoch": 0.0007657899094172387,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 211008
    },
    {
      "epoch": 0.0007659060437680754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 211040
    },
    {
      "epoch": 0.0007660221781189121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 211072
    },
    {
      "epoch": 0.0007661383124697488,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 211104
    },
    {
      "epoch": 0.0007662544468205855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7312,
      "step": 211136
    },
    {
      "epoch": 0.0007663705811714222,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 211168
    },
    {
      "epoch": 0.0007664867155222589,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 211200
    },
    {
      "epoch": 0.0007666028498730956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 211232
    },
    {
      "epoch": 0.0007667189842239324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 211264
    },
    {
      "epoch": 0.000766835118574769,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 211296
    },
    {
      "epoch": 0.0007669512529256058,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7293,
      "step": 211328
    },
    {
      "epoch": 0.0007670673872764424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 211360
    },
    {
      "epoch": 0.0007671835216272792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7427,
      "step": 211392
    },
    {
      "epoch": 0.0007672996559781158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 211424
    },
    {
      "epoch": 0.0007674157903289526,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 211456
    },
    {
      "epoch": 0.0007675319246797892,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 211488
    },
    {
      "epoch": 0.000767648059030626,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 211520
    },
    {
      "epoch": 0.0007677641933814627,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7418,
      "step": 211552
    },
    {
      "epoch": 0.0007678803277322994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 211584
    },
    {
      "epoch": 0.0007679964620831361,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 211616
    },
    {
      "epoch": 0.0007681125964339728,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 211648
    },
    {
      "epoch": 0.0007682287307848095,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 211680
    },
    {
      "epoch": 0.0007683448651356462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7479,
      "step": 211712
    },
    {
      "epoch": 0.0007684609994864829,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 211744
    },
    {
      "epoch": 0.0007685771338373196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.694,
      "step": 211776
    },
    {
      "epoch": 0.0007686932681881563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 211808
    },
    {
      "epoch": 0.0007688094025389931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 211840
    },
    {
      "epoch": 0.0007689255368898297,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 211872
    },
    {
      "epoch": 0.0007690416712406665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7076,
      "step": 211904
    },
    {
      "epoch": 0.0007691578055915031,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 211936
    },
    {
      "epoch": 0.0007692739399423399,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 211968
    },
    {
      "epoch": 0.0007693900742931765,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 212000
    },
    {
      "epoch": 0.0007695062086440133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 212032
    },
    {
      "epoch": 0.0007696223429948499,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 212064
    },
    {
      "epoch": 0.0007697384773456867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7102,
      "step": 212096
    },
    {
      "epoch": 0.0007698546116965234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 212128
    },
    {
      "epoch": 0.0007699707460473601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7489,
      "step": 212160
    },
    {
      "epoch": 0.0007700868803981968,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 212192
    },
    {
      "epoch": 0.0007702030147490335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 212224
    },
    {
      "epoch": 0.0007703191490998702,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 212256
    },
    {
      "epoch": 0.0007704352834507069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7396,
      "step": 212288
    },
    {
      "epoch": 0.0007705514178015436,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7355,
      "step": 212320
    },
    {
      "epoch": 0.0007706675521523803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 212352
    },
    {
      "epoch": 0.000770783686503217,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 212384
    },
    {
      "epoch": 0.0007708998208540538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 212416
    },
    {
      "epoch": 0.0007710159552048904,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 212448
    },
    {
      "epoch": 0.0007711320895557272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 212480
    },
    {
      "epoch": 0.0007712482239065638,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 212512
    },
    {
      "epoch": 0.0007713643582574006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 212544
    },
    {
      "epoch": 0.0007714804926082372,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7407,
      "step": 212576
    },
    {
      "epoch": 0.000771596626959074,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 212608
    },
    {
      "epoch": 0.0007717127613099106,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6973,
      "step": 212640
    },
    {
      "epoch": 0.0007718288956607474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 212672
    },
    {
      "epoch": 0.0007719450300115842,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 212704
    },
    {
      "epoch": 0.0007720611643624208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 212736
    },
    {
      "epoch": 0.0007721772987132576,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 212768
    },
    {
      "epoch": 0.0007722934330640942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 212800
    },
    {
      "epoch": 0.000772409567414931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 212832
    },
    {
      "epoch": 0.0007725257017657676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7228,
      "step": 212864
    },
    {
      "epoch": 0.0007726418361166044,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7374,
      "step": 212896
    },
    {
      "epoch": 0.000772757970467441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 212928
    },
    {
      "epoch": 0.0007728741048182778,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 212960
    },
    {
      "epoch": 0.0007729902391691145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 212992
    },
    {
      "epoch": 0.0007731063735199512,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 213024
    },
    {
      "epoch": 0.0007732225078707879,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7344,
      "step": 213056
    },
    {
      "epoch": 0.0007733386422216246,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7266,
      "step": 213088
    },
    {
      "epoch": 0.0007734547765724613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 213120
    },
    {
      "epoch": 0.000773570910923298,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7403,
      "step": 213152
    },
    {
      "epoch": 0.0007736870452741347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 213184
    },
    {
      "epoch": 0.0007738031796249714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 213216
    },
    {
      "epoch": 0.0007739193139758081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 213248
    },
    {
      "epoch": 0.0007740354483266449,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 213280
    },
    {
      "epoch": 0.0007741515826774815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 213312
    },
    {
      "epoch": 0.0007742677170283183,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6925,
      "step": 213344
    },
    {
      "epoch": 0.0007743838513791549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7076,
      "step": 213376
    },
    {
      "epoch": 0.0007744999857299917,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 213408
    },
    {
      "epoch": 0.0007746161200808283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7245,
      "step": 213440
    },
    {
      "epoch": 0.0007747322544316651,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 213472
    },
    {
      "epoch": 0.0007748483887825017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 213504
    },
    {
      "epoch": 0.0007749645231333385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6879,
      "step": 213536
    },
    {
      "epoch": 0.0007750806574841752,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6931,
      "step": 213568
    },
    {
      "epoch": 0.0007751967918350119,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 213600
    },
    {
      "epoch": 0.0007753129261858486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 213632
    },
    {
      "epoch": 0.0007754290605366853,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 213664
    },
    {
      "epoch": 0.000775545194887522,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 213696
    },
    {
      "epoch": 0.0007756613292383587,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7168,
      "step": 213728
    },
    {
      "epoch": 0.0007757774635891954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 213760
    },
    {
      "epoch": 0.0007758935979400321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6931,
      "step": 213792
    },
    {
      "epoch": 0.0007760097322908688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 213824
    },
    {
      "epoch": 0.0007761258666417056,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 213856
    },
    {
      "epoch": 0.0007762420009925422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 213888
    },
    {
      "epoch": 0.000776358135343379,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.764,
      "step": 213920
    },
    {
      "epoch": 0.0007764742696942156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 213952
    },
    {
      "epoch": 0.0007765904040450524,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 213984
    },
    {
      "epoch": 0.000776706538395889,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 214016
    },
    {
      "epoch": 0.0007768226727467258,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7477,
      "step": 214048
    },
    {
      "epoch": 0.0007769388070975624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 214080
    },
    {
      "epoch": 0.0007770549414483992,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 214112
    },
    {
      "epoch": 0.0007771710757992359,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 214144
    },
    {
      "epoch": 0.0007772872101500726,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6764,
      "step": 214176
    },
    {
      "epoch": 0.0007774033445009093,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6957,
      "step": 214208
    },
    {
      "epoch": 0.000777519478851746,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 214240
    },
    {
      "epoch": 0.0007776356132025827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 214272
    },
    {
      "epoch": 0.0007777517475534194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7026,
      "step": 214304
    },
    {
      "epoch": 0.0007778678819042561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7466,
      "step": 214336
    },
    {
      "epoch": 0.0007779840162550928,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6956,
      "step": 214368
    },
    {
      "epoch": 0.0007781001506059295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6896,
      "step": 214400
    },
    {
      "epoch": 0.0007782162849567663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 214432
    },
    {
      "epoch": 0.0007783324193076029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 214464
    },
    {
      "epoch": 0.0007784485536584397,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 214496
    },
    {
      "epoch": 0.0007785646880092763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 214528
    },
    {
      "epoch": 0.0007786808223601131,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7021,
      "step": 214560
    },
    {
      "epoch": 0.0007787969567109497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 214592
    },
    {
      "epoch": 0.0007789130910617865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 214624
    },
    {
      "epoch": 0.0007790292254126231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 214656
    },
    {
      "epoch": 0.0007791453597634599,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 214688
    },
    {
      "epoch": 0.0007792614941142966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6915,
      "step": 214720
    },
    {
      "epoch": 0.0007793776284651333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 214752
    },
    {
      "epoch": 0.00077949376281597,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 214784
    },
    {
      "epoch": 0.0007796098971668067,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 214816
    },
    {
      "epoch": 0.0007797260315176434,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 214848
    },
    {
      "epoch": 0.0007798421658684801,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 214880
    },
    {
      "epoch": 0.0007799583002193168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 214912
    },
    {
      "epoch": 0.0007800744345701535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 214944
    },
    {
      "epoch": 0.0007801905689209902,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 214976
    },
    {
      "epoch": 0.000780306703271827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 215008
    },
    {
      "epoch": 0.0007804228376226636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 215040
    },
    {
      "epoch": 0.0007805389719735004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 215072
    },
    {
      "epoch": 0.000780655106324337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 215104
    },
    {
      "epoch": 0.0007807712406751738,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 215136
    },
    {
      "epoch": 0.0007808873750260104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 215168
    },
    {
      "epoch": 0.0007810035093768472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 215200
    },
    {
      "epoch": 0.0007811196437276838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 215232
    },
    {
      "epoch": 0.0007812357780785206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 215264
    },
    {
      "epoch": 0.0007813519124293573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 215296
    },
    {
      "epoch": 0.000781468046780194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 215328
    },
    {
      "epoch": 0.0007815841811310307,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 215360
    },
    {
      "epoch": 0.0007817003154818674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 215392
    },
    {
      "epoch": 0.0007818164498327041,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.695,
      "step": 215424
    },
    {
      "epoch": 0.0007819325841835408,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 215456
    },
    {
      "epoch": 0.0007820487185343775,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 215488
    },
    {
      "epoch": 0.0007821648528852142,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7329,
      "step": 215520
    },
    {
      "epoch": 0.0007822809872360509,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 215552
    },
    {
      "epoch": 0.0007823971215868877,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 215584
    },
    {
      "epoch": 0.0007825132559377243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 215616
    },
    {
      "epoch": 0.0007826293902885611,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 215648
    },
    {
      "epoch": 0.0007827455246393977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7454,
      "step": 215680
    },
    {
      "epoch": 0.0007828616589902345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7287,
      "step": 215712
    },
    {
      "epoch": 0.0007829777933410711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 215744
    },
    {
      "epoch": 0.0007830939276919079,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.723,
      "step": 215776
    },
    {
      "epoch": 0.0007832100620427445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 215808
    },
    {
      "epoch": 0.0007833261963935813,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 215840
    },
    {
      "epoch": 0.000783442330744418,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 215872
    },
    {
      "epoch": 0.0007835584650952547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6924,
      "step": 215904
    },
    {
      "epoch": 0.0007836745994460914,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 215936
    },
    {
      "epoch": 0.0007837907337969281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 215968
    },
    {
      "epoch": 0.0007839068681477648,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 216000
    },
    {
      "epoch": 0.0007840230024986015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 216032
    },
    {
      "epoch": 0.0007841391368494382,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 216064
    },
    {
      "epoch": 0.0007842552712002749,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7415,
      "step": 216096
    },
    {
      "epoch": 0.0007843714055511116,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 216128
    },
    {
      "epoch": 0.0007844875399019484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.691,
      "step": 216160
    },
    {
      "epoch": 0.000784603674252785,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 216192
    },
    {
      "epoch": 0.0007847198086036218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 216224
    },
    {
      "epoch": 0.0007848359429544584,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6889,
      "step": 216256
    },
    {
      "epoch": 0.0007849520773052952,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7013,
      "step": 216288
    },
    {
      "epoch": 0.0007850682116561318,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 216320
    },
    {
      "epoch": 0.0007851843460069686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7127,
      "step": 216352
    },
    {
      "epoch": 0.0007853004803578052,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 216384
    },
    {
      "epoch": 0.000785416614708642,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 216416
    },
    {
      "epoch": 0.0007855327490594788,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 216448
    },
    {
      "epoch": 0.0007856488834103154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 216480
    },
    {
      "epoch": 0.0007857650177611522,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 216512
    },
    {
      "epoch": 0.0007858811521119888,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7466,
      "step": 216544
    },
    {
      "epoch": 0.0007859972864628256,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 216576
    },
    {
      "epoch": 0.0007861134208136622,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 216608
    },
    {
      "epoch": 0.000786229555164499,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 216640
    },
    {
      "epoch": 0.0007863456895153356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 216672
    },
    {
      "epoch": 0.0007864618238661723,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7409,
      "step": 216704
    },
    {
      "epoch": 0.0007865779582170091,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6931,
      "step": 216736
    },
    {
      "epoch": 0.0007866940925678457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6976,
      "step": 216768
    },
    {
      "epoch": 0.0007868102269186825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6959,
      "step": 216800
    },
    {
      "epoch": 0.0007869263612695191,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 216832
    },
    {
      "epoch": 0.0007870424956203559,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 216864
    },
    {
      "epoch": 0.0007871586299711925,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6916,
      "step": 216896
    },
    {
      "epoch": 0.0007872747643220293,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 216928
    },
    {
      "epoch": 0.000787390898672866,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7367,
      "step": 216960
    },
    {
      "epoch": 0.0007875070330237027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 216992
    },
    {
      "epoch": 0.0007876231673745395,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 217024
    },
    {
      "epoch": 0.0007877393017253761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6948,
      "step": 217056
    },
    {
      "epoch": 0.0007878554360762129,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6875,
      "step": 217088
    },
    {
      "epoch": 0.0007879715704270495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6968,
      "step": 217120
    },
    {
      "epoch": 0.0007880877047778863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 217152
    },
    {
      "epoch": 0.0007882038391287229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 217184
    },
    {
      "epoch": 0.0007883199734795597,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 217216
    },
    {
      "epoch": 0.0007884361078303963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7026,
      "step": 217248
    },
    {
      "epoch": 0.0007885522421812331,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 217280
    },
    {
      "epoch": 0.0007886683765320698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6977,
      "step": 217312
    },
    {
      "epoch": 0.0007887845108829065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 217344
    },
    {
      "epoch": 0.0007889006452337432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7295,
      "step": 217376
    },
    {
      "epoch": 0.0007890167795845799,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 217408
    },
    {
      "epoch": 0.0007891329139354166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7385,
      "step": 217440
    },
    {
      "epoch": 0.0007892490482862533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 217472
    },
    {
      "epoch": 0.00078936518263709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 217504
    },
    {
      "epoch": 0.0007894813169879267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 217536
    },
    {
      "epoch": 0.0007895974513387634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7458,
      "step": 217568
    },
    {
      "epoch": 0.0007897135856896002,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 217600
    },
    {
      "epoch": 0.0007898297200404368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6943,
      "step": 217632
    },
    {
      "epoch": 0.0007899458543912736,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6933,
      "step": 217664
    },
    {
      "epoch": 0.0007900619887421102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6868,
      "step": 217696
    },
    {
      "epoch": 0.000790178123092947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6855,
      "step": 217728
    },
    {
      "epoch": 0.0007902942574437836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 217760
    },
    {
      "epoch": 0.0007904103917946204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 217792
    },
    {
      "epoch": 0.000790526526145457,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 217824
    },
    {
      "epoch": 0.0007906426604962938,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 217856
    },
    {
      "epoch": 0.0007907587948471305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 217888
    },
    {
      "epoch": 0.0007908749291979672,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6793,
      "step": 217920
    },
    {
      "epoch": 0.0007909910635488039,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6964,
      "step": 217952
    },
    {
      "epoch": 0.0007911071978996406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 217984
    },
    {
      "epoch": 0.0007912233322504773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 218016
    },
    {
      "epoch": 0.000791339466601314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7125,
      "step": 218048
    },
    {
      "epoch": 0.0007914556009521507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 218080
    },
    {
      "epoch": 0.0007915717353029874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6948,
      "step": 218112
    },
    {
      "epoch": 0.0007916878696538241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 218144
    },
    {
      "epoch": 0.0007918040040046609,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 218176
    },
    {
      "epoch": 0.0007919201383554975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 218208
    },
    {
      "epoch": 0.0007920362727063343,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 218240
    },
    {
      "epoch": 0.0007921524070571709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7355,
      "step": 218272
    },
    {
      "epoch": 0.0007922685414080077,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 218304
    },
    {
      "epoch": 0.0007923846757588443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 218336
    },
    {
      "epoch": 0.0007925008101096811,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 218368
    },
    {
      "epoch": 0.0007926169444605177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 218400
    },
    {
      "epoch": 0.0007927330788113545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 218432
    },
    {
      "epoch": 0.0007928492131621912,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 218464
    },
    {
      "epoch": 0.0007929653475130279,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6879,
      "step": 218496
    },
    {
      "epoch": 0.0007930814818638646,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6809,
      "step": 218528
    },
    {
      "epoch": 0.0007931976162147013,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6898,
      "step": 218560
    },
    {
      "epoch": 0.000793313750565538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 218592
    },
    {
      "epoch": 0.0007934298849163747,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 218624
    },
    {
      "epoch": 0.0007935460192672114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 218656
    },
    {
      "epoch": 0.0007936621536180481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 218688
    },
    {
      "epoch": 0.0007937782879688848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 218720
    },
    {
      "epoch": 0.0007938944223197216,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 218752
    },
    {
      "epoch": 0.0007940105566705582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 218784
    },
    {
      "epoch": 0.000794126691021395,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 218816
    },
    {
      "epoch": 0.0007942428253722316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 218848
    },
    {
      "epoch": 0.0007943589597230684,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 218880
    },
    {
      "epoch": 0.000794475094073905,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 218912
    },
    {
      "epoch": 0.0007945912284247418,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6896,
      "step": 218944
    },
    {
      "epoch": 0.0007947073627755784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 218976
    },
    {
      "epoch": 0.0007948234971264152,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 219008
    },
    {
      "epoch": 0.0007949396314772519,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 219040
    },
    {
      "epoch": 0.0007950557658280886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 219072
    },
    {
      "epoch": 0.0007951719001789253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 219104
    },
    {
      "epoch": 0.000795288034529762,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 219136
    },
    {
      "epoch": 0.0007954041688805987,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 219168
    },
    {
      "epoch": 0.0007955203032314354,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 219200
    },
    {
      "epoch": 0.0007956364375822721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7291,
      "step": 219232
    },
    {
      "epoch": 0.0007957525719331088,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 219264
    },
    {
      "epoch": 0.0007958687062839455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 219296
    },
    {
      "epoch": 0.0007959848406347823,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 219328
    },
    {
      "epoch": 0.0007961009749856189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6996,
      "step": 219360
    },
    {
      "epoch": 0.0007962171093364557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 219392
    },
    {
      "epoch": 0.0007963332436872923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6921,
      "step": 219424
    },
    {
      "epoch": 0.0007964493780381291,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 219456
    },
    {
      "epoch": 0.0007965655123889657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 219488
    },
    {
      "epoch": 0.0007966816467398025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 219520
    },
    {
      "epoch": 0.0007967977810906391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 219552
    },
    {
      "epoch": 0.0007969139154414759,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 219584
    },
    {
      "epoch": 0.0007970300497923126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 219616
    },
    {
      "epoch": 0.0007971461841431493,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 219648
    },
    {
      "epoch": 0.000797262318493986,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6926,
      "step": 219680
    },
    {
      "epoch": 0.0007973784528448227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 219712
    },
    {
      "epoch": 0.0007974945871956594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 219744
    },
    {
      "epoch": 0.0007976107215464961,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6846,
      "step": 219776
    },
    {
      "epoch": 0.0007977268558973328,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 219808
    },
    {
      "epoch": 0.0007978429902481695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 219840
    },
    {
      "epoch": 0.0007979591245990062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7454,
      "step": 219872
    },
    {
      "epoch": 0.000798075258949843,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 219904
    },
    {
      "epoch": 0.0007981913933006796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 219936
    },
    {
      "epoch": 0.0007983075276515164,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 219968
    },
    {
      "epoch": 0.000798423662002353,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 220000
    },
    {
      "epoch": 0.0007985397963531898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 220032
    },
    {
      "epoch": 0.0007986559307040264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7327,
      "step": 220064
    },
    {
      "epoch": 0.0007987720650548632,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 220096
    },
    {
      "epoch": 0.0007988881994056998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 220128
    },
    {
      "epoch": 0.0007990043337565366,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 220160
    },
    {
      "epoch": 0.0007991204681073733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6893,
      "step": 220192
    },
    {
      "epoch": 0.00079923660245821,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 220224
    },
    {
      "epoch": 0.0007993527368090467,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 220256
    },
    {
      "epoch": 0.0007994688711598834,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 220288
    },
    {
      "epoch": 0.0007995850055107201,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 220320
    },
    {
      "epoch": 0.0007997011398615568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7275,
      "step": 220352
    },
    {
      "epoch": 0.0007998172742123935,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 220384
    },
    {
      "epoch": 0.0007999334085632302,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6904,
      "step": 220416
    },
    {
      "epoch": 0.0008000495429140669,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 220448
    },
    {
      "epoch": 0.0008001656772649037,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7354,
      "step": 220480
    },
    {
      "epoch": 0.0008002818116157403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 220512
    },
    {
      "epoch": 0.0008003979459665771,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 220544
    },
    {
      "epoch": 0.0008005140803174137,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 220576
    },
    {
      "epoch": 0.0008006302146682505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 220608
    },
    {
      "epoch": 0.0008007463490190871,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 220640
    },
    {
      "epoch": 0.0008008624833699239,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 220672
    },
    {
      "epoch": 0.0008009786177207605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 220704
    },
    {
      "epoch": 0.0008010947520715973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 220736
    },
    {
      "epoch": 0.000801210886422434,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 220768
    },
    {
      "epoch": 0.0008013270207732707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 220800
    },
    {
      "epoch": 0.0008014431551241075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 220832
    },
    {
      "epoch": 0.0008015592894749441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 220864
    },
    {
      "epoch": 0.0008016754238257809,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 220896
    },
    {
      "epoch": 0.0008017915581766175,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7491,
      "step": 220928
    },
    {
      "epoch": 0.0008019076925274543,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 220960
    },
    {
      "epoch": 0.0008020238268782909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 220992
    },
    {
      "epoch": 0.0008021399612291277,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 221024
    },
    {
      "epoch": 0.0008022560955799643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 221056
    },
    {
      "epoch": 0.000802372229930801,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 221088
    },
    {
      "epoch": 0.0008024883642816378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 221120
    },
    {
      "epoch": 0.0008026044986324745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 221152
    },
    {
      "epoch": 0.0008027206329833112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 221184
    },
    {
      "epoch": 0.0008028367673341479,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 221216
    },
    {
      "epoch": 0.0008029529016849846,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 221248
    },
    {
      "epoch": 0.0008030690360358213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 221280
    },
    {
      "epoch": 0.000803185170386658,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 221312
    },
    {
      "epoch": 0.0008033013047374947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7402,
      "step": 221344
    },
    {
      "epoch": 0.0008034174390883314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 221376
    },
    {
      "epoch": 0.0008035335734391682,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 221408
    },
    {
      "epoch": 0.0008036497077900048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.694,
      "step": 221440
    },
    {
      "epoch": 0.0008037658421408416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 221472
    },
    {
      "epoch": 0.0008038819764916782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 221504
    },
    {
      "epoch": 0.000803998110842515,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 221536
    },
    {
      "epoch": 0.0008041142451933516,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 221568
    },
    {
      "epoch": 0.0008042303795441884,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 221600
    },
    {
      "epoch": 0.000804346513895025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 221632
    },
    {
      "epoch": 0.0008044626482458618,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 221664
    },
    {
      "epoch": 0.0008045787825966985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 221696
    },
    {
      "epoch": 0.0008046949169475352,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7336,
      "step": 221728
    },
    {
      "epoch": 0.0008048110512983719,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 221760
    },
    {
      "epoch": 0.0008049271856492086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.738,
      "step": 221792
    },
    {
      "epoch": 0.0008050433200000453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 221824
    },
    {
      "epoch": 0.000805159454350882,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 221856
    },
    {
      "epoch": 0.0008052755887017187,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7274,
      "step": 221888
    },
    {
      "epoch": 0.0008053917230525554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 221920
    },
    {
      "epoch": 0.0008055078574033921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 221952
    },
    {
      "epoch": 0.0008056239917542289,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.742,
      "step": 221984
    },
    {
      "epoch": 0.0008057401261050655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 222016
    },
    {
      "epoch": 0.0008058562604559023,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.675,
      "step": 222048
    },
    {
      "epoch": 0.0008059723948067389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6912,
      "step": 222080
    },
    {
      "epoch": 0.0008060885291575757,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 222112
    },
    {
      "epoch": 0.0008062046635084123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 222144
    },
    {
      "epoch": 0.0008063207978592491,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 222176
    },
    {
      "epoch": 0.0008064369322100857,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 222208
    },
    {
      "epoch": 0.0008065530665609225,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 222240
    },
    {
      "epoch": 0.0008066692009117592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 222272
    },
    {
      "epoch": 0.0008067853352625959,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 222304
    },
    {
      "epoch": 0.0008069014696134326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 222336
    },
    {
      "epoch": 0.0008070176039642693,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 222368
    },
    {
      "epoch": 0.000807133738315106,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 222400
    },
    {
      "epoch": 0.0008072498726659427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 222432
    },
    {
      "epoch": 0.0008073660070167794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 222464
    },
    {
      "epoch": 0.0008074821413676161,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 222496
    },
    {
      "epoch": 0.0008075982757184528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 222528
    },
    {
      "epoch": 0.0008077144100692896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7248,
      "step": 222560
    },
    {
      "epoch": 0.0008078305444201262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 222592
    },
    {
      "epoch": 0.000807946678770963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 222624
    },
    {
      "epoch": 0.0008080628131217996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 222656
    },
    {
      "epoch": 0.0008081789474726364,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 222688
    },
    {
      "epoch": 0.000808295081823473,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 222720
    },
    {
      "epoch": 0.0008084112161743098,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 222752
    },
    {
      "epoch": 0.0008085273505251464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7266,
      "step": 222784
    },
    {
      "epoch": 0.0008086434848759832,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 222816
    },
    {
      "epoch": 0.0008087596192268199,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 222848
    },
    {
      "epoch": 0.0008088757535776566,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6973,
      "step": 222880
    },
    {
      "epoch": 0.0008089918879284933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 222912
    },
    {
      "epoch": 0.00080910802227933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 222944
    },
    {
      "epoch": 0.0008092241566301667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 222976
    },
    {
      "epoch": 0.0008093402909810034,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 223008
    },
    {
      "epoch": 0.0008094564253318401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 223040
    },
    {
      "epoch": 0.0008095725596826768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 223072
    },
    {
      "epoch": 0.0008096886940335135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7352,
      "step": 223104
    },
    {
      "epoch": 0.0008098048283843503,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 223136
    },
    {
      "epoch": 0.0008099209627351869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7297,
      "step": 223168
    },
    {
      "epoch": 0.0008100370970860237,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 223200
    },
    {
      "epoch": 0.0008101532314368603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 223232
    },
    {
      "epoch": 0.0008102693657876971,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 223264
    },
    {
      "epoch": 0.0008103855001385337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 223296
    },
    {
      "epoch": 0.0008105016344893705,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 223328
    },
    {
      "epoch": 0.0008106177688402071,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 223360
    },
    {
      "epoch": 0.0008107339031910439,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7499,
      "step": 223392
    },
    {
      "epoch": 0.0008108500375418806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 223424
    },
    {
      "epoch": 0.0008109661718927173,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7344,
      "step": 223456
    },
    {
      "epoch": 0.000811082306243554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.736,
      "step": 223488
    },
    {
      "epoch": 0.0008111984405943907,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 223520
    },
    {
      "epoch": 0.0008113145749452274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7442,
      "step": 223552
    },
    {
      "epoch": 0.0008114307092960641,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7237,
      "step": 223584
    },
    {
      "epoch": 0.0008115468436469008,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 223616
    },
    {
      "epoch": 0.0008116629779977375,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 223648
    },
    {
      "epoch": 0.0008117791123485742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7461,
      "step": 223680
    },
    {
      "epoch": 0.000811895246699411,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 223712
    },
    {
      "epoch": 0.0008120113810502476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 223744
    },
    {
      "epoch": 0.0008121275154010844,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 223776
    },
    {
      "epoch": 0.000812243649751921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 223808
    },
    {
      "epoch": 0.0008123597841027578,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 223840
    },
    {
      "epoch": 0.0008124759184535944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7384,
      "step": 223872
    },
    {
      "epoch": 0.0008125920528044312,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 223904
    },
    {
      "epoch": 0.0008127081871552678,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 223936
    },
    {
      "epoch": 0.0008128243215061046,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7424,
      "step": 223968
    },
    {
      "epoch": 0.0008129404558569413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 224000
    },
    {
      "epoch": 0.000813056590207778,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 224032
    },
    {
      "epoch": 0.0008131727245586147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7379,
      "step": 224064
    },
    {
      "epoch": 0.0008132888589094514,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7411,
      "step": 224096
    },
    {
      "epoch": 0.0008134049932602881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 224128
    },
    {
      "epoch": 0.0008135211276111248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 224160
    },
    {
      "epoch": 0.0008136372619619615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 224192
    },
    {
      "epoch": 0.0008137533963127982,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7395,
      "step": 224224
    },
    {
      "epoch": 0.0008138695306636349,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7352,
      "step": 224256
    },
    {
      "epoch": 0.0008139856650144717,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7497,
      "step": 224288
    },
    {
      "epoch": 0.0008141017993653083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 224320
    },
    {
      "epoch": 0.0008142179337161451,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 224352
    },
    {
      "epoch": 0.0008143340680669817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 224384
    },
    {
      "epoch": 0.0008144502024178185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 224416
    },
    {
      "epoch": 0.0008145663367686551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 224448
    },
    {
      "epoch": 0.0008146824711194919,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 224480
    },
    {
      "epoch": 0.0008147986054703285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 224512
    },
    {
      "epoch": 0.0008149147398211653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 224544
    },
    {
      "epoch": 0.000815030874172002,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 224576
    },
    {
      "epoch": 0.0008151470085228387,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6976,
      "step": 224608
    },
    {
      "epoch": 0.0008152631428736754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 224640
    },
    {
      "epoch": 0.0008153792772245121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 224672
    },
    {
      "epoch": 0.0008154954115753488,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 224704
    },
    {
      "epoch": 0.0008156115459261855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 224736
    },
    {
      "epoch": 0.0008157276802770222,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 224768
    },
    {
      "epoch": 0.0008158438146278589,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 224800
    },
    {
      "epoch": 0.0008159599489786956,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7309,
      "step": 224832
    },
    {
      "epoch": 0.0008160760833295324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7373,
      "step": 224864
    },
    {
      "epoch": 0.000816192217680369,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 224896
    },
    {
      "epoch": 0.0008163083520312058,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 224928
    },
    {
      "epoch": 0.0008164244863820424,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 224960
    },
    {
      "epoch": 0.0008165406207328792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 224992
    },
    {
      "epoch": 0.0008166567550837158,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 225024
    },
    {
      "epoch": 0.0008167728894345526,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6922,
      "step": 225056
    },
    {
      "epoch": 0.0008168890237853892,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 225088
    },
    {
      "epoch": 0.000817005158136226,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 225120
    },
    {
      "epoch": 0.0008171212924870628,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 225152
    },
    {
      "epoch": 0.0008172374268378994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 225184
    },
    {
      "epoch": 0.0008173535611887362,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 225216
    },
    {
      "epoch": 0.0008174696955395728,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7449,
      "step": 225248
    },
    {
      "epoch": 0.0008175858298904096,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 225280
    },
    {
      "epoch": 0.0008177019642412462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7478,
      "step": 225312
    },
    {
      "epoch": 0.000817818098592083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6901,
      "step": 225344
    },
    {
      "epoch": 0.0008179342329429196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.692,
      "step": 225376
    },
    {
      "epoch": 0.0008180503672937564,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 225408
    },
    {
      "epoch": 0.0008181665016445931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 225440
    },
    {
      "epoch": 0.0008182826359954298,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 225472
    },
    {
      "epoch": 0.0008183987703462665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 225504
    },
    {
      "epoch": 0.0008185149046971032,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 225536
    },
    {
      "epoch": 0.0008186310390479399,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6881,
      "step": 225568
    },
    {
      "epoch": 0.0008187471733987766,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 225600
    },
    {
      "epoch": 0.0008188633077496133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 225632
    },
    {
      "epoch": 0.00081897944210045,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 225664
    },
    {
      "epoch": 0.0008190955764512867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 225696
    },
    {
      "epoch": 0.0008192117108021235,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7349,
      "step": 225728
    },
    {
      "epoch": 0.0008193278451529601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7073,
      "step": 225760
    },
    {
      "epoch": 0.0008194439795037969,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6926,
      "step": 225792
    },
    {
      "epoch": 0.0008195601138546335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 225824
    },
    {
      "epoch": 0.0008196762482054703,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7264,
      "step": 225856
    },
    {
      "epoch": 0.0008197923825563069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 225888
    },
    {
      "epoch": 0.0008199085169071437,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 225920
    },
    {
      "epoch": 0.0008200246512579803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 225952
    },
    {
      "epoch": 0.0008201407856088171,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 225984
    },
    {
      "epoch": 0.0008202569199596538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 226016
    },
    {
      "epoch": 0.0008203730543104905,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 226048
    },
    {
      "epoch": 0.0008204891886613272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 226080
    },
    {
      "epoch": 0.0008206053230121639,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 226112
    },
    {
      "epoch": 0.0008207214573630006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 226144
    },
    {
      "epoch": 0.0008208375917138373,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7377,
      "step": 226176
    },
    {
      "epoch": 0.000820953726064674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7398,
      "step": 226208
    },
    {
      "epoch": 0.0008210698604155107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7001,
      "step": 226240
    },
    {
      "epoch": 0.0008211859947663474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 226272
    },
    {
      "epoch": 0.0008213021291171842,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 226304
    },
    {
      "epoch": 0.0008214182634680208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 226336
    },
    {
      "epoch": 0.0008215343978188576,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 226368
    },
    {
      "epoch": 0.0008216505321696942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 226400
    },
    {
      "epoch": 0.000821766666520531,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 226432
    },
    {
      "epoch": 0.0008218828008713676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 226464
    },
    {
      "epoch": 0.0008219989352222044,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 226496
    },
    {
      "epoch": 0.000822115069573041,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 226528
    },
    {
      "epoch": 0.0008222312039238778,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 226560
    },
    {
      "epoch": 0.0008223473382747145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 226592
    },
    {
      "epoch": 0.0008224634726255512,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 226624
    },
    {
      "epoch": 0.0008225796069763879,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 226656
    },
    {
      "epoch": 0.0008226957413272246,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 226688
    },
    {
      "epoch": 0.0008228118756780613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 226720
    },
    {
      "epoch": 0.000822928010028898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 226752
    },
    {
      "epoch": 0.0008230441443797347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 226784
    },
    {
      "epoch": 0.0008231602787305714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 226816
    },
    {
      "epoch": 0.0008232764130814081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 226848
    },
    {
      "epoch": 0.0008233925474322449,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7521,
      "step": 226880
    },
    {
      "epoch": 0.0008235086817830815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.756,
      "step": 226912
    },
    {
      "epoch": 0.0008236248161339183,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 226944
    },
    {
      "epoch": 0.0008237409504847549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 226976
    },
    {
      "epoch": 0.0008238570848355917,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 227008
    },
    {
      "epoch": 0.0008239732191864283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 227040
    },
    {
      "epoch": 0.0008240893535372651,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 227072
    },
    {
      "epoch": 0.0008242054878881017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 227104
    },
    {
      "epoch": 0.0008243216222389385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 227136
    },
    {
      "epoch": 0.0008244377565897752,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 227168
    },
    {
      "epoch": 0.0008245538909406119,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 227200
    },
    {
      "epoch": 0.0008246700252914486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6957,
      "step": 227232
    },
    {
      "epoch": 0.0008247861596422853,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6962,
      "step": 227264
    },
    {
      "epoch": 0.000824902293993122,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 227296
    },
    {
      "epoch": 0.0008250184283439587,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6916,
      "step": 227328
    },
    {
      "epoch": 0.0008251345626947954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 227360
    },
    {
      "epoch": 0.0008252506970456321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 227392
    },
    {
      "epoch": 0.0008253668313964688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6872,
      "step": 227424
    },
    {
      "epoch": 0.0008254829657473056,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 227456
    },
    {
      "epoch": 0.0008255991000981422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 227488
    },
    {
      "epoch": 0.000825715234448979,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 227520
    },
    {
      "epoch": 0.0008258313687998156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6879,
      "step": 227552
    },
    {
      "epoch": 0.0008259475031506524,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 227584
    },
    {
      "epoch": 0.000826063637501489,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 227616
    },
    {
      "epoch": 0.0008261797718523258,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6945,
      "step": 227648
    },
    {
      "epoch": 0.0008262959062031624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.706,
      "step": 227680
    },
    {
      "epoch": 0.0008264120405539992,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 227712
    },
    {
      "epoch": 0.0008265281749048359,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7383,
      "step": 227744
    },
    {
      "epoch": 0.0008266443092556726,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 227776
    },
    {
      "epoch": 0.0008267604436065093,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.738,
      "step": 227808
    },
    {
      "epoch": 0.000826876577957346,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6876,
      "step": 227840
    },
    {
      "epoch": 0.0008269927123081827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 227872
    },
    {
      "epoch": 0.0008271088466590194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 227904
    },
    {
      "epoch": 0.0008272249810098561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7369,
      "step": 227936
    },
    {
      "epoch": 0.0008273411153606928,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7335,
      "step": 227968
    },
    {
      "epoch": 0.0008274572497115295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 228000
    },
    {
      "epoch": 0.0008275733840623663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 228032
    },
    {
      "epoch": 0.0008276895184132029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 228064
    },
    {
      "epoch": 0.0008278056527640397,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 228096
    },
    {
      "epoch": 0.0008279217871148763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 228128
    },
    {
      "epoch": 0.0008280379214657131,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 228160
    },
    {
      "epoch": 0.0008281540558165497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 228192
    },
    {
      "epoch": 0.0008282701901673865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7239,
      "step": 228224
    },
    {
      "epoch": 0.0008283863245182231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 228256
    },
    {
      "epoch": 0.0008285024588690599,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 228288
    },
    {
      "epoch": 0.0008286185932198966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 228320
    },
    {
      "epoch": 0.0008287347275707333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7529,
      "step": 228352
    },
    {
      "epoch": 0.00082885086192157,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 228384
    },
    {
      "epoch": 0.0008289669962724067,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 228416
    },
    {
      "epoch": 0.0008290831306232434,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 228448
    },
    {
      "epoch": 0.0008291992649740801,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 228480
    },
    {
      "epoch": 0.0008293153993249168,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 228512
    },
    {
      "epoch": 0.0008294315336757535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 228544
    },
    {
      "epoch": 0.0008295476680265902,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7366,
      "step": 228576
    },
    {
      "epoch": 0.000829663802377427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7505,
      "step": 228608
    },
    {
      "epoch": 0.0008297799367282636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7486,
      "step": 228640
    },
    {
      "epoch": 0.0008298960710791004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 228672
    },
    {
      "epoch": 0.000830012205429937,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 228704
    },
    {
      "epoch": 0.0008301283397807738,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 228736
    },
    {
      "epoch": 0.0008302444741316104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7528,
      "step": 228768
    },
    {
      "epoch": 0.0008303606084824472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7399,
      "step": 228800
    },
    {
      "epoch": 0.0008304767428332838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7436,
      "step": 228832
    },
    {
      "epoch": 0.0008305928771841206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 228864
    },
    {
      "epoch": 0.0008307090115349573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 228896
    },
    {
      "epoch": 0.000830825145885794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 228928
    },
    {
      "epoch": 0.0008309412802366307,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 228960
    },
    {
      "epoch": 0.0008310574145874674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 228992
    },
    {
      "epoch": 0.0008311735489383041,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7362,
      "step": 229024
    },
    {
      "epoch": 0.0008312896832891408,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 229056
    },
    {
      "epoch": 0.0008314058176399775,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 229088
    },
    {
      "epoch": 0.0008315219519908142,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 229120
    },
    {
      "epoch": 0.000831638086341651,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 229152
    },
    {
      "epoch": 0.0008317542206924877,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7326,
      "step": 229184
    },
    {
      "epoch": 0.0008318703550433243,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.756,
      "step": 229216
    },
    {
      "epoch": 0.0008319864893941611,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7728,
      "step": 229248
    },
    {
      "epoch": 0.0008321026237449977,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 229280
    },
    {
      "epoch": 0.0008322187580958345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.681,
      "step": 229312
    },
    {
      "epoch": 0.0008323348924466711,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 229344
    },
    {
      "epoch": 0.0008324510267975079,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 229376
    },
    {
      "epoch": 0.0008325671611483445,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 229408
    },
    {
      "epoch": 0.0008326832954991813,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 229440
    },
    {
      "epoch": 0.000832799429850018,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 229472
    },
    {
      "epoch": 0.0008329155642008547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 229504
    },
    {
      "epoch": 0.0008330316985516915,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 229536
    },
    {
      "epoch": 0.0008331478329025281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 229568
    },
    {
      "epoch": 0.0008332639672533649,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 229600
    },
    {
      "epoch": 0.0008333801016042015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 229632
    },
    {
      "epoch": 0.0008334962359550383,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 229664
    },
    {
      "epoch": 0.0008336123703058749,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 229696
    },
    {
      "epoch": 0.0008337285046567117,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 229728
    },
    {
      "epoch": 0.0008338446390075484,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 229760
    },
    {
      "epoch": 0.000833960773358385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7206,
      "step": 229792
    },
    {
      "epoch": 0.0008340769077092218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 229824
    },
    {
      "epoch": 0.0008341930420600585,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 229856
    },
    {
      "epoch": 0.0008343091764108952,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 229888
    },
    {
      "epoch": 0.0008344253107617319,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6975,
      "step": 229920
    },
    {
      "epoch": 0.0008345414451125686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 229952
    },
    {
      "epoch": 0.0008346575794634053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 229984
    },
    {
      "epoch": 0.000834773713814242,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 230016
    },
    {
      "epoch": 0.0008348898481650788,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6983,
      "step": 230048
    },
    {
      "epoch": 0.0008350059825159154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 230080
    },
    {
      "epoch": 0.0008351221168667522,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 230112
    },
    {
      "epoch": 0.0008352382512175888,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 230144
    },
    {
      "epoch": 0.0008353543855684256,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 230176
    },
    {
      "epoch": 0.0008354705199192622,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7333,
      "step": 230208
    },
    {
      "epoch": 0.000835586654270099,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7355,
      "step": 230240
    },
    {
      "epoch": 0.0008357027886209356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 230272
    },
    {
      "epoch": 0.0008358189229717724,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 230304
    },
    {
      "epoch": 0.0008359350573226091,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 230336
    },
    {
      "epoch": 0.0008360511916734458,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 230368
    },
    {
      "epoch": 0.0008361673260242825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 230400
    },
    {
      "epoch": 0.0008362834603751192,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 230432
    },
    {
      "epoch": 0.0008363995947259559,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6908,
      "step": 230464
    },
    {
      "epoch": 0.0008365157290767926,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 230496
    },
    {
      "epoch": 0.0008366318634276293,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 230528
    },
    {
      "epoch": 0.000836747997778466,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7396,
      "step": 230560
    },
    {
      "epoch": 0.0008368641321293027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 230592
    },
    {
      "epoch": 0.0008369802664801395,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 230624
    },
    {
      "epoch": 0.0008370964008309761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 230656
    },
    {
      "epoch": 0.0008372125351818129,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 230688
    },
    {
      "epoch": 0.0008373286695326495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 230720
    },
    {
      "epoch": 0.0008374448038834863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6866,
      "step": 230752
    },
    {
      "epoch": 0.0008375609382343229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 230784
    },
    {
      "epoch": 0.0008376770725851597,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7227,
      "step": 230816
    },
    {
      "epoch": 0.0008377932069359963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 230848
    },
    {
      "epoch": 0.0008379093412868331,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 230880
    },
    {
      "epoch": 0.0008380254756376698,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 230912
    },
    {
      "epoch": 0.0008381416099885065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6877,
      "step": 230944
    },
    {
      "epoch": 0.0008382577443393432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7191,
      "step": 230976
    },
    {
      "epoch": 0.0008383738786901799,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 231008
    },
    {
      "epoch": 0.0008384900130410166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 231040
    },
    {
      "epoch": 0.0008386061473918533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7016,
      "step": 231072
    },
    {
      "epoch": 0.00083872228174269,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7424,
      "step": 231104
    },
    {
      "epoch": 0.0008388384160935267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7473,
      "step": 231136
    },
    {
      "epoch": 0.0008389545504443634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 231168
    },
    {
      "epoch": 0.0008390706847952002,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 231200
    },
    {
      "epoch": 0.0008391868191460368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 231232
    },
    {
      "epoch": 0.0008393029534968736,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 231264
    },
    {
      "epoch": 0.0008394190878477102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 231296
    },
    {
      "epoch": 0.000839535222198547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 231328
    },
    {
      "epoch": 0.0008396513565493836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6948,
      "step": 231360
    },
    {
      "epoch": 0.0008397674909002204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7218,
      "step": 231392
    },
    {
      "epoch": 0.000839883625251057,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7177,
      "step": 231424
    },
    {
      "epoch": 0.0008399997596018938,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7426,
      "step": 231456
    },
    {
      "epoch": 0.0008401158939527305,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 231488
    },
    {
      "epoch": 0.0008402320283035672,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 231520
    },
    {
      "epoch": 0.0008403481626544039,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7114,
      "step": 231552
    },
    {
      "epoch": 0.0008404642970052406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 231584
    },
    {
      "epoch": 0.0008405804313560773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7002,
      "step": 231616
    },
    {
      "epoch": 0.000840696565706914,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 231648
    },
    {
      "epoch": 0.0008408127000577507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 231680
    },
    {
      "epoch": 0.0008409288344085874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.742,
      "step": 231712
    },
    {
      "epoch": 0.0008410449687594241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7351,
      "step": 231744
    },
    {
      "epoch": 0.0008411611031102608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 231776
    },
    {
      "epoch": 0.0008412772374610975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 231808
    },
    {
      "epoch": 0.0008413933718119343,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 231840
    },
    {
      "epoch": 0.0008415095061627709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7498,
      "step": 231872
    },
    {
      "epoch": 0.0008416256405136077,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 231904
    },
    {
      "epoch": 0.0008417417748644443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 231936
    },
    {
      "epoch": 0.0008418579092152811,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6953,
      "step": 231968
    },
    {
      "epoch": 0.0008419740435661177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7061,
      "step": 232000
    },
    {
      "epoch": 0.0008420901779169545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 232032
    },
    {
      "epoch": 0.0008422063122677911,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 232064
    },
    {
      "epoch": 0.0008423224466186279,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 232096
    },
    {
      "epoch": 0.0008424385809694646,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 232128
    },
    {
      "epoch": 0.0008425547153203013,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 232160
    },
    {
      "epoch": 0.000842670849671138,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 232192
    },
    {
      "epoch": 0.0008427869840219747,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6827,
      "step": 232224
    },
    {
      "epoch": 0.0008429031183728114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 232256
    },
    {
      "epoch": 0.0008430192527236481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7489,
      "step": 232288
    },
    {
      "epoch": 0.0008431353870744848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7428,
      "step": 232320
    },
    {
      "epoch": 0.0008432515214253215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7218,
      "step": 232352
    },
    {
      "epoch": 0.0008433676557761582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 232384
    },
    {
      "epoch": 0.000843483790126995,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6924,
      "step": 232416
    },
    {
      "epoch": 0.0008435999244778316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 232448
    },
    {
      "epoch": 0.0008437160588286684,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7015,
      "step": 232480
    },
    {
      "epoch": 0.000843832193179505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6983,
      "step": 232512
    },
    {
      "epoch": 0.0008439483275303418,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 232544
    },
    {
      "epoch": 0.0008440644618811784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7108,
      "step": 232576
    },
    {
      "epoch": 0.0008441805962320152,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6962,
      "step": 232608
    },
    {
      "epoch": 0.0008442967305828518,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 232640
    },
    {
      "epoch": 0.0008444128649336886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 232672
    },
    {
      "epoch": 0.0008445289992845253,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7248,
      "step": 232704
    },
    {
      "epoch": 0.000844645133635362,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7528,
      "step": 232736
    },
    {
      "epoch": 0.0008447612679861987,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 232768
    },
    {
      "epoch": 0.0008448774023370354,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7024,
      "step": 232800
    },
    {
      "epoch": 0.0008449935366878721,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6901,
      "step": 232832
    },
    {
      "epoch": 0.0008451096710387088,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7141,
      "step": 232864
    },
    {
      "epoch": 0.0008452258053895455,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7376,
      "step": 232896
    },
    {
      "epoch": 0.0008453419397403822,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 232928
    },
    {
      "epoch": 0.0008454580740912189,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 232960
    },
    {
      "epoch": 0.0008455742084420557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7218,
      "step": 232992
    },
    {
      "epoch": 0.0008456903427928923,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 233024
    },
    {
      "epoch": 0.0008458064771437291,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7261,
      "step": 233056
    },
    {
      "epoch": 0.0008459226114945657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 233088
    },
    {
      "epoch": 0.0008460387458454025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 233120
    },
    {
      "epoch": 0.0008461548801962391,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7387,
      "step": 233152
    },
    {
      "epoch": 0.0008462710145470759,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7459,
      "step": 233184
    },
    {
      "epoch": 0.0008463871488979125,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 233216
    },
    {
      "epoch": 0.0008465032832487493,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 233248
    },
    {
      "epoch": 0.000846619417599586,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7413,
      "step": 233280
    },
    {
      "epoch": 0.0008467355519504227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 233312
    },
    {
      "epoch": 0.0008468516863012594,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7284,
      "step": 233344
    },
    {
      "epoch": 0.0008469678206520961,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 233376
    },
    {
      "epoch": 0.0008470839550029328,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 233408
    },
    {
      "epoch": 0.0008472000893537695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 233440
    },
    {
      "epoch": 0.0008473162237046062,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7365,
      "step": 233472
    },
    {
      "epoch": 0.0008474323580554429,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7328,
      "step": 233504
    },
    {
      "epoch": 0.0008475484924062796,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7402,
      "step": 233536
    },
    {
      "epoch": 0.0008476646267571164,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7359,
      "step": 233568
    },
    {
      "epoch": 0.000847780761107953,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 233600
    },
    {
      "epoch": 0.0008478968954587898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 233632
    },
    {
      "epoch": 0.0008480130298096264,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 233664
    },
    {
      "epoch": 0.0008481291641604632,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 233696
    },
    {
      "epoch": 0.0008482452985112998,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7256,
      "step": 233728
    },
    {
      "epoch": 0.0008483614328621366,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7368,
      "step": 233760
    },
    {
      "epoch": 0.0008484775672129732,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 233792
    },
    {
      "epoch": 0.00084859370156381,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 233824
    },
    {
      "epoch": 0.0008487098359146468,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 233856
    },
    {
      "epoch": 0.0008488259702654834,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7382,
      "step": 233888
    },
    {
      "epoch": 0.0008489421046163202,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 233920
    },
    {
      "epoch": 0.0008490582389671568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7382,
      "step": 233952
    },
    {
      "epoch": 0.0008491743733179936,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 233984
    },
    {
      "epoch": 0.0008492905076688302,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 234016
    },
    {
      "epoch": 0.000849406642019667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 234048
    },
    {
      "epoch": 0.0008495227763705036,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.749,
      "step": 234080
    },
    {
      "epoch": 0.0008496389107213404,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 234112
    },
    {
      "epoch": 0.0008497550450721771,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.739,
      "step": 234144
    },
    {
      "epoch": 0.0008498711794230138,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7402,
      "step": 234176
    },
    {
      "epoch": 0.0008499873137738505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 234208
    },
    {
      "epoch": 0.0008501034481246872,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6923,
      "step": 234240
    },
    {
      "epoch": 0.0008502195824755239,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 234272
    },
    {
      "epoch": 0.0008503357168263606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6971,
      "step": 234304
    },
    {
      "epoch": 0.0008504518511771973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 234336
    },
    {
      "epoch": 0.000850567985528034,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 234368
    },
    {
      "epoch": 0.0008506841198788707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 234400
    },
    {
      "epoch": 0.0008508002542297075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 234432
    },
    {
      "epoch": 0.0008509163885805441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6934,
      "step": 234464
    },
    {
      "epoch": 0.0008510325229313809,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 234496
    },
    {
      "epoch": 0.0008511486572822175,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7266,
      "step": 234528
    },
    {
      "epoch": 0.0008512647916330543,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 234560
    },
    {
      "epoch": 0.0008513809259838909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7065,
      "step": 234592
    },
    {
      "epoch": 0.0008514970603347277,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 234624
    },
    {
      "epoch": 0.0008516131946855643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7342,
      "step": 234656
    },
    {
      "epoch": 0.0008517293290364011,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 234688
    },
    {
      "epoch": 0.0008518454633872378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 234720
    },
    {
      "epoch": 0.0008519615977380745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 234752
    },
    {
      "epoch": 0.0008520777320889112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 234784
    },
    {
      "epoch": 0.0008521938664397479,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 234816
    },
    {
      "epoch": 0.0008523100007905846,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7153,
      "step": 234848
    },
    {
      "epoch": 0.0008524261351414213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7006,
      "step": 234880
    },
    {
      "epoch": 0.000852542269492258,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 234912
    },
    {
      "epoch": 0.0008526584038430947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 234944
    },
    {
      "epoch": 0.0008527745381939314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 234976
    },
    {
      "epoch": 0.0008528906725447682,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6976,
      "step": 235008
    },
    {
      "epoch": 0.0008530068068956048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 235040
    },
    {
      "epoch": 0.0008531229412464416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 235072
    },
    {
      "epoch": 0.0008532390755972782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 235104
    },
    {
      "epoch": 0.000853355209948115,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 235136
    },
    {
      "epoch": 0.0008534713442989516,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 235168
    },
    {
      "epoch": 0.0008535874786497884,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 235200
    },
    {
      "epoch": 0.000853703613000625,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 235232
    },
    {
      "epoch": 0.0008538197473514618,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 235264
    },
    {
      "epoch": 0.0008539358817022985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 235296
    },
    {
      "epoch": 0.0008540520160531352,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7037,
      "step": 235328
    },
    {
      "epoch": 0.0008541681504039719,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 235360
    },
    {
      "epoch": 0.0008542842847548086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 235392
    },
    {
      "epoch": 0.0008544004191056453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 235424
    },
    {
      "epoch": 0.000854516553456482,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 235456
    },
    {
      "epoch": 0.0008546326878073187,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 235488
    },
    {
      "epoch": 0.0008547488221581554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 235520
    },
    {
      "epoch": 0.0008548649565089921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 235552
    },
    {
      "epoch": 0.0008549810908598289,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7105,
      "step": 235584
    },
    {
      "epoch": 0.0008550972252106655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 235616
    },
    {
      "epoch": 0.0008552133595615023,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 235648
    },
    {
      "epoch": 0.0008553294939123389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7149,
      "step": 235680
    },
    {
      "epoch": 0.0008554456282631757,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 235712
    },
    {
      "epoch": 0.0008555617626140123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 235744
    },
    {
      "epoch": 0.0008556778969648491,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 235776
    },
    {
      "epoch": 0.0008557940313156857,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7509,
      "step": 235808
    },
    {
      "epoch": 0.0008559101656665225,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7662,
      "step": 235840
    },
    {
      "epoch": 0.0008560263000173592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 235872
    },
    {
      "epoch": 0.0008561424343681959,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6998,
      "step": 235904
    },
    {
      "epoch": 0.0008562585687190326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6929,
      "step": 235936
    },
    {
      "epoch": 0.0008563747030698693,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7154,
      "step": 235968
    },
    {
      "epoch": 0.000856490837420706,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 236000
    },
    {
      "epoch": 0.0008566069717715427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7099,
      "step": 236032
    },
    {
      "epoch": 0.0008567231061223794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7364,
      "step": 236064
    },
    {
      "epoch": 0.0008568392404732161,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 236096
    },
    {
      "epoch": 0.0008569553748240528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 236128
    },
    {
      "epoch": 0.0008570715091748896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 236160
    },
    {
      "epoch": 0.0008571876435257262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 236192
    },
    {
      "epoch": 0.000857303777876563,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 236224
    },
    {
      "epoch": 0.0008574199122273996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 236256
    },
    {
      "epoch": 0.0008575360465782364,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 236288
    },
    {
      "epoch": 0.000857652180929073,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6987,
      "step": 236320
    },
    {
      "epoch": 0.0008577683152799098,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6934,
      "step": 236352
    },
    {
      "epoch": 0.0008578844496307464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7173,
      "step": 236384
    },
    {
      "epoch": 0.0008580005839815832,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 236416
    },
    {
      "epoch": 0.0008581167183324199,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 236448
    },
    {
      "epoch": 0.0008582328526832566,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 236480
    },
    {
      "epoch": 0.0008583489870340933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 236512
    },
    {
      "epoch": 0.00085846512138493,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6882,
      "step": 236544
    },
    {
      "epoch": 0.0008585812557357667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 236576
    },
    {
      "epoch": 0.0008586973900866034,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 236608
    },
    {
      "epoch": 0.0008588135244374401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7388,
      "step": 236640
    },
    {
      "epoch": 0.0008589296587882768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 236672
    },
    {
      "epoch": 0.0008590457931391135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7649,
      "step": 236704
    },
    {
      "epoch": 0.0008591619274899503,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 236736
    },
    {
      "epoch": 0.0008592780618407869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7347,
      "step": 236768
    },
    {
      "epoch": 0.0008593941961916237,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7307,
      "step": 236800
    },
    {
      "epoch": 0.0008595103305424603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 236832
    },
    {
      "epoch": 0.0008596264648932971,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7003,
      "step": 236864
    },
    {
      "epoch": 0.0008597425992441337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6941,
      "step": 236896
    },
    {
      "epoch": 0.0008598587335949705,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 236928
    },
    {
      "epoch": 0.0008599748679458071,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6863,
      "step": 236960
    },
    {
      "epoch": 0.0008600910022966439,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 236992
    },
    {
      "epoch": 0.0008602071366474806,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 237024
    },
    {
      "epoch": 0.0008603232709983173,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 237056
    },
    {
      "epoch": 0.000860439405349154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.708,
      "step": 237088
    },
    {
      "epoch": 0.0008605555396999907,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 237120
    },
    {
      "epoch": 0.0008606716740508274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 237152
    },
    {
      "epoch": 0.0008607878084016641,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 237184
    },
    {
      "epoch": 0.0008609039427525008,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7161,
      "step": 237216
    },
    {
      "epoch": 0.0008610200771033375,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 237248
    },
    {
      "epoch": 0.0008611362114541742,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 237280
    },
    {
      "epoch": 0.000861252345805011,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 237312
    },
    {
      "epoch": 0.0008613684801558476,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 237344
    },
    {
      "epoch": 0.0008614846145066844,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 237376
    },
    {
      "epoch": 0.000861600748857521,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7025,
      "step": 237408
    },
    {
      "epoch": 0.0008617168832083578,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7248,
      "step": 237440
    },
    {
      "epoch": 0.0008618330175591944,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 237472
    },
    {
      "epoch": 0.0008619491519100312,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 237504
    },
    {
      "epoch": 0.0008620652862608678,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 237536
    },
    {
      "epoch": 0.0008621814206117046,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 237568
    },
    {
      "epoch": 0.0008622975549625413,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7554,
      "step": 237600
    },
    {
      "epoch": 0.000862413689313378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7238,
      "step": 237632
    },
    {
      "epoch": 0.0008625298236642147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7409,
      "step": 237664
    },
    {
      "epoch": 0.0008626459580150514,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 237696
    },
    {
      "epoch": 0.0008627620923658881,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 237728
    },
    {
      "epoch": 0.0008628782267167248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 237760
    },
    {
      "epoch": 0.0008629943610675615,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6897,
      "step": 237792
    },
    {
      "epoch": 0.0008631104954183982,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 237824
    },
    {
      "epoch": 0.000863226629769235,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 237856
    },
    {
      "epoch": 0.0008633427641200717,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 237888
    },
    {
      "epoch": 0.0008634588984709083,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 237920
    },
    {
      "epoch": 0.0008635750328217451,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 237952
    },
    {
      "epoch": 0.0008636911671725817,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 237984
    },
    {
      "epoch": 0.0008638073015234185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7262,
      "step": 238016
    },
    {
      "epoch": 0.0008639234358742551,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 238048
    },
    {
      "epoch": 0.0008640395702250919,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 238080
    },
    {
      "epoch": 0.0008641557045759285,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 238112
    },
    {
      "epoch": 0.0008642718389267653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 238144
    },
    {
      "epoch": 0.0008643879732776021,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 238176
    },
    {
      "epoch": 0.0008645041076284387,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7403,
      "step": 238208
    },
    {
      "epoch": 0.0008646202419792755,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 238240
    },
    {
      "epoch": 0.0008647363763301121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.742,
      "step": 238272
    },
    {
      "epoch": 0.0008648525106809489,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7113,
      "step": 238304
    },
    {
      "epoch": 0.0008649686450317855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 238336
    },
    {
      "epoch": 0.0008650847793826223,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7204,
      "step": 238368
    },
    {
      "epoch": 0.0008652009137334589,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7177,
      "step": 238400
    },
    {
      "epoch": 0.0008653170480842957,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7327,
      "step": 238432
    },
    {
      "epoch": 0.0008654331824351324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7733,
      "step": 238464
    },
    {
      "epoch": 0.0008655493167859691,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7514,
      "step": 238496
    },
    {
      "epoch": 0.0008656654511368058,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 238528
    },
    {
      "epoch": 0.0008657815854876425,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 238560
    },
    {
      "epoch": 0.0008658977198384792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 238592
    },
    {
      "epoch": 0.0008660138541893159,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 238624
    },
    {
      "epoch": 0.0008661299885401526,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 238656
    },
    {
      "epoch": 0.0008662461228909893,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 238688
    },
    {
      "epoch": 0.000866362257241826,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 238720
    },
    {
      "epoch": 0.0008664783915926628,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7368,
      "step": 238752
    },
    {
      "epoch": 0.0008665945259434994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7435,
      "step": 238784
    },
    {
      "epoch": 0.0008667106602943362,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 238816
    },
    {
      "epoch": 0.0008668267946451728,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 238848
    },
    {
      "epoch": 0.0008669429289960096,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7389,
      "step": 238880
    },
    {
      "epoch": 0.0008670590633468462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7347,
      "step": 238912
    },
    {
      "epoch": 0.000867175197697683,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 238944
    },
    {
      "epoch": 0.0008672913320485196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 238976
    },
    {
      "epoch": 0.0008674074663993564,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 239008
    },
    {
      "epoch": 0.0008675236007501931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7334,
      "step": 239040
    },
    {
      "epoch": 0.0008676397351010298,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7309,
      "step": 239072
    },
    {
      "epoch": 0.0008677558694518665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7383,
      "step": 239104
    },
    {
      "epoch": 0.0008678720038027032,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 239136
    },
    {
      "epoch": 0.0008679881381535399,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 239168
    },
    {
      "epoch": 0.0008681042725043766,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 239200
    },
    {
      "epoch": 0.0008682204068552133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6995,
      "step": 239232
    },
    {
      "epoch": 0.00086833654120605,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 239264
    },
    {
      "epoch": 0.0008684526755568867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7082,
      "step": 239296
    },
    {
      "epoch": 0.0008685688099077235,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7418,
      "step": 239328
    },
    {
      "epoch": 0.0008686849442585601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7394,
      "step": 239360
    },
    {
      "epoch": 0.0008688010786093969,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 239392
    },
    {
      "epoch": 0.0008689172129602335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 239424
    },
    {
      "epoch": 0.0008690333473110703,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6928,
      "step": 239456
    },
    {
      "epoch": 0.0008691494816619069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6931,
      "step": 239488
    },
    {
      "epoch": 0.0008692656160127437,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 239520
    },
    {
      "epoch": 0.0008693817503635803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 239552
    },
    {
      "epoch": 0.0008694978847144171,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 239584
    },
    {
      "epoch": 0.0008696140190652538,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 239616
    },
    {
      "epoch": 0.0008697301534160905,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 239648
    },
    {
      "epoch": 0.0008698462877669272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 239680
    },
    {
      "epoch": 0.0008699624221177639,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 239712
    },
    {
      "epoch": 0.0008700785564686006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7277,
      "step": 239744
    },
    {
      "epoch": 0.0008701946908194373,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 239776
    },
    {
      "epoch": 0.000870310825170274,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 239808
    },
    {
      "epoch": 0.0008704269595211107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6834,
      "step": 239840
    },
    {
      "epoch": 0.0008705430938719474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6942,
      "step": 239872
    },
    {
      "epoch": 0.0008706592282227842,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 239904
    },
    {
      "epoch": 0.0008707753625736208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 239936
    },
    {
      "epoch": 0.0008708914969244576,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 239968
    },
    {
      "epoch": 0.0008710076312752942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 240000
    },
    {
      "epoch": 0.000871123765626131,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 240032
    },
    {
      "epoch": 0.0008712398999769676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7251,
      "step": 240064
    },
    {
      "epoch": 0.0008713560343278044,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.727,
      "step": 240096
    },
    {
      "epoch": 0.000871472168678641,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 240128
    },
    {
      "epoch": 0.0008715883030294778,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 240160
    },
    {
      "epoch": 0.0008717044373803145,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7032,
      "step": 240192
    },
    {
      "epoch": 0.0008718205717311512,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7625,
      "step": 240224
    },
    {
      "epoch": 0.0008719367060819879,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 240256
    },
    {
      "epoch": 0.0008720528404328246,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6985,
      "step": 240288
    },
    {
      "epoch": 0.0008721689747836613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 240320
    },
    {
      "epoch": 0.000872285109134498,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 240352
    },
    {
      "epoch": 0.0008724012434853347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7089,
      "step": 240384
    },
    {
      "epoch": 0.0008725173778361714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 240416
    },
    {
      "epoch": 0.0008726335121870081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 240448
    },
    {
      "epoch": 0.0008727496465378449,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7012,
      "step": 240480
    },
    {
      "epoch": 0.0008728657808886815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 240512
    },
    {
      "epoch": 0.0008729819152395183,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7306,
      "step": 240544
    },
    {
      "epoch": 0.0008730980495903549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 240576
    },
    {
      "epoch": 0.0008732141839411917,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 240608
    },
    {
      "epoch": 0.0008733303182920283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 240640
    },
    {
      "epoch": 0.0008734464526428651,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 240672
    },
    {
      "epoch": 0.0008735625869937017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 240704
    },
    {
      "epoch": 0.0008736787213445385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 240736
    },
    {
      "epoch": 0.0008737948556953752,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7278,
      "step": 240768
    },
    {
      "epoch": 0.0008739109900462119,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7192,
      "step": 240800
    },
    {
      "epoch": 0.0008740271243970486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 240832
    },
    {
      "epoch": 0.0008741432587478853,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6919,
      "step": 240864
    },
    {
      "epoch": 0.000874259393098722,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 240896
    },
    {
      "epoch": 0.0008743755274495587,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 240928
    },
    {
      "epoch": 0.0008744916618003954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7331,
      "step": 240960
    },
    {
      "epoch": 0.0008746077961512321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7436,
      "step": 240992
    },
    {
      "epoch": 0.0008747239305020688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 241024
    },
    {
      "epoch": 0.0008748400648529056,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.69,
      "step": 241056
    },
    {
      "epoch": 0.0008749561992037422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7354,
      "step": 241088
    },
    {
      "epoch": 0.000875072333554579,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7495,
      "step": 241120
    },
    {
      "epoch": 0.0008751884679054156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 241152
    },
    {
      "epoch": 0.0008753046022562524,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 241184
    },
    {
      "epoch": 0.000875420736607089,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6963,
      "step": 241216
    },
    {
      "epoch": 0.0008755368709579258,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6877,
      "step": 241248
    },
    {
      "epoch": 0.0008756530053087624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.698,
      "step": 241280
    },
    {
      "epoch": 0.0008757691396595992,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 241312
    },
    {
      "epoch": 0.0008758852740104359,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 241344
    },
    {
      "epoch": 0.0008760014083612726,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 241376
    },
    {
      "epoch": 0.0008761175427121093,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 241408
    },
    {
      "epoch": 0.000876233677062946,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 241440
    },
    {
      "epoch": 0.0008763498114137827,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.711,
      "step": 241472
    },
    {
      "epoch": 0.0008764659457646194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7345,
      "step": 241504
    },
    {
      "epoch": 0.0008765820801154561,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 241536
    },
    {
      "epoch": 0.0008766982144662928,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7302,
      "step": 241568
    },
    {
      "epoch": 0.0008768143488171295,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 241600
    },
    {
      "epoch": 0.0008769304831679663,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 241632
    },
    {
      "epoch": 0.0008770466175188029,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 241664
    },
    {
      "epoch": 0.0008771627518696397,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7453,
      "step": 241696
    },
    {
      "epoch": 0.0008772788862204763,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.735,
      "step": 241728
    },
    {
      "epoch": 0.0008773950205713131,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 241760
    },
    {
      "epoch": 0.0008775111549221497,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 241792
    },
    {
      "epoch": 0.0008776272892729865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 241824
    },
    {
      "epoch": 0.0008777434236238231,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 241856
    },
    {
      "epoch": 0.0008778595579746599,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6959,
      "step": 241888
    },
    {
      "epoch": 0.0008779756923254967,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 241920
    },
    {
      "epoch": 0.0008780918266763333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7013,
      "step": 241952
    },
    {
      "epoch": 0.00087820796102717,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7533,
      "step": 241984
    },
    {
      "epoch": 0.0008783240953780067,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 242016
    },
    {
      "epoch": 0.0008784402297288435,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 242048
    },
    {
      "epoch": 0.0008785563640796801,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 242080
    },
    {
      "epoch": 0.0008786724984305169,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.688,
      "step": 242112
    },
    {
      "epoch": 0.0008787886327813535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 242144
    },
    {
      "epoch": 0.0008789047671321903,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 242176
    },
    {
      "epoch": 0.000879020901483027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 242208
    },
    {
      "epoch": 0.0008791370358338636,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6982,
      "step": 242240
    },
    {
      "epoch": 0.0008792531701847004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 242272
    },
    {
      "epoch": 0.000879369304535537,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7295,
      "step": 242304
    },
    {
      "epoch": 0.0008794854388863738,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6949,
      "step": 242336
    },
    {
      "epoch": 0.0008796015732372104,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 242368
    },
    {
      "epoch": 0.0008797177075880472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 242400
    },
    {
      "epoch": 0.0008798338419388838,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7048,
      "step": 242432
    },
    {
      "epoch": 0.0008799499762897206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.684,
      "step": 242464
    },
    {
      "epoch": 0.0008800661106405572,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 242496
    },
    {
      "epoch": 0.000880182244991394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7331,
      "step": 242528
    },
    {
      "epoch": 0.0008802983793422308,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 242560
    },
    {
      "epoch": 0.0008804145136930674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 242592
    },
    {
      "epoch": 0.0008805306480439042,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.68,
      "step": 242624
    },
    {
      "epoch": 0.0008806467823947408,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7195,
      "step": 242656
    },
    {
      "epoch": 0.0008807629167455776,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.712,
      "step": 242688
    },
    {
      "epoch": 0.0008808790510964142,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7153,
      "step": 242720
    },
    {
      "epoch": 0.000880995185447251,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 242752
    },
    {
      "epoch": 0.0008811113197980876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7222,
      "step": 242784
    },
    {
      "epoch": 0.0008812274541489244,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 242816
    },
    {
      "epoch": 0.0008813435884997611,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7404,
      "step": 242848
    },
    {
      "epoch": 0.0008814597228505978,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7442,
      "step": 242880
    },
    {
      "epoch": 0.0008815758572014345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 242912
    },
    {
      "epoch": 0.0008816919915522712,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.718,
      "step": 242944
    },
    {
      "epoch": 0.0008818081259031079,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 242976
    },
    {
      "epoch": 0.0008819242602539446,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7018,
      "step": 243008
    },
    {
      "epoch": 0.0008820403946047813,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 243040
    },
    {
      "epoch": 0.000882156528955618,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 243072
    },
    {
      "epoch": 0.0008822726633064547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 243104
    },
    {
      "epoch": 0.0008823887976572915,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7422,
      "step": 243136
    },
    {
      "epoch": 0.0008825049320081281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 243168
    },
    {
      "epoch": 0.0008826210663589649,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 243200
    },
    {
      "epoch": 0.0008827372007098015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 243232
    },
    {
      "epoch": 0.0008828533350606383,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.734,
      "step": 243264
    },
    {
      "epoch": 0.0008829694694114749,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 243296
    },
    {
      "epoch": 0.0008830856037623117,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 243328
    },
    {
      "epoch": 0.0008832017381131483,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 243360
    },
    {
      "epoch": 0.0008833178724639851,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7334,
      "step": 243392
    },
    {
      "epoch": 0.0008834340068148218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.742,
      "step": 243424
    },
    {
      "epoch": 0.0008835501411656585,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 243456
    },
    {
      "epoch": 0.0008836662755164952,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7232,
      "step": 243488
    },
    {
      "epoch": 0.0008837824098673319,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7177,
      "step": 243520
    },
    {
      "epoch": 0.0008838985442181686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 243552
    },
    {
      "epoch": 0.0008840146785690053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7272,
      "step": 243584
    },
    {
      "epoch": 0.000884130812919842,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 243616
    },
    {
      "epoch": 0.0008842469472706787,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 243648
    },
    {
      "epoch": 0.0008843630816215154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7257,
      "step": 243680
    },
    {
      "epoch": 0.0008844792159723522,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 243712
    },
    {
      "epoch": 0.0008845953503231888,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7607,
      "step": 243744
    },
    {
      "epoch": 0.0008847114846740256,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 243776
    },
    {
      "epoch": 0.0008848276190248622,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 243808
    },
    {
      "epoch": 0.000884943753375699,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 243840
    },
    {
      "epoch": 0.0008850598877265356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 243872
    },
    {
      "epoch": 0.0008851760220773724,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 243904
    },
    {
      "epoch": 0.000885292156428209,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 243936
    },
    {
      "epoch": 0.0008854082907790458,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 243968
    },
    {
      "epoch": 0.0008855244251298825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7332,
      "step": 244000
    },
    {
      "epoch": 0.0008856405594807192,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7323,
      "step": 244032
    },
    {
      "epoch": 0.0008857566938315559,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 244064
    },
    {
      "epoch": 0.0008858728281823926,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7087,
      "step": 244096
    },
    {
      "epoch": 0.0008859889625332293,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7186,
      "step": 244128
    },
    {
      "epoch": 0.000886105096884066,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7215,
      "step": 244160
    },
    {
      "epoch": 0.0008862212312349027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 244192
    },
    {
      "epoch": 0.0008863373655857394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6837,
      "step": 244224
    },
    {
      "epoch": 0.0008864534999365761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 244256
    },
    {
      "epoch": 0.0008865696342874129,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7139,
      "step": 244288
    },
    {
      "epoch": 0.0008866857686382495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7132,
      "step": 244320
    },
    {
      "epoch": 0.0008868019029890863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 244352
    },
    {
      "epoch": 0.0008869180373399229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6911,
      "step": 244384
    },
    {
      "epoch": 0.0008870341716907597,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 244416
    },
    {
      "epoch": 0.0008871503060415963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 244448
    },
    {
      "epoch": 0.0008872664403924331,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 244480
    },
    {
      "epoch": 0.0008873825747432697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 244512
    },
    {
      "epoch": 0.0008874987090941065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7327,
      "step": 244544
    },
    {
      "epoch": 0.0008876148434449432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6983,
      "step": 244576
    },
    {
      "epoch": 0.0008877309777957799,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7421,
      "step": 244608
    },
    {
      "epoch": 0.0008878471121466166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7347,
      "step": 244640
    },
    {
      "epoch": 0.0008879632464974533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7297,
      "step": 244672
    },
    {
      "epoch": 0.00088807938084829,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 244704
    },
    {
      "epoch": 0.0008881955151991267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6924,
      "step": 244736
    },
    {
      "epoch": 0.0008883116495499634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.691,
      "step": 244768
    },
    {
      "epoch": 0.0008884277839008001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6819,
      "step": 244800
    },
    {
      "epoch": 0.0008885439182516368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7137,
      "step": 244832
    },
    {
      "epoch": 0.0008886600526024736,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6984,
      "step": 244864
    },
    {
      "epoch": 0.0008887761869533102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 244896
    },
    {
      "epoch": 0.000888892321304147,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7208,
      "step": 244928
    },
    {
      "epoch": 0.0008890084556549836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 244960
    },
    {
      "epoch": 0.0008891245900058204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7286,
      "step": 244992
    },
    {
      "epoch": 0.000889240724356657,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7456,
      "step": 245024
    },
    {
      "epoch": 0.0008893568587074938,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7133,
      "step": 245056
    },
    {
      "epoch": 0.0008894729930583304,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6906,
      "step": 245088
    },
    {
      "epoch": 0.0008895891274091672,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 245120
    },
    {
      "epoch": 0.0008897052617600039,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.716,
      "step": 245152
    },
    {
      "epoch": 0.0008898213961108406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 245184
    },
    {
      "epoch": 0.0008899375304616773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 245216
    },
    {
      "epoch": 0.000890053664812514,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 245248
    },
    {
      "epoch": 0.0008901697991633507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 245280
    },
    {
      "epoch": 0.0008902859335141874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 245312
    },
    {
      "epoch": 0.0008904020678650241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7338,
      "step": 245344
    },
    {
      "epoch": 0.0008905182022158608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6988,
      "step": 245376
    },
    {
      "epoch": 0.0008906343365666975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 245408
    },
    {
      "epoch": 0.0008907504709175343,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 245440
    },
    {
      "epoch": 0.0008908666052683709,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 245472
    },
    {
      "epoch": 0.0008909827396192077,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7407,
      "step": 245504
    },
    {
      "epoch": 0.0008910988739700443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 245536
    },
    {
      "epoch": 0.0008912150083208811,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6891,
      "step": 245568
    },
    {
      "epoch": 0.0008913311426717177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7041,
      "step": 245600
    },
    {
      "epoch": 0.0008914472770225545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7028,
      "step": 245632
    },
    {
      "epoch": 0.0008915634113733911,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7083,
      "step": 245664
    },
    {
      "epoch": 0.0008916795457242279,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 245696
    },
    {
      "epoch": 0.0008917956800750646,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7039,
      "step": 245728
    },
    {
      "epoch": 0.0008919118144259013,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7049,
      "step": 245760
    },
    {
      "epoch": 0.000892027948776738,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6985,
      "step": 245792
    },
    {
      "epoch": 0.0008921440831275747,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7333,
      "step": 245824
    },
    {
      "epoch": 0.0008922602174784114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7153,
      "step": 245856
    },
    {
      "epoch": 0.0008923763518292481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 245888
    },
    {
      "epoch": 0.0008924924861800848,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.749,
      "step": 245920
    },
    {
      "epoch": 0.0008926086205309215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 245952
    },
    {
      "epoch": 0.0008927247548817582,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6786,
      "step": 245984
    },
    {
      "epoch": 0.000892840889232595,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7102,
      "step": 246016
    },
    {
      "epoch": 0.0008929570235834316,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7309,
      "step": 246048
    },
    {
      "epoch": 0.0008930731579342684,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 246080
    },
    {
      "epoch": 0.000893189292285105,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 246112
    },
    {
      "epoch": 0.0008933054266359418,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 246144
    },
    {
      "epoch": 0.0008934215609867784,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 246176
    },
    {
      "epoch": 0.0008935376953376152,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 246208
    },
    {
      "epoch": 0.0008936538296884518,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 246240
    },
    {
      "epoch": 0.0008937699640392886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7165,
      "step": 246272
    },
    {
      "epoch": 0.0008938860983901254,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 246304
    },
    {
      "epoch": 0.000894002232740962,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7152,
      "step": 246336
    },
    {
      "epoch": 0.0008941183670917988,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7385,
      "step": 246368
    },
    {
      "epoch": 0.0008942345014426354,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 246400
    },
    {
      "epoch": 0.0008943506357934722,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.719,
      "step": 246432
    },
    {
      "epoch": 0.0008944667701443088,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 246464
    },
    {
      "epoch": 0.0008945829044951456,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 246496
    },
    {
      "epoch": 0.0008946990388459822,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7096,
      "step": 246528
    },
    {
      "epoch": 0.000894815173196819,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 246560
    },
    {
      "epoch": 0.0008949313075476557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 246592
    },
    {
      "epoch": 0.0008950474418984924,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7488,
      "step": 246624
    },
    {
      "epoch": 0.0008951635762493291,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7283,
      "step": 246656
    },
    {
      "epoch": 0.0008952797106001658,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 246688
    },
    {
      "epoch": 0.0008953958449510025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6892,
      "step": 246720
    },
    {
      "epoch": 0.0008955119793018392,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6992,
      "step": 246752
    },
    {
      "epoch": 0.0008956281136526759,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 246784
    },
    {
      "epoch": 0.0008957442480035126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 246816
    },
    {
      "epoch": 0.0008958603823543493,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6893,
      "step": 246848
    },
    {
      "epoch": 0.0008959765167051861,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 246880
    },
    {
      "epoch": 0.0008960926510560227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7142,
      "step": 246912
    },
    {
      "epoch": 0.0008962087854068595,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 246944
    },
    {
      "epoch": 0.0008963249197576961,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 246976
    },
    {
      "epoch": 0.0008964410541085329,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 247008
    },
    {
      "epoch": 0.0008965571884593695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7124,
      "step": 247040
    },
    {
      "epoch": 0.0008966733228102063,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7147,
      "step": 247072
    },
    {
      "epoch": 0.0008967894571610429,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7267,
      "step": 247104
    },
    {
      "epoch": 0.0008969055915118797,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6929,
      "step": 247136
    },
    {
      "epoch": 0.0008970217258627164,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7051,
      "step": 247168
    },
    {
      "epoch": 0.0008971378602135531,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 247200
    },
    {
      "epoch": 0.0008972539945643898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7349,
      "step": 247232
    },
    {
      "epoch": 0.0008973701289152265,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7282,
      "step": 247264
    },
    {
      "epoch": 0.0008974862632660632,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 247296
    },
    {
      "epoch": 0.0008976023976168999,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6936,
      "step": 247328
    },
    {
      "epoch": 0.0008977185319677366,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 247360
    },
    {
      "epoch": 0.0008978346663185733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6951,
      "step": 247392
    },
    {
      "epoch": 0.00089795080066941,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7,
      "step": 247424
    },
    {
      "epoch": 0.0008980669350202468,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 247456
    },
    {
      "epoch": 0.0008981830693710834,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 247488
    },
    {
      "epoch": 0.0008982992037219202,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7317,
      "step": 247520
    },
    {
      "epoch": 0.0008984153380727568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6922,
      "step": 247552
    },
    {
      "epoch": 0.0008985314724235936,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7255,
      "step": 247584
    },
    {
      "epoch": 0.0008986476067744302,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 247616
    },
    {
      "epoch": 0.000898763741125267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7221,
      "step": 247648
    },
    {
      "epoch": 0.0008988798754761036,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7203,
      "step": 247680
    },
    {
      "epoch": 0.0008989960098269404,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 247712
    },
    {
      "epoch": 0.0008991121441777771,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6986,
      "step": 247744
    },
    {
      "epoch": 0.0008992282785286138,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7169,
      "step": 247776
    },
    {
      "epoch": 0.0008993444128794505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 247808
    },
    {
      "epoch": 0.0008994605472302872,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 247840
    },
    {
      "epoch": 0.0008995766815811239,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7337,
      "step": 247872
    },
    {
      "epoch": 0.0008996928159319606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7027,
      "step": 247904
    },
    {
      "epoch": 0.0008998089502827973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 247936
    },
    {
      "epoch": 0.000899925084633634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7341,
      "step": 247968
    },
    {
      "epoch": 0.0009000412189844707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7129,
      "step": 248000
    },
    {
      "epoch": 0.0009001573533353075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7196,
      "step": 248032
    },
    {
      "epoch": 0.0009002734876861441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7434,
      "step": 248064
    },
    {
      "epoch": 0.0009003896220369809,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7179,
      "step": 248096
    },
    {
      "epoch": 0.0009005057563878175,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7387,
      "step": 248128
    },
    {
      "epoch": 0.0009006218907386543,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.733,
      "step": 248160
    },
    {
      "epoch": 0.0009007380250894909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7294,
      "step": 248192
    },
    {
      "epoch": 0.0009008541594403277,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 248224
    },
    {
      "epoch": 0.0009009702937911643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 248256
    },
    {
      "epoch": 0.0009010864281420011,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 248288
    },
    {
      "epoch": 0.0009012025624928378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7218,
      "step": 248320
    },
    {
      "epoch": 0.0009013186968436745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7392,
      "step": 248352
    },
    {
      "epoch": 0.0009014348311945112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 248384
    },
    {
      "epoch": 0.0009015509655453479,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7042,
      "step": 248416
    },
    {
      "epoch": 0.0009016670998961846,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 248448
    },
    {
      "epoch": 0.0009017832342470213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 248480
    },
    {
      "epoch": 0.000901899368597858,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 248512
    },
    {
      "epoch": 0.0009020155029486947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7431,
      "step": 248544
    },
    {
      "epoch": 0.0009021316372995314,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7217,
      "step": 248576
    },
    {
      "epoch": 0.0009022477716503682,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7064,
      "step": 248608
    },
    {
      "epoch": 0.0009023639060012048,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 248640
    },
    {
      "epoch": 0.0009024800403520416,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 248672
    },
    {
      "epoch": 0.0009025961747028782,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 248704
    },
    {
      "epoch": 0.000902712309053715,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 248736
    },
    {
      "epoch": 0.0009028284434045516,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7405,
      "step": 248768
    },
    {
      "epoch": 0.0009029445777553884,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7336,
      "step": 248800
    },
    {
      "epoch": 0.000903060712106225,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 248832
    },
    {
      "epoch": 0.0009031768464570618,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7319,
      "step": 248864
    },
    {
      "epoch": 0.0009032929808078985,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7156,
      "step": 248896
    },
    {
      "epoch": 0.0009034091151587352,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 248928
    },
    {
      "epoch": 0.0009035252495095719,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7316,
      "step": 248960
    },
    {
      "epoch": 0.0009036413838604086,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7538,
      "step": 248992
    },
    {
      "epoch": 0.0009037575182112453,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 249024
    },
    {
      "epoch": 0.000903873652562082,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 249056
    },
    {
      "epoch": 0.0009039897869129187,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 249088
    },
    {
      "epoch": 0.0009041059212637554,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 249120
    },
    {
      "epoch": 0.0009042220556145921,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6927,
      "step": 249152
    },
    {
      "epoch": 0.0009043381899654289,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6879,
      "step": 249184
    },
    {
      "epoch": 0.0009044543243162655,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7219,
      "step": 249216
    },
    {
      "epoch": 0.0009045704586671023,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 249248
    },
    {
      "epoch": 0.0009046865930179389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 249280
    },
    {
      "epoch": 0.0009048027273687757,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6979,
      "step": 249312
    },
    {
      "epoch": 0.0009049188617196123,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 249344
    },
    {
      "epoch": 0.0009050349960704491,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7161,
      "step": 249376
    },
    {
      "epoch": 0.0009051511304212857,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 249408
    },
    {
      "epoch": 0.0009052672647721225,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 249440
    },
    {
      "epoch": 0.0009053833991229592,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 249472
    },
    {
      "epoch": 0.0009054995334737959,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 249504
    },
    {
      "epoch": 0.0009056156678246326,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 249536
    },
    {
      "epoch": 0.0009057318021754693,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7259,
      "step": 249568
    },
    {
      "epoch": 0.000905847936526306,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 249600
    },
    {
      "epoch": 0.0009059640708771427,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7289,
      "step": 249632
    },
    {
      "epoch": 0.0009060802052279794,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7094,
      "step": 249664
    },
    {
      "epoch": 0.0009061963395788161,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 249696
    },
    {
      "epoch": 0.0009063124739296528,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 249728
    },
    {
      "epoch": 0.0009064286082804896,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 249760
    },
    {
      "epoch": 0.0009065447426313262,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 249792
    },
    {
      "epoch": 0.000906660876982163,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7074,
      "step": 249824
    },
    {
      "epoch": 0.0009067770113329996,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 249856
    },
    {
      "epoch": 0.0009068931456838364,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 249888
    },
    {
      "epoch": 0.000907009280034673,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7342,
      "step": 249920
    },
    {
      "epoch": 0.0009071254143855098,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7376,
      "step": 249952
    },
    {
      "epoch": 0.0009072415487363464,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 249984
    },
    {
      "epoch": 0.0009073576830871832,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6841,
      "step": 250016
    },
    {
      "epoch": 0.00090747381743802,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6931,
      "step": 250048
    },
    {
      "epoch": 0.0009075899517888566,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 250080
    },
    {
      "epoch": 0.0009077060861396933,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 250112
    },
    {
      "epoch": 0.00090782222049053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7182,
      "step": 250144
    },
    {
      "epoch": 0.0009079383548413667,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6909,
      "step": 250176
    },
    {
      "epoch": 0.0009080544891922034,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 250208
    },
    {
      "epoch": 0.0009081706235430401,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 250240
    },
    {
      "epoch": 0.0009082867578938768,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7244,
      "step": 250272
    },
    {
      "epoch": 0.0009084028922447135,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 250304
    },
    {
      "epoch": 0.0009085190265955503,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7077,
      "step": 250336
    },
    {
      "epoch": 0.0009086351609463869,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6881,
      "step": 250368
    },
    {
      "epoch": 0.0009087512952972237,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7193,
      "step": 250400
    },
    {
      "epoch": 0.0009088674296480603,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 250432
    },
    {
      "epoch": 0.0009089835639988971,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7053,
      "step": 250464
    },
    {
      "epoch": 0.0009090996983497337,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7026,
      "step": 250496
    },
    {
      "epoch": 0.0009092158327005705,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 250528
    },
    {
      "epoch": 0.0009093319670514071,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.722,
      "step": 250560
    },
    {
      "epoch": 0.0009094481014022439,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 250592
    },
    {
      "epoch": 0.0009095642357530807,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7247,
      "step": 250624
    },
    {
      "epoch": 0.0009096803701039173,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 250656
    },
    {
      "epoch": 0.000909796504454754,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 250688
    },
    {
      "epoch": 0.0009099126388055907,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 250720
    },
    {
      "epoch": 0.0009100287731564275,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7438,
      "step": 250752
    },
    {
      "epoch": 0.0009101449075072641,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 250784
    },
    {
      "epoch": 0.0009102610418581009,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7241,
      "step": 250816
    },
    {
      "epoch": 0.0009103771762089375,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 250848
    },
    {
      "epoch": 0.0009104933105597743,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 250880
    },
    {
      "epoch": 0.000910609444910611,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6783,
      "step": 250912
    },
    {
      "epoch": 0.0009107255792614477,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6954,
      "step": 250944
    },
    {
      "epoch": 0.0009108417136122844,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.73,
      "step": 250976
    },
    {
      "epoch": 0.000910957847963121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 251008
    },
    {
      "epoch": 0.0009110739823139578,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 251040
    },
    {
      "epoch": 0.0009111901166647945,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7047,
      "step": 251072
    },
    {
      "epoch": 0.0009113062510156312,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7115,
      "step": 251104
    },
    {
      "epoch": 0.0009114223853664679,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7266,
      "step": 251136
    },
    {
      "epoch": 0.0009115385197173046,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7311,
      "step": 251168
    },
    {
      "epoch": 0.0009116546540681414,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 251200
    },
    {
      "epoch": 0.000911770788418978,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6791,
      "step": 251232
    },
    {
      "epoch": 0.0009118869227698148,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6982,
      "step": 251264
    },
    {
      "epoch": 0.0009120030571206514,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7183,
      "step": 251296
    },
    {
      "epoch": 0.0009121191914714882,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 251328
    },
    {
      "epoch": 0.0009122353258223248,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7035,
      "step": 251360
    },
    {
      "epoch": 0.0009123514601731616,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7279,
      "step": 251392
    },
    {
      "epoch": 0.0009124675945239982,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7388,
      "step": 251424
    },
    {
      "epoch": 0.000912583728874835,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7174,
      "step": 251456
    },
    {
      "epoch": 0.0009126998632256717,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7374,
      "step": 251488
    },
    {
      "epoch": 0.0009128159975765084,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7213,
      "step": 251520
    },
    {
      "epoch": 0.0009129321319273451,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7345,
      "step": 251552
    },
    {
      "epoch": 0.0009130482662781818,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7336,
      "step": 251584
    },
    {
      "epoch": 0.0009131644006290185,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 251616
    },
    {
      "epoch": 0.0009132805349798552,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 251648
    },
    {
      "epoch": 0.0009133966693306919,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 251680
    },
    {
      "epoch": 0.0009135128036815286,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 251712
    },
    {
      "epoch": 0.0009136289380323653,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6974,
      "step": 251744
    },
    {
      "epoch": 0.0009137450723832021,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6897,
      "step": 251776
    },
    {
      "epoch": 0.0009138612067340387,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6926,
      "step": 251808
    },
    {
      "epoch": 0.0009139773410848755,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 251840
    },
    {
      "epoch": 0.0009140934754357121,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6991,
      "step": 251872
    },
    {
      "epoch": 0.0009142096097865489,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7104,
      "step": 251904
    },
    {
      "epoch": 0.0009143257441373855,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7009,
      "step": 251936
    },
    {
      "epoch": 0.0009144418784882223,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6989,
      "step": 251968
    },
    {
      "epoch": 0.0009145580128390589,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7237,
      "step": 252000
    },
    {
      "epoch": 0.0009146741471898957,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7253,
      "step": 252032
    },
    {
      "epoch": 0.0009147902815407324,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 252064
    },
    {
      "epoch": 0.0009149064158915691,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7029,
      "step": 252096
    },
    {
      "epoch": 0.0009150225502424058,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6912,
      "step": 252128
    },
    {
      "epoch": 0.0009151386845932425,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 252160
    },
    {
      "epoch": 0.0009152548189440792,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 252192
    },
    {
      "epoch": 0.0009153709532949159,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6918,
      "step": 252224
    },
    {
      "epoch": 0.0009154870876457526,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7159,
      "step": 252256
    },
    {
      "epoch": 0.0009156032219965893,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7166,
      "step": 252288
    },
    {
      "epoch": 0.000915719356347426,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7235,
      "step": 252320
    },
    {
      "epoch": 0.0009158354906982628,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 252352
    },
    {
      "epoch": 0.0009159516250490994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 252384
    },
    {
      "epoch": 0.0009160677593999362,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 252416
    },
    {
      "epoch": 0.0009161838937507728,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7325,
      "step": 252448
    },
    {
      "epoch": 0.0009163000281016096,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 252480
    },
    {
      "epoch": 0.0009164161624524462,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7339,
      "step": 252512
    },
    {
      "epoch": 0.000916532296803283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7223,
      "step": 252544
    },
    {
      "epoch": 0.0009166484311541196,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7226,
      "step": 252576
    },
    {
      "epoch": 0.0009167645655049564,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7103,
      "step": 252608
    },
    {
      "epoch": 0.0009168806998557931,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 252640
    },
    {
      "epoch": 0.0009169968342066298,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7017,
      "step": 252672
    },
    {
      "epoch": 0.0009171129685574665,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 252704
    },
    {
      "epoch": 0.0009172291029083032,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7207,
      "step": 252736
    },
    {
      "epoch": 0.0009173452372591399,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 252768
    },
    {
      "epoch": 0.0009174613716099766,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 252800
    },
    {
      "epoch": 0.0009175775059608133,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 252832
    },
    {
      "epoch": 0.00091769364031165,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.725,
      "step": 252864
    },
    {
      "epoch": 0.0009178097746624867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7561,
      "step": 252896
    },
    {
      "epoch": 0.0009179259090133235,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7309,
      "step": 252928
    },
    {
      "epoch": 0.0009180420433641601,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 252960
    },
    {
      "epoch": 0.0009181581777149969,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7119,
      "step": 252992
    },
    {
      "epoch": 0.0009182743120658335,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7078,
      "step": 253024
    },
    {
      "epoch": 0.0009183904464166703,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.72,
      "step": 253056
    },
    {
      "epoch": 0.0009185065807675069,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 253088
    },
    {
      "epoch": 0.0009186227151183437,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7184,
      "step": 253120
    },
    {
      "epoch": 0.0009187388494691803,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7123,
      "step": 253152
    },
    {
      "epoch": 0.0009188549838200171,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.744,
      "step": 253184
    },
    {
      "epoch": 0.0009189711181708537,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7185,
      "step": 253216
    },
    {
      "epoch": 0.0009190872525216905,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7481,
      "step": 253248
    },
    {
      "epoch": 0.0009192033868725272,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7423,
      "step": 253280
    },
    {
      "epoch": 0.0009193195212233639,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 253312
    },
    {
      "epoch": 0.0009194356555742006,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7188,
      "step": 253344
    },
    {
      "epoch": 0.0009195517899250373,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.74,
      "step": 253376
    },
    {
      "epoch": 0.000919667924275874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7263,
      "step": 253408
    },
    {
      "epoch": 0.0009197840586267107,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7135,
      "step": 253440
    },
    {
      "epoch": 0.0009199001929775474,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7387,
      "step": 253472
    },
    {
      "epoch": 0.0009200163273283841,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7292,
      "step": 253504
    },
    {
      "epoch": 0.0009201324616792208,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6939,
      "step": 253536
    },
    {
      "epoch": 0.0009202485960300576,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 253568
    },
    {
      "epoch": 0.0009203647303808942,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 253600
    },
    {
      "epoch": 0.000920480864731731,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 253632
    },
    {
      "epoch": 0.0009205969990825676,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7252,
      "step": 253664
    },
    {
      "epoch": 0.0009207131334334044,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7353,
      "step": 253696
    },
    {
      "epoch": 0.000920829267784241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.704,
      "step": 253728
    },
    {
      "epoch": 0.0009209454021350778,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7387,
      "step": 253760
    },
    {
      "epoch": 0.0009210615364859144,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7358,
      "step": 253792
    },
    {
      "epoch": 0.0009211776708367512,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7386,
      "step": 253824
    },
    {
      "epoch": 0.0009212938051875879,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7197,
      "step": 253856
    },
    {
      "epoch": 0.0009214099395384246,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 253888
    },
    {
      "epoch": 0.0009215260738892613,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7416,
      "step": 253920
    },
    {
      "epoch": 0.000921642208240098,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 253952
    },
    {
      "epoch": 0.0009217583425909347,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6962,
      "step": 253984
    },
    {
      "epoch": 0.0009218744769417714,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7071,
      "step": 254016
    },
    {
      "epoch": 0.0009219906112926081,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 254048
    },
    {
      "epoch": 0.0009221067456434448,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7172,
      "step": 254080
    },
    {
      "epoch": 0.0009222228799942815,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7218,
      "step": 254112
    },
    {
      "epoch": 0.0009223390143451183,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7055,
      "step": 254144
    },
    {
      "epoch": 0.0009224551486959549,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7045,
      "step": 254176
    },
    {
      "epoch": 0.0009225712830467917,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 254208
    },
    {
      "epoch": 0.0009226874173976283,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 254240
    },
    {
      "epoch": 0.0009228035517484651,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7343,
      "step": 254272
    },
    {
      "epoch": 0.0009229196860993017,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7145,
      "step": 254304
    },
    {
      "epoch": 0.0009230358204501385,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7212,
      "step": 254336
    },
    {
      "epoch": 0.0009231519548009751,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7128,
      "step": 254368
    },
    {
      "epoch": 0.0009232680891518119,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 254400
    },
    {
      "epoch": 0.0009233842235026486,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 254432
    },
    {
      "epoch": 0.0009235003578534853,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 254464
    },
    {
      "epoch": 0.000923616492204322,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7121,
      "step": 254496
    },
    {
      "epoch": 0.0009237326265551587,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7164,
      "step": 254528
    },
    {
      "epoch": 0.0009238487609059954,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 254560
    },
    {
      "epoch": 0.0009239648952568321,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7059,
      "step": 254592
    },
    {
      "epoch": 0.0009240810296076688,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7162,
      "step": 254624
    },
    {
      "epoch": 0.0009241971639585055,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7343,
      "step": 254656
    },
    {
      "epoch": 0.0009243132983093422,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.715,
      "step": 254688
    },
    {
      "epoch": 0.000924429432660179,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7063,
      "step": 254720
    },
    {
      "epoch": 0.0009245455670110156,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6807,
      "step": 254752
    },
    {
      "epoch": 0.0009246617013618524,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6917,
      "step": 254784
    },
    {
      "epoch": 0.000924777835712689,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 254816
    },
    {
      "epoch": 0.0009248939700635258,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7194,
      "step": 254848
    },
    {
      "epoch": 0.0009250101044143624,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 254880
    },
    {
      "epoch": 0.0009251262387651992,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7271,
      "step": 254912
    },
    {
      "epoch": 0.0009252423731160358,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 254944
    },
    {
      "epoch": 0.0009253585074668726,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 254976
    },
    {
      "epoch": 0.0009254746418177094,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 255008
    },
    {
      "epoch": 0.000925590776168546,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 255040
    },
    {
      "epoch": 0.0009257069105193828,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7148,
      "step": 255072
    },
    {
      "epoch": 0.0009258230448702194,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7068,
      "step": 255104
    },
    {
      "epoch": 0.0009259391792210562,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7361,
      "step": 255136
    },
    {
      "epoch": 0.0009260553135718928,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 255168
    },
    {
      "epoch": 0.0009261714479227296,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 255200
    },
    {
      "epoch": 0.0009262875822735662,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7291,
      "step": 255232
    },
    {
      "epoch": 0.000926403716624403,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 255264
    },
    {
      "epoch": 0.0009265198509752397,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6935,
      "step": 255296
    },
    {
      "epoch": 0.0009266359853260764,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.695,
      "step": 255328
    },
    {
      "epoch": 0.0009267521196769131,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7084,
      "step": 255360
    },
    {
      "epoch": 0.0009268682540277498,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 255392
    },
    {
      "epoch": 0.0009269843883785865,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6981,
      "step": 255424
    },
    {
      "epoch": 0.0009271005227294232,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 255456
    },
    {
      "epoch": 0.0009272166570802599,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 255488
    },
    {
      "epoch": 0.0009273327914310966,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7448,
      "step": 255520
    },
    {
      "epoch": 0.0009274489257819333,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7465,
      "step": 255552
    },
    {
      "epoch": 0.0009275650601327701,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7085,
      "step": 255584
    },
    {
      "epoch": 0.0009276811944836067,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6843,
      "step": 255616
    },
    {
      "epoch": 0.0009277973288344435,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6999,
      "step": 255648
    },
    {
      "epoch": 0.0009279134631852801,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7163,
      "step": 255680
    },
    {
      "epoch": 0.0009280295975361169,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7229,
      "step": 255712
    },
    {
      "epoch": 0.0009281457318869535,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 255744
    },
    {
      "epoch": 0.0009282618662377903,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.724,
      "step": 255776
    },
    {
      "epoch": 0.0009283780005886269,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7557,
      "step": 255808
    },
    {
      "epoch": 0.0009284941349394637,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7106,
      "step": 255840
    },
    {
      "epoch": 0.0009286102692903004,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7157,
      "step": 255872
    },
    {
      "epoch": 0.0009287264036411371,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7131,
      "step": 255904
    },
    {
      "epoch": 0.0009288425379919738,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7112,
      "step": 255936
    },
    {
      "epoch": 0.0009289586723428105,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7054,
      "step": 255968
    },
    {
      "epoch": 0.0009290748066936472,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 256000
    },
    {
      "epoch": 0.0009291909410444839,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7231,
      "step": 256032
    },
    {
      "epoch": 0.0009293070753953206,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7144,
      "step": 256064
    },
    {
      "epoch": 0.0009294232097461573,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.717,
      "step": 256096
    },
    {
      "epoch": 0.000929539344096994,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7171,
      "step": 256128
    },
    {
      "epoch": 0.0009296554784478308,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6829,
      "step": 256160
    },
    {
      "epoch": 0.0009297716127986674,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 256192
    },
    {
      "epoch": 0.0009298877471495042,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7189,
      "step": 256224
    },
    {
      "epoch": 0.0009300038815003408,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 256256
    },
    {
      "epoch": 0.0009301200158511776,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7158,
      "step": 256288
    },
    {
      "epoch": 0.0009302361502020142,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7095,
      "step": 256320
    },
    {
      "epoch": 0.000930352284552851,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 256352
    },
    {
      "epoch": 0.0009304684189036876,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 256384
    },
    {
      "epoch": 0.0009305845532545244,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7586,
      "step": 256416
    },
    {
      "epoch": 0.0009307006876053611,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7399,
      "step": 256448
    },
    {
      "epoch": 0.0009308168219561978,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 256480
    },
    {
      "epoch": 0.0009309329563070345,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.721,
      "step": 256512
    },
    {
      "epoch": 0.0009310490906578712,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7044,
      "step": 256544
    },
    {
      "epoch": 0.0009311652250087079,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 256576
    },
    {
      "epoch": 0.0009312813593595446,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6966,
      "step": 256608
    },
    {
      "epoch": 0.0009313974937103813,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7037,
      "step": 256640
    },
    {
      "epoch": 0.000931513628061218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 256672
    },
    {
      "epoch": 0.0009316297624120547,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 256704
    },
    {
      "epoch": 0.0009317458967628915,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 256736
    },
    {
      "epoch": 0.0009318620311137281,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 256768
    },
    {
      "epoch": 0.0009319781654645649,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7072,
      "step": 256800
    },
    {
      "epoch": 0.0009320942998154015,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.705,
      "step": 256832
    },
    {
      "epoch": 0.0009322104341662383,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7176,
      "step": 256864
    },
    {
      "epoch": 0.0009323265685170749,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7211,
      "step": 256896
    },
    {
      "epoch": 0.0009324427028679117,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7199,
      "step": 256928
    },
    {
      "epoch": 0.0009325588372187483,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7167,
      "step": 256960
    },
    {
      "epoch": 0.0009326749715695851,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7214,
      "step": 256992
    },
    {
      "epoch": 0.0009327911059204218,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.701,
      "step": 257024
    },
    {
      "epoch": 0.0009329072402712585,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 257056
    },
    {
      "epoch": 0.0009330233746220952,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.691,
      "step": 257088
    },
    {
      "epoch": 0.0009331395089729319,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 257120
    },
    {
      "epoch": 0.0009332556433237686,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6868,
      "step": 257152
    },
    {
      "epoch": 0.0009333717776746053,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 257184
    },
    {
      "epoch": 0.000933487912025442,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7091,
      "step": 257216
    },
    {
      "epoch": 0.0009336040463762787,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7043,
      "step": 257248
    },
    {
      "epoch": 0.0009337201807271154,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7322,
      "step": 257280
    },
    {
      "epoch": 0.0009338363150779522,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7315,
      "step": 257312
    },
    {
      "epoch": 0.0009339524494287888,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7246,
      "step": 257344
    },
    {
      "epoch": 0.0009340685837796256,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 257376
    },
    {
      "epoch": 0.0009341847181304622,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7069,
      "step": 257408
    },
    {
      "epoch": 0.000934300852481299,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7086,
      "step": 257440
    },
    {
      "epoch": 0.0009344169868321356,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 257472
    },
    {
      "epoch": 0.0009345331211829724,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.709,
      "step": 257504
    },
    {
      "epoch": 0.000934649255533809,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.702,
      "step": 257536
    },
    {
      "epoch": 0.0009347653898846458,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7313,
      "step": 257568
    },
    {
      "epoch": 0.0009348815242354825,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.733,
      "step": 257600
    },
    {
      "epoch": 0.0009349976585863192,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 257632
    },
    {
      "epoch": 0.0009351137929371559,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 257664
    },
    {
      "epoch": 0.0009352299272879926,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7198,
      "step": 257696
    },
    {
      "epoch": 0.0009353460616388293,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 257728
    },
    {
      "epoch": 0.000935462195989666,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7453,
      "step": 257760
    },
    {
      "epoch": 0.0009355783303405027,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 257792
    },
    {
      "epoch": 0.0009356944646913394,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 257824
    },
    {
      "epoch": 0.0009358105990421761,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 257856
    },
    {
      "epoch": 0.0009359267333930129,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7187,
      "step": 257888
    },
    {
      "epoch": 0.0009360428677438495,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.697,
      "step": 257920
    },
    {
      "epoch": 0.0009361590020946863,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 257952
    },
    {
      "epoch": 0.0009362751364455229,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7076,
      "step": 257984
    },
    {
      "epoch": 0.0009363912707963597,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7117,
      "step": 258016
    },
    {
      "epoch": 0.0009365074051471963,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 258048
    },
    {
      "epoch": 0.0009366235394980331,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7146,
      "step": 258080
    },
    {
      "epoch": 0.0009367396738488697,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7067,
      "step": 258112
    },
    {
      "epoch": 0.0009368558081997065,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7249,
      "step": 258144
    },
    {
      "epoch": 0.0009369719425505432,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7641,
      "step": 258176
    },
    {
      "epoch": 0.0009370880769013799,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7581,
      "step": 258208
    },
    {
      "epoch": 0.0009372042112522166,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7109,
      "step": 258240
    },
    {
      "epoch": 0.0009373203456030533,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6934,
      "step": 258272
    },
    {
      "epoch": 0.00093743647995389,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7007,
      "step": 258304
    },
    {
      "epoch": 0.0009375526143047267,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7303,
      "step": 258336
    },
    {
      "epoch": 0.0009376687486555634,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7143,
      "step": 258368
    },
    {
      "epoch": 0.0009377848830064001,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7272,
      "step": 258400
    },
    {
      "epoch": 0.0009379010173572368,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7345,
      "step": 258432
    },
    {
      "epoch": 0.0009380171517080736,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7314,
      "step": 258464
    },
    {
      "epoch": 0.0009381332860589102,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.726,
      "step": 258496
    },
    {
      "epoch": 0.000938249420409747,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7209,
      "step": 258528
    },
    {
      "epoch": 0.0009383655547605836,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7177,
      "step": 258560
    },
    {
      "epoch": 0.0009384816891114204,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7175,
      "step": 258592
    },
    {
      "epoch": 0.000938597823462257,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7493,
      "step": 258624
    },
    {
      "epoch": 0.0009387139578130938,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7418,
      "step": 258656
    },
    {
      "epoch": 0.0009388300921639304,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7276,
      "step": 258688
    },
    {
      "epoch": 0.0009389462265147672,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 258720
    },
    {
      "epoch": 0.000939062360865604,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7318,
      "step": 258752
    },
    {
      "epoch": 0.0009391784952164406,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7269,
      "step": 258784
    },
    {
      "epoch": 0.0009392946295672773,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7234,
      "step": 258816
    },
    {
      "epoch": 0.000939410763918114,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7383,
      "step": 258848
    },
    {
      "epoch": 0.0009395268982689507,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6994,
      "step": 258880
    },
    {
      "epoch": 0.0009396430326197874,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6986,
      "step": 258912
    },
    {
      "epoch": 0.0009397591669706241,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.703,
      "step": 258944
    },
    {
      "epoch": 0.0009398753013214608,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7076,
      "step": 258976
    },
    {
      "epoch": 0.0009399914356722975,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7052,
      "step": 259008
    },
    {
      "epoch": 0.0009401075700231343,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7324,
      "step": 259040
    },
    {
      "epoch": 0.000940223704373971,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7298,
      "step": 259072
    },
    {
      "epoch": 0.0009403398387248077,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7066,
      "step": 259104
    },
    {
      "epoch": 0.0009404559730756443,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6867,
      "step": 259136
    },
    {
      "epoch": 0.0009405721074264811,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7005,
      "step": 259168
    },
    {
      "epoch": 0.0009406882417773177,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7151,
      "step": 259200
    },
    {
      "epoch": 0.0009408043761281545,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 259232
    },
    {
      "epoch": 0.0009409205104789911,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7081,
      "step": 259264
    },
    {
      "epoch": 0.0009410366448298279,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6978,
      "step": 259296
    },
    {
      "epoch": 0.0009411527791806647,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7358,
      "step": 259328
    },
    {
      "epoch": 0.0009412689135315013,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7342,
      "step": 259360
    },
    {
      "epoch": 0.0009413850478823381,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 259392
    },
    {
      "epoch": 0.0009415011822331747,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7092,
      "step": 259424
    },
    {
      "epoch": 0.0009416173165840115,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7224,
      "step": 259456
    },
    {
      "epoch": 0.0009417334509348481,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 259488
    },
    {
      "epoch": 0.0009418495852856849,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7355,
      "step": 259520
    },
    {
      "epoch": 0.0009419657196365215,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 259552
    },
    {
      "epoch": 0.0009420818539873583,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7138,
      "step": 259584
    },
    {
      "epoch": 0.000942197988338195,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7014,
      "step": 259616
    },
    {
      "epoch": 0.0009423141226890317,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7057,
      "step": 259648
    },
    {
      "epoch": 0.0009424302570398684,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6816,
      "step": 259680
    },
    {
      "epoch": 0.000942546391390705,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6938,
      "step": 259712
    },
    {
      "epoch": 0.0009426625257415418,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7118,
      "step": 259744
    },
    {
      "epoch": 0.0009427786600923785,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6965,
      "step": 259776
    },
    {
      "epoch": 0.0009428947944432152,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7375,
      "step": 259808
    },
    {
      "epoch": 0.0009430109287940519,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7308,
      "step": 259840
    },
    {
      "epoch": 0.0009431270631448886,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6917,
      "step": 259872
    },
    {
      "epoch": 0.0009432431974957254,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 259904
    },
    {
      "epoch": 0.000943359331846562,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7462,
      "step": 259936
    },
    {
      "epoch": 0.0009434754661973988,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7367,
      "step": 259968
    },
    {
      "epoch": 0.0009435916005482354,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6958,
      "step": 260000
    },
    {
      "epoch": 0.0009437077348990722,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6993,
      "step": 260032
    },
    {
      "epoch": 0.0009438238692499088,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.696,
      "step": 260064
    },
    {
      "epoch": 0.0009439400036007456,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7305,
      "step": 260096
    },
    {
      "epoch": 0.0009440561379515822,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7079,
      "step": 260128
    },
    {
      "epoch": 0.000944172272302419,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 260160
    },
    {
      "epoch": 0.0009442884066532557,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7102,
      "step": 260192
    },
    {
      "epoch": 0.0009444045410040924,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.728,
      "step": 260224
    },
    {
      "epoch": 0.0009445206753549291,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7178,
      "step": 260256
    },
    {
      "epoch": 0.0009446368097057658,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7088,
      "step": 260288
    },
    {
      "epoch": 0.0009447529440566025,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 260320
    },
    {
      "epoch": 0.0009448690784074392,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6963,
      "step": 260352
    },
    {
      "epoch": 0.0009449852127582759,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7265,
      "step": 260384
    },
    {
      "epoch": 0.0009451013471091126,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7299,
      "step": 260416
    },
    {
      "epoch": 0.0009452174814599493,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7236,
      "step": 260448
    },
    {
      "epoch": 0.0009453336158107861,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7181,
      "step": 260480
    },
    {
      "epoch": 0.0009454497501616227,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7243,
      "step": 260512
    },
    {
      "epoch": 0.0009455658845124595,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.707,
      "step": 260544
    },
    {
      "epoch": 0.0009456820188632961,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 260576
    },
    {
      "epoch": 0.0009457981532141329,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7046,
      "step": 260608
    },
    {
      "epoch": 0.0009459142875649695,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7058,
      "step": 260640
    },
    {
      "epoch": 0.0009460304219158063,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7097,
      "step": 260672
    },
    {
      "epoch": 0.0009461465562666429,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7136,
      "step": 260704
    },
    {
      "epoch": 0.0009462626906174797,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7416,
      "step": 260736
    },
    {
      "epoch": 0.0009463788249683164,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7098,
      "step": 260768
    },
    {
      "epoch": 0.0009464949593191531,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7285,
      "step": 260800
    },
    {
      "epoch": 0.0009466110936699898,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7346,
      "step": 260832
    },
    {
      "epoch": 0.0009467272280208265,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7022,
      "step": 260864
    },
    {
      "epoch": 0.0009468433623716632,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6915,
      "step": 260896
    },
    {
      "epoch": 0.0009469594967224999,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7038,
      "step": 260928
    },
    {
      "epoch": 0.0009470756310733366,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 260960
    },
    {
      "epoch": 0.0009471917654241733,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7225,
      "step": 260992
    },
    {
      "epoch": 0.00094730789977501,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7111,
      "step": 261024
    },
    {
      "epoch": 0.0009474240341258468,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.71,
      "step": 261056
    },
    {
      "epoch": 0.0009475401684766834,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.714,
      "step": 261088
    },
    {
      "epoch": 0.0009476563028275202,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7331,
      "step": 261120
    },
    {
      "epoch": 0.0009477724371783568,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7233,
      "step": 261152
    },
    {
      "epoch": 0.0009478885715291936,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7126,
      "step": 261184
    },
    {
      "epoch": 0.0009480047058800302,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7134,
      "step": 261216
    },
    {
      "epoch": 0.000948120840230867,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7062,
      "step": 261248
    },
    {
      "epoch": 0.0009482369745817036,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7548,
      "step": 261280
    },
    {
      "epoch": 0.0009483531089325404,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7336,
      "step": 261312
    },
    {
      "epoch": 0.0009484692432833771,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7329,
      "step": 261344
    },
    {
      "epoch": 0.0009485853776342138,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7254,
      "step": 261376
    },
    {
      "epoch": 0.0009487015119850505,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7366,
      "step": 261408
    },
    {
      "epoch": 0.0009488176463358872,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7258,
      "step": 261440
    },
    {
      "epoch": 0.0009489337806867239,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7122,
      "step": 261472
    },
    {
      "epoch": 0.0009490499150375606,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7034,
      "step": 261504
    },
    {
      "epoch": 0.0009491660493883973,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6851,
      "step": 261536
    },
    {
      "epoch": 0.000949282183739234,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7075,
      "step": 261568
    },
    {
      "epoch": 0.0009493983180900707,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7026,
      "step": 261600
    },
    {
      "epoch": 0.0009495144524409075,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7011,
      "step": 261632
    },
    {
      "epoch": 0.0009496305867917441,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7093,
      "step": 261664
    },
    {
      "epoch": 0.0009497467211425809,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7315,
      "step": 261696
    },
    {
      "epoch": 0.0009498628554934175,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7321,
      "step": 261728
    },
    {
      "epoch": 0.0009499789898442543,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6848,
      "step": 261760
    },
    {
      "epoch": 0.0009500951241950909,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7033,
      "step": 261792
    },
    {
      "epoch": 0.0009502112585459277,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6967,
      "step": 261824
    },
    {
      "epoch": 0.0009503273928967643,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7116,
      "step": 261856
    },
    {
      "epoch": 0.0009504435272476011,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.713,
      "step": 261888
    },
    {
      "epoch": 0.0009505596615984378,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7201,
      "step": 261920
    },
    {
      "epoch": 0.0009506757959492745,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7101,
      "step": 261952
    },
    {
      "epoch": 0.0009507919303001112,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7242,
      "step": 261984
    },
    {
      "epoch": 0.0009509080646509479,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7216,
      "step": 262016
    },
    {
      "epoch": 0.0009510241990017846,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7155,
      "step": 262048
    },
    {
      "epoch": 0.0009511403333526213,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.6986,
      "step": 262080
    },
    {
      "epoch": 0.000951256467703458,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7031,
      "step": 262112
    },
    {
      "epoch": 0.0009513726020542947,
      "grad_norm": 1.2276249554308492,
      "learning_rate": 0.002,
      "loss": 2.7262,
      "step": 262144
    },
    {
      "epoch": 0.0009513726020542947,
      "eval_loss": 2.5859375,
      "eval_runtime": 24820.6511,
      "eval_samples_per_second": 214.709,
      "eval_steps_per_second": 0.419,
      "step": 262144
    }
  ],
  "logging_steps": 32,
  "max_steps": 275542936,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 9223372036854775807,
  "save_steps": 262144,
  "total_flos": 2.0463160438120514e+19,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
